# Script dir = /Users/lmthang/nmt.matlab/scripts
cd /Users/lmthang/nmt.matlab/scripts/../code

## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'attnFunc', 0, 'feedInput', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 104, individual sizes:  W_src{1}=32 W_tgt{1}=48 W_emb_src=8 W_emb_tgt=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 0
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 1
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# attnGlobal = 0
# attnLocalMono = 0
# attnLocalPred = 0
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 104
  src input 1: y y x y
  src mask: 1  1  1  1
  tgt input 1: <s> a b a
  tgt output 1: a b a </s>
  tgt mask: 1  1  1  1
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=4.12108e-12
 -0.000000	 -0.000000	diff=2.62038e-13
 -0.000000	 -0.000000	diff=2.29777e-11
  0.000000	  0.000000	diff=5.08694e-12
 -0.000000	 -0.000000	diff=1.41871e-15
  0.000000	  0.000000	diff=3.76824e-13
 -0.000082	 -0.000082	diff=1.41073e-08
 -0.000429	 -0.000429	diff=5.82613e-09
 -0.000005	 -0.000005	diff=3.85284e-12
 -0.000002	 -0.000002	diff=1.41833e-11
 -0.000000	 -0.000000	diff=2.35784e-10
 -0.000000	 -0.000000	diff=4.20775e-12
  0.000000	  0.000000	diff=6.37582e-13
  0.000000	  0.000000	diff=1.55415e-14
 -0.001714	 -0.001714	diff=7.79316e-08
  0.000583	  0.000583	diff=1.44267e-08
 -0.000000	 -0.000000	diff=2.43737e-13
 -0.000000	 -0.000000	diff=2.62419e-13
 -0.000000	 -0.000000	diff=6.7098e-14
 -0.000000	 -0.000000	diff=2.40209e-13
  0.000000	  0.000000	diff=5.89005e-13
  0.000000	  0.000000	diff=5.07916e-13
 -0.000000	 -0.000000	diff=7.77005e-09
  0.000015	  0.000015	diff=1.10464e-10
  0.000000	  0.000000	diff=1.4889e-13
  0.000000	  0.000000	diff=4.96042e-13
  0.000000	  0.000000	diff=2.62731e-13
  0.000000	  0.000000	diff=4.80863e-14
 -0.000000	 -0.000000	diff=1.41999e-13
 -0.000000	 -0.000000	diff=1.99158e-13
 -0.000001	 -0.000001	diff=3.78879e-10
 -0.000010	 -0.000010	diff=1.80099e-08
  local_diff=1.38856e-07
# W_tgt{1}, [8 6]
 -0.000048	 -0.000048	diff=6.23528e-11
  0.000003	  0.000003	diff=4.21402e-12
  0.000008	  0.000008	diff=1.3699e-09
  0.000001	  0.000001	diff=1.52867e-10
 -0.000028	 -0.000028	diff=4.10949e-11
  0.000002	  0.000002	diff=6.22244e-13
 -0.000583	 -0.000584	diff=1.97963e-07
 -0.001178	 -0.001178	diff=2.08685e-08
 -0.000029	 -0.000029	diff=6.80607e-11
  0.000006	  0.000006	diff=8.83643e-12
 -0.000004	 -0.000004	diff=2.98218e-09
 -0.000003	 -0.000003	diff=3.50223e-10
 -0.000025	 -0.000025	diff=4.80695e-11
  0.000001	  0.000001	diff=2.12906e-11
 -0.012451	 -0.012452	diff=3.70661e-07
  0.000339	  0.000339	diff=3.0649e-09
  0.000000	  0.000000	diff=2.24188e-13
 -0.000000	 -0.000000	diff=2.90945e-14
 -0.000000	 -0.000000	diff=7.64907e-13
  0.000000	  0.000000	diff=7.07533e-13
 -0.000000	 -0.000000	diff=6.45375e-13
 -0.000000	 -0.000000	diff=3.09982e-13
 -0.000066	 -0.000066	diff=1.06522e-07
 -0.000001	 -0.000001	diff=2.34566e-11
 -0.000000	 -0.000000	diff=1.38788e-13
  0.000000	  0.000000	diff=1.30415e-13
  0.000000	  0.000000	diff=1.30545e-13
 -0.000000	 -0.000000	diff=3.6064e-13
 -0.000000	 -0.000000	diff=1.65886e-13
 -0.000000	 -0.000000	diff=2.34762e-13
 -0.000009	 -0.000009	diff=3.86424e-10
 -0.000000	 -0.000000	diff=7.96309e-09
  0.000000	  0.000000	diff=1.69923e-12
 -0.000000	 -0.000000	diff=8.78881e-14
 -0.000000	 -0.000000	diff=2.87261e-13
  0.000000	  0.000000	diff=3.92753e-13
 -0.000000	 -0.000000	diff=6.74556e-13
 -0.000000	 -0.000000	diff=6.85968e-13
 -0.000118	 -0.000118	diff=7.09232e-07
  0.000028	  0.000028	diff=2.59377e-09
 -0.000000	 -0.000000	diff=3.74429e-14
 -0.000000	 -0.000000	diff=7.93994e-13
  0.000000	  0.000000	diff=5.56238e-13
  0.000000	  0.000000	diff=2.52151e-13
 -0.000000	 -0.000000	diff=2.31236e-14
  0.000000	  0.000000	diff=4.54346e-13
  0.000054	  0.000054	diff=4.45869e-09
 -0.000023	 -0.000023	diff=8.81102e-08
  local_diff=1.51697e-06
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000825	  0.000825	diff=2.58159e-07
 -0.001517	 -0.001516	diff=6.64834e-07
  0.000079	  0.000079	diff=1.31214e-08
 -0.000444	 -0.000444	diff=2.36816e-07
  local_diff=1.17293e-06
# W_emb_tgt, [2 4]
 -0.003297	 -0.003296	diff=1.38301e-06
 -0.000952	 -0.000951	diff=3.06922e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.008593	 -0.008592	diff=5.44548e-07
 -0.003148	 -0.003147	diff=3.60548e-07
 -0.003640	 -0.003640	diff=3.84628e-07
 -0.001405	 -0.001405	diff=2.02457e-07
  local_diff=3.18211e-06
# W_soft, [4 2]
  0.001906	  0.001906	diff=4.54324e-08
 -0.001267	 -0.001267	diff=4.54347e-08
  0.002200	  0.002200	diff=4.54334e-08
 -0.002838	 -0.002838	diff=4.54343e-08
 -0.000094	 -0.000094	diff=1.8145e-08
  0.000714	  0.000714	diff=1.81449e-08
 -0.002257	 -0.002257	diff=1.81447e-08
  0.001638	  0.001638	diff=1.81453e-08
  local_diff=2.54315e-07
# Num params=104, abs_diff=6.26517e-06
Elapsed time is 0.799133 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'attnFunc', 0, 'feedInput', 1, 'numLayers', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 0
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# attnGlobal = 0
# attnLocalMono = 0
# attnLocalPred = 0
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s> x y y
  src mask: 0  1  1  1
  tgt input 1: <s> b b </s> </s>
  tgt output 1: b b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=1.87871e-13
  0.000000	  0.000000	diff=4.75103e-15
 -0.000000	 -0.000000	diff=1.17588e-12
  0.000000	  0.000000	diff=5.47156e-13
 -0.000000	 -0.000000	diff=8.1325e-15
 -0.000000	 -0.000000	diff=8.36079e-13
  0.000078	  0.000078	diff=1.29093e-10
  0.000029	  0.000029	diff=2.99692e-10
  0.000000	  0.000000	diff=1.38588e-12
 -0.000000	 -0.000000	diff=1.45782e-12
  0.000000	  0.000000	diff=5.29089e-12
 -0.000000	 -0.000000	diff=1.9633e-12
  0.000000	  0.000000	diff=1.88295e-12
  0.000000	  0.000000	diff=1.46083e-12
 -0.000146	 -0.000146	diff=3.69597e-10
 -0.000050	 -0.000050	diff=7.14102e-10
  0.000000	  0.000000	diff=1.7042e-13
 -0.000000	 -0.000000	diff=2.19934e-13
  0.000000	  0.000000	diff=6.20103e-13
 -0.000000	 -0.000000	diff=8.92369e-15
  0.000000	  0.000000	diff=3.33915e-13
  0.000000	  0.000000	diff=4.07054e-13
 -0.000002	 -0.000002	diff=2.7209e-09
 -0.000001	 -0.000001	diff=5.82579e-12
 -0.000000	 -0.000000	diff=3.72225e-13
  0.000000	  0.000000	diff=9.99215e-14
 -0.000000	 -0.000000	diff=3.81436e-13
  0.000000	  0.000000	diff=9.86182e-13
 -0.000000	 -0.000000	diff=1.6738e-13
 -0.000000	 -0.000000	diff=4.96972e-13
  0.000002	  0.000002	diff=1.37024e-11
  0.000001	  0.000001	diff=1.14097e-09
  local_diff=5.41436e-09
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=4.53474e-13
  0.000000	  0.000000	diff=1.34504e-13
  0.000000	  0.000000	diff=6.23959e-13
  0.000000	  0.000000	diff=7.88075e-13
 -0.000000	 -0.000000	diff=2.74073e-13
  0.000000	  0.000000	diff=4.31215e-13
 -0.000013	 -0.000013	diff=1.16015e-12
  0.000125	  0.000125	diff=3.2989e-11
 -0.000000	 -0.000000	diff=6.34955e-13
 -0.000000	 -0.000000	diff=3.00408e-13
 -0.000000	 -0.000000	diff=4.77675e-13
 -0.000000	 -0.000000	diff=5.29321e-14
  0.000000	  0.000000	diff=1.84297e-13
 -0.000000	 -0.000000	diff=1.00939e-12
  0.000011	  0.000011	diff=4.28623e-13
 -0.000110	 -0.000110	diff=2.32604e-11
  0.000000	  0.000000	diff=3.06914e-13
  0.000000	  0.000000	diff=1.83441e-13
  0.000000	  0.000000	diff=3.043e-13
  0.000000	  0.000000	diff=9.44611e-14
  0.000000	  0.000000	diff=2.75684e-14
 -0.000000	 -0.000000	diff=1.15939e-12
 -0.000000	 -0.000000	diff=3.36492e-10
  0.000002	  0.000002	diff=9.28825e-13
 -0.000000	 -0.000000	diff=3.50341e-13
 -0.000000	 -0.000000	diff=7.52409e-14
 -0.000000	 -0.000000	diff=1.74739e-14
 -0.000000	 -0.000000	diff=4.63679e-13
  0.000000	 -0.000000	diff=1.00198e-14
  0.000000	  0.000000	diff=3.02766e-13
  0.000000	  0.000000	diff=2.75185e-13
 -0.000003	 -0.000003	diff=3.49534e-09
  local_diff=3.89953e-09
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=5.17737e-13
 -0.000000	 -0.000000	diff=1.38985e-12
  0.000000	  0.000000	diff=5.08026e-13
  0.000000	  0.000000	diff=1.20726e-11
  0.000000	  0.000000	diff=8.89307e-13
  0.000000	  0.000000	diff=1.65113e-12
 -0.000015	 -0.000015	diff=2.60037e-13
  0.000062	  0.000062	diff=9.26206e-10
 -0.000000	 -0.000000	diff=9.67936e-14
  0.000000	  0.000000	diff=1.41854e-12
 -0.000000	 -0.000000	diff=4.95997e-12
 -0.000000	 -0.000000	diff=1.86669e-11
 -0.000000	 -0.000000	diff=3.67983e-13
  0.000000	  0.000000	diff=1.24693e-12
  0.000039	  0.000039	diff=2.08119e-10
 -0.000246	 -0.000246	diff=1.15356e-09
 -0.000000	 -0.000000	diff=2.74914e-13
  0.000000	  0.000000	diff=8.15147e-13
 -0.000000	 -0.000000	diff=2.62175e-13
  0.000000	  0.000000	diff=7.42665e-13
 -0.000000	 -0.000000	diff=7.93994e-13
  0.000000	  0.000000	diff=3.29668e-13
  0.000000	  0.000000	diff=6.85349e-13
 -0.000000	 -0.000000	diff=3.92488e-13
 -0.000000	 -0.000000	diff=1.55321e-13
  0.000000	  0.000000	diff=4.17505e-13
 -0.000000	 -0.000000	diff=9.98782e-14
  0.000000	  0.000000	diff=4.81805e-13
 -0.000000	 -0.000000	diff=4.44256e-14
  0.000000	  0.000000	diff=3.88969e-13
 -0.000000	 -0.000000	diff=1.24565e-13
 -0.000000	 -0.000000	diff=4.05286e-12
 -0.000000	 -0.000000	diff=1.28261e-12
  0.000000	  0.000000	diff=1.38249e-13
 -0.000000	 -0.000000	diff=2.33193e-13
 -0.000000	 -0.000000	diff=1.12589e-12
 -0.000000	 -0.000000	diff=3.66089e-13
 -0.000000	 -0.000000	diff=7.37407e-13
  0.000001	  0.000001	diff=2.31297e-10
 -0.000003	 -0.000003	diff=1.38626e-10
  0.000000	  0.000000	diff=3.22522e-13
 -0.000000	 -0.000000	diff=7.6103e-14
  0.000000	  0.000000	diff=2.80737e-13
  0.000000	  0.000000	diff=3.54845e-13
  0.000000	  0.000000	diff=1.37503e-13
 -0.000000	 -0.000000	diff=9.48806e-13
 -0.000001	 -0.000001	diff=8.0484e-12
  0.000005	  0.000005	diff=4.11802e-09
  local_diff=6.84399e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=2.01666e-13
 -0.000000	 -0.000000	diff=3.55836e-13
  0.000000	  0.000000	diff=4.33285e-13
  0.000000	  0.000000	diff=3.49945e-13
  0.000000	  0.000000	diff=1.01009e-13
  0.000000	  0.000000	diff=5.52553e-13
 -0.000017	 -0.000017	diff=3.8587e-11
  0.000075	  0.000075	diff=1.12985e-09
  0.000000	  0.000000	diff=5.65055e-13
 -0.000000	 -0.000000	diff=3.45518e-13
  0.000000	  0.000000	diff=5.41945e-13
 -0.000000	 -0.000000	diff=2.11951e-13
  0.000000	  0.000000	diff=1.72483e-13
 -0.000000	 -0.000000	diff=3.24814e-14
 -0.000007	 -0.000007	diff=8.52036e-10
 -0.000017	 -0.000017	diff=5.05571e-09
 -0.000000	 -0.000000	diff=3.91826e-13
  0.000000	  0.000000	diff=3.82185e-13
  0.000000	  0.000000	diff=8.93196e-13
  0.000000	  0.000000	diff=1.01494e-13
  0.000000	  0.000000	diff=3.42643e-13
  0.000000	  0.000000	diff=7.43071e-13
 -0.000001	 -0.000001	diff=2.26882e-09
  0.000008	  0.000008	diff=1.23334e-10
  0.000000	  0.000000	diff=7.85061e-13
  0.000000	  0.000000	diff=3.95749e-13
 -0.000000	 -0.000000	diff=5.20942e-13
 -0.000000	 -0.000000	diff=4.53371e-13
 -0.000000	 -0.000000	diff=1.25216e-12
 -0.000000	 -0.000000	diff=5.07102e-13
  0.000001	  0.000001	diff=3.17078e-12
 -0.000007	 -0.000007	diff=2.27645e-10
  local_diff=9.70978e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000068	 -0.000068	diff=1.93566e-08
  0.000063	  0.000063	diff=5.08945e-08
 -0.000052	 -0.000052	diff=1.84554e-08
  0.000041	  0.000041	diff=4.53804e-08
  local_diff=1.34087e-07
# W_emb_tgt, [2 4]
 -0.000158	 -0.000158	diff=2.67855e-08
  0.000016	  0.000016	diff=6.77983e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000030	 -0.000030	diff=4.72495e-11
  0.000007	  0.000007	diff=4.74812e-09
  0.000048	  0.000048	diff=1.06678e-08
 -0.000004	 -0.000004	diff=1.79221e-09
  local_diff=5.08208e-08
# W_soft, [4 2]
  0.000042	  0.000042	diff=1.4367e-11
 -0.000201	 -0.000201	diff=1.39263e-11
  0.000111	  0.000111	diff=1.47236e-11
  0.000048	  0.000048	diff=1.45372e-11
  0.000418	  0.000418	diff=8.29578e-11
 -0.000214	 -0.000214	diff=8.33051e-11
 -0.000266	 -0.000266	diff=8.36797e-11
  0.000062	  0.000062	diff=8.33019e-11
  local_diff=3.90799e-10
# Num params=168, abs_diff=2.11166e-07
Elapsed time is 1.650331 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'attnFunc', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 0
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# attnGlobal = 0
# attnLocalMono = 0
# attnLocalPred = 0
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s> x y y
  src mask: 0  1  1  1
  tgt input 1: <s> b b </s> </s>
  tgt output 1: b b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=1.09364e-12
  0.000000	  0.000000	diff=9.80612e-13
 -0.000000	 -0.000000	diff=2.95292e-12
  0.000000	  0.000000	diff=8.52952e-13
 -0.000000	 -0.000000	diff=1.13293e-12
 -0.000000	 -0.000000	diff=4.50829e-13
  0.000108	  0.000108	diff=1.9171e-10
  0.000037	  0.000037	diff=4.68442e-10
  0.000001	  0.000001	diff=2.80729e-12
 -0.000000	 -0.000000	diff=9.33952e-13
  0.000000	  0.000000	diff=1.06795e-11
 -0.000000	 -0.000000	diff=4.98434e-12
  0.000001	  0.000001	diff=2.87542e-12
  0.000000	  0.000000	diff=1.92008e-13
 -0.000174	 -0.000174	diff=6.12174e-10
 -0.000068	 -0.000068	diff=1.11872e-09
  0.000000	  0.000000	diff=2.52429e-13
 -0.000000	 -0.000000	diff=8.25308e-13
  0.000000	  0.000000	diff=2.05444e-13
 -0.000000	 -0.000000	diff=6.31417e-14
  0.000000	  0.000000	diff=4.44248e-13
  0.000000	  0.000000	diff=4.17173e-13
 -0.000003	 -0.000003	diff=3.14552e-09
 -0.000001	 -0.000001	diff=6.44732e-12
 -0.000000	 -0.000000	diff=1.65474e-13
  0.000000	  0.000000	diff=3.48623e-13
 -0.000000	 -0.000000	diff=9.29333e-14
  0.000000	  0.000000	diff=5.59084e-13
 -0.000000	 -0.000000	diff=3.0615e-13
 -0.000000	 -0.000000	diff=6.59088e-13
  0.000003	  0.000003	diff=1.35491e-11
  0.000001	  0.000001	diff=1.51822e-09
  local_diff=7.10905e-09
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=5.50563e-13
  0.000000	  0.000000	diff=1.22676e-13
  0.000000	  0.000000	diff=1.91327e-13
  0.000000	  0.000000	diff=1.45279e-13
  0.000000	  0.000000	diff=2.66669e-13
 -0.000000	 -0.000000	diff=1.17497e-12
 -0.000007	 -0.000007	diff=1.82884e-12
  0.000161	  0.000161	diff=6.668e-11
 -0.000000	 -0.000000	diff=8.28265e-13
 -0.000000	 -0.000000	diff=3.25382e-15
 -0.000000	 -0.000000	diff=2.74441e-13
 -0.000000	 -0.000000	diff=8.13436e-13
 -0.000000	 -0.000000	diff=2.21267e-14
  0.000000	  0.000000	diff=4.63295e-13
  0.000005	  0.000005	diff=4.63231e-13
 -0.000135	 -0.000135	diff=4.89445e-11
  0.000000	  0.000000	diff=5.53561e-13
  0.000000	  0.000000	diff=8.26172e-13
  0.000000	  0.000000	diff=5.89552e-13
  0.000000	  0.000000	diff=5.68236e-13
  0.000000	  0.000000	diff=6.84781e-13
 -0.000000	 -0.000000	diff=5.87344e-14
 -0.000000	 -0.000000	diff=2.32642e-10
  0.000003	  0.000003	diff=2.15876e-13
 -0.000000	 -0.000000	diff=8.66625e-13
 -0.000000	 -0.000000	diff=5.98642e-13
 -0.000000	 -0.000000	diff=9.46902e-14
 -0.000000	 -0.000000	diff=3.99087e-13
 -0.000000	 -0.000000	diff=3.03796e-13
  0.000000	  0.000000	diff=5.1609e-13
  0.000000	  0.000000	diff=5.39588e-13
 -0.000004	 -0.000004	diff=4.05826e-09
  local_diff=4.42049e-09
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=1.7816e-13
 -0.000000	 -0.000000	diff=2.8465e-12
  0.000000	  0.000000	diff=1.92235e-12
  0.000000	  0.000000	diff=3.1677e-11
  0.000000	  0.000000	diff=1.00932e-12
  0.000000	  0.000000	diff=2.36142e-12
 -0.000020	 -0.000020	diff=1.29066e-10
  0.000115	  0.000115	diff=1.38437e-09
 -0.000000	 -0.000000	diff=2.41373e-13
  0.000001	  0.000001	diff=1.48548e-12
 -0.000000	 -0.000000	diff=7.13818e-12
 -0.000000	 -0.000000	diff=3.64973e-11
 -0.000000	 -0.000000	diff=5.47413e-13
  0.000000	  0.000000	diff=6.64778e-13
  0.000022	  0.000022	diff=1.91815e-11
 -0.000201	 -0.000201	diff=2.07743e-09
 -0.000000	 -0.000000	diff=1.49093e-12
  0.000000	  0.000000	diff=9.12218e-14
 -0.000000	 -0.000000	diff=2.26095e-14
  0.000000	  0.000000	diff=1.17987e-13
 -0.000000	 -0.000000	diff=5.62661e-13
  0.000000	  0.000000	diff=6.83768e-13
  0.000000	  0.000000	diff=3.83518e-13
 -0.000000	 -0.000000	diff=4.67511e-13
 -0.000000	 -0.000000	diff=4.66735e-13
  0.000000	  0.000000	diff=2.78207e-13
 -0.000000	 -0.000000	diff=4.97995e-13
  0.000000	  0.000000	diff=4.71402e-13
  0.000000	  0.000000	diff=3.22534e-13
  0.000000	  0.000000	diff=4.02284e-13
  0.000000	  0.000000	diff=5.58212e-13
 -0.000000	 -0.000000	diff=4.76981e-12
 -0.000000	 -0.000000	diff=3.22877e-13
  0.000000	  0.000000	diff=7.48947e-13
 -0.000000	 -0.000000	diff=4.89491e-13
 -0.000000	 -0.000000	diff=5.9079e-13
 -0.000000	 -0.000000	diff=4.52118e-13
 -0.000000	 -0.000000	diff=5.36659e-13
  0.000001	  0.000001	diff=2.55753e-10
 -0.000005	 -0.000005	diff=1.76365e-10
  0.000000	  0.000000	diff=3.53711e-13
 -0.000000	 -0.000000	diff=2.12685e-14
  0.000000	  0.000000	diff=4.32161e-13
  0.000000	  0.000000	diff=4.9507e-13
  0.000000	  0.000000	diff=2.67875e-13
 -0.000000	 -0.000000	diff=1.02391e-13
 -0.000001	 -0.000001	diff=6.3292e-12
  0.000006	  0.000006	diff=6.28238e-09
  local_diff=1.04338e-08
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=1.02928e-12
 -0.000000	 -0.000000	diff=1.70213e-13
  0.000000	  0.000000	diff=7.19194e-13
  0.000000	  0.000000	diff=2.93348e-14
  0.000000	  0.000000	diff=4.01891e-13
  0.000000	  0.000000	diff=2.24166e-13
 -0.000025	 -0.000025	diff=2.19886e-10
  0.000184	  0.000184	diff=3.15538e-09
 -0.000000	 -0.000000	diff=3.3341e-15
 -0.000000	 -0.000000	diff=1.1556e-13
  0.000000	  0.000000	diff=2.3503e-13
 -0.000000	 -0.000000	diff=4.497e-13
  0.000000	  0.000000	diff=1.26662e-13
 -0.000000	 -0.000000	diff=7.56155e-13
 -0.000010	 -0.000010	diff=1.40094e-09
  0.000006	  0.000006	diff=3.61153e-09
 -0.000000	 -0.000000	diff=3.25059e-13
  0.000000	  0.000000	diff=1.93779e-13
  0.000000	  0.000000	diff=6.82007e-13
  0.000000	  0.000000	diff=1.46005e-13
 -0.000000	 -0.000000	diff=6.81174e-13
  0.000000	  0.000000	diff=5.09287e-13
 -0.000001	 -0.000001	diff=2.44011e-09
  0.000010	  0.000010	diff=1.44717e-10
  0.000000	  0.000000	diff=2.12523e-13
  0.000000	  0.000000	diff=2.90598e-13
 -0.000000	 -0.000000	diff=5.47854e-13
 -0.000000	 -0.000000	diff=3.97262e-13
  0.000000	  0.000000	diff=3.83309e-13
 -0.000000	 -0.000000	diff=2.3611e-13
  0.000001	  0.000001	diff=1.9942e-12
 -0.000010	 -0.000010	diff=3.88842e-09
  local_diff=1.48718e-08
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000069	 -0.000069	diff=2.71427e-08
  0.000052	  0.000052	diff=5.86418e-08
 -0.000077	 -0.000077	diff=3.39724e-08
  0.000055	  0.000055	diff=7.00118e-08
  local_diff=1.89769e-07
# W_emb_tgt, [2 4]
 -0.000194	 -0.000194	diff=4.48346e-08
  0.000009	  0.000009	diff=3.76697e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000066	 -0.000066	diff=1.23607e-09
  0.000005	  0.000005	diff=3.73416e-09
  0.000047	  0.000047	diff=1.31973e-08
 -0.000003	 -0.000003	diff=2.08585e-09
  local_diff=6.8855e-08
# W_soft, [4 2]
  0.000076	  0.000076	diff=3.22358e-11
 -0.000222	 -0.000222	diff=3.22656e-11
  0.000120	  0.000120	diff=3.27771e-11
  0.000025	  0.000025	diff=3.27508e-11
  0.000468	  0.000468	diff=1.4538e-10
 -0.000177	 -0.000177	diff=1.4486e-10
 -0.000386	 -0.000386	diff=1.45896e-10
  0.000095	  0.000095	diff=1.45087e-10
  local_diff=7.11253e-10
# Num params=168, abs_diff=2.9617e-07
Elapsed time is 1.661042 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 1
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s> y x x
  src mask: 0  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=6.88548e-13
  0.000000	  0.000000	diff=8.36065e-13
 -0.000000	 -0.000000	diff=1.61821e-12
  0.000000	  0.000000	diff=1.03905e-12
 -0.000000	 -0.000000	diff=8.8062e-13
 -0.000000	 -0.000000	diff=7.37703e-13
  0.000000	  0.000000	diff=4.8661e-11
  0.000002	  0.000002	diff=2.2271e-11
  0.000000	  0.000000	diff=5.07879e-13
 -0.000000	 -0.000000	diff=3.71076e-13
  0.000000	  0.000000	diff=8.99572e-13
 -0.000000	 -0.000000	diff=1.04706e-12
  0.000000	  0.000000	diff=9.28084e-13
  0.000000	  0.000000	diff=6.23029e-13
 -0.000004	 -0.000004	diff=1.14261e-10
 -0.000005	 -0.000005	diff=6.69479e-11
  0.000000	  0.000000	diff=5.21005e-13
 -0.000000	 -0.000000	diff=8.66919e-13
  0.000000	  0.000000	diff=6.63329e-13
 -0.000000	 -0.000000	diff=4.87999e-13
  0.000000	  0.000000	diff=8.80015e-13
  0.000000	  0.000000	diff=1.08339e-12
 -0.000000	 -0.000000	diff=1.0771e-10
 -0.000000	 -0.000000	diff=1.17317e-12
 -0.000000	 -0.000000	diff=1.32296e-12
  0.000000	  0.000000	diff=1.08085e-12
 -0.000000	 -0.000000	diff=1.02843e-12
  0.000000	  0.000000	diff=5.7323e-13
 -0.000000	 -0.000000	diff=9.55287e-13
 -0.000000	 -0.000000	diff=5.48242e-13
  0.000000	  0.000000	diff=1.21948e-12
  0.000000	  0.000000	diff=5.42346e-11
  local_diff=4.36666e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=6.79797e-13
  0.000000	  0.000000	diff=1.05541e-12
  0.000000	  0.000000	diff=9.29485e-13
  0.000000	  0.000000	diff=5.68897e-13
  0.000000	  0.000000	diff=1.15556e-14
 -0.000000	 -0.000000	diff=1.09979e-12
 -0.000003	 -0.000003	diff=1.60231e-12
  0.000000	  0.000000	diff=4.27095e-12
 -0.000000	 -0.000000	diff=7.13633e-13
 -0.000000	 -0.000000	diff=1.59203e-12
 -0.000000	 -0.000000	diff=8.68697e-13
 -0.000000	 -0.000000	diff=9.51453e-13
 -0.000000	 -0.000000	diff=5.1282e-13
  0.000000	  0.000000	diff=1.09761e-12
  0.000002	  0.000002	diff=3.64925e-13
 -0.000001	 -0.000001	diff=3.57701e-12
  0.000000	  0.000000	diff=8.01743e-13
  0.000000	  0.000000	diff=1.19217e-12
  0.000000	  0.000000	diff=3.51089e-13
  0.000000	  0.000000	diff=6.46993e-13
  0.000000	  0.000000	diff=2.47219e-14
 -0.000000	 -0.000000	diff=8.03847e-13
 -0.000000	 -0.000000	diff=1.50265e-11
  0.000000	  0.000000	diff=3.94465e-13
 -0.000000	 -0.000000	diff=5.32596e-13
 -0.000000	 -0.000000	diff=5.67969e-13
 -0.000000	 -0.000000	diff=6.02219e-13
 -0.000000	 -0.000000	diff=1.0891e-13
 -0.000000	 -0.000000	diff=9.37629e-13
  0.000000	  0.000000	diff=7.59696e-13
  0.000000	  0.000000	diff=8.59509e-13
 -0.000000	 -0.000000	diff=1.30047e-10
  local_diff=1.73553e-10
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=1.22842e-12
  0.000000	  0.000000	diff=2.03576e-13
  0.000000	  0.000000	diff=9.12118e-13
  0.000000	  0.000000	diff=1.74141e-14
  0.000000	  0.000000	diff=8.86168e-13
  0.000000	  0.000000	diff=6.92089e-13
 -0.000001	 -0.000001	diff=2.01473e-11
 -0.000001	 -0.000001	diff=5.88403e-12
  0.000000	  0.000000	diff=8.27061e-13
 -0.000000	 -0.000000	diff=1.26103e-12
 -0.000000	 -0.000000	diff=1.126e-12
 -0.000000	 -0.000000	diff=3.45648e-13
 -0.000000	 -0.000000	diff=9.61819e-13
 -0.000000	 -0.000000	diff=5.21359e-14
  0.000001	  0.000001	diff=1.22109e-11
 -0.000004	 -0.000004	diff=1.05836e-10
  0.000000	  0.000000	diff=9.30589e-15
  0.000000	  0.000000	diff=5.86168e-14
  0.000000	 -0.000000	diff=3.65553e-15
  0.000000	 -0.000000	diff=7.24666e-13
  0.000000	 -0.000000	diff=4.1619e-16
  0.000000	  0.000000	diff=7.10447e-14
  0.000000	  0.000000	diff=3.64917e-13
 -0.000000	 -0.000000	diff=1.08088e-12
  0.000000	 -0.000000	diff=7.22993e-13
  0.000000	  0.000000	diff=1.3405e-13
  0.000000	 -0.000000	diff=1.37632e-14
  0.000000	  0.000000	diff=6.86946e-13
  0.000000	 -0.000000	diff=2.29627e-14
  0.000000	  0.000000	diff=5.6629e-13
  0.000000	  0.000000	diff=5.23458e-13
 -0.000000	 -0.000000	diff=5.09363e-13
 -0.000000	 -0.000000	diff=4.25178e-13
  0.000000	  0.000000	diff=1.0514e-12
 -0.000000	 -0.000000	diff=2.56734e-13
 -0.000000	 -0.000000	diff=1.59849e-12
 -0.000000	 -0.000000	diff=4.64162e-13
 -0.000000	 -0.000000	diff=6.83472e-13
  0.000000	  0.000000	diff=1.50546e-11
 -0.000000	 -0.000000	diff=1.64058e-12
 -0.000000	 -0.000000	diff=1.24408e-12
 -0.000000	 -0.000000	diff=8.23345e-13
 -0.000000	 -0.000000	diff=1.03498e-12
  0.000000	  0.000000	diff=9.96847e-13
 -0.000000	 -0.000000	diff=1.28849e-12
  0.000000	  0.000000	diff=4.05989e-13
  0.000000	  0.000000	diff=1.14532e-12
  0.000000	  0.000000	diff=2.9081e-10
  local_diff=4.77008e-10
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=9.17873e-14
 -0.000000	 -0.000000	diff=1.39024e-12
 -0.000000	 -0.000000	diff=7.15407e-13
  0.000000	  0.000000	diff=1.36112e-12
  0.000000	  0.000000	diff=6.40369e-13
  0.000000	  0.000000	diff=9.87172e-13
  0.000001	  0.000001	diff=8.17744e-13
  0.000023	  0.000023	diff=5.13688e-11
  0.000000	  0.000000	diff=4.6509e-13
 -0.000000	 -0.000000	diff=9.97141e-13
  0.000000	  0.000000	diff=7.73193e-13
 -0.000000	 -0.000000	diff=6.25001e-13
  0.000000	  0.000000	diff=6.25078e-13
 -0.000000	 -0.000000	diff=1.32202e-12
 -0.000000	 -0.000000	diff=7.96616e-13
 -0.000005	 -0.000005	diff=5.26296e-12
  0.000000	  0.000000	diff=6.61944e-13
 -0.000000	 -0.000000	diff=8.19056e-13
 -0.000000	 -0.000000	diff=1.00162e-14
  0.000000	  0.000000	diff=7.19314e-13
 -0.000000	 -0.000000	diff=6.55132e-13
  0.000000	  0.000000	diff=1.1584e-12
  0.000000	  0.000000	diff=4.30172e-12
  0.000000	  0.000000	diff=4.66545e-12
  0.000000	 -0.000000	diff=3.79186e-13
  0.000000	  0.000000	diff=5.26826e-13
  0.000000	  0.000000	diff=6.10613e-13
 -0.000000	 -0.000000	diff=1.12148e-12
  0.000000	  0.000000	diff=1.89584e-13
 -0.000000	 -0.000000	diff=8.44874e-13
 -0.000000	 -0.000000	diff=4.11167e-13
 -0.000000	 -0.000000	diff=3.70596e-10
  local_diff=4.55911e-10
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=9.59615e-12
 -0.000002	 -0.000002	diff=9.03656e-10
  0.000000	  0.000000	diff=2.62626e-10
 -0.000000	 -0.000000	diff=6.47188e-10
  local_diff=1.82307e-09
# W_emb_tgt, [2 4]
 -0.000004	 -0.000004	diff=3.21261e-10
  0.000001	  0.000001	diff=4.45686e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000004	  0.000004	diff=2.30024e-11
 -0.000000	 -0.000000	diff=7.45975e-11
  0.000001	  0.000001	diff=2.55916e-10
  0.000000	  0.000000	diff=8.3311e-11
  local_diff=1.20377e-09
# W_h, [2 4]
 -0.000003	 -0.000003	diff=5.54338e-13
  0.000023	  0.000023	diff=2.11994e-12
  0.000004	  0.000004	diff=1.03137e-12
 -0.000028	 -0.000028	diff=2.24115e-12
  0.000011	  0.000011	diff=8.25527e-12
 -0.000010	 -0.000010	diff=6.46867e-13
  0.000008	  0.000008	diff=7.11794e-11
 -0.000018	 -0.000018	diff=7.62286e-11
  local_diff=1.62257e-10
# W_soft, [4 2]
  0.000010	  0.000010	diff=1.15485e-12
 -0.000007	 -0.000007	diff=5.68045e-13
  0.000001	  0.000001	diff=1.29841e-12
 -0.000004	 -0.000004	diff=5.31408e-13
  0.000002	  0.000002	diff=1.01439e-12
 -0.000005	 -0.000005	diff=1.44723e-12
  0.000003	  0.000003	diff=4.99522e-13
  0.000000	  0.000000	diff=1.30212e-12
  local_diff=7.81597e-12
# Num params=176, abs_diff=4.74005e-09
Elapsed time is 2.511751 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 2, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 2
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s> y x x
  src mask: 0  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=2.8446e-13
  0.000000	  0.000000	diff=1.4517e-13
 -0.000000	 -0.000000	diff=3.2446e-13
  0.000000	  0.000000	diff=3.64582e-13
 -0.000000	 -0.000000	diff=5.39226e-13
 -0.000000	 -0.000000	diff=1.93794e-14
  0.000000	  0.000000	diff=4.96297e-11
  0.000002	  0.000002	diff=2.44427e-11
  0.000000	  0.000000	diff=4.74783e-13
 -0.000000	 -0.000000	diff=1.21478e-12
  0.000000	  0.000000	diff=1.1527e-12
 -0.000000	 -0.000000	diff=4.57675e-13
  0.000000	  0.000000	diff=9.01772e-13
  0.000000	  0.000000	diff=9.06545e-13
 -0.000003	 -0.000003	diff=1.16582e-10
 -0.000005	 -0.000005	diff=6.88028e-11
  0.000000	  0.000000	diff=7.49879e-13
 -0.000000	 -0.000000	diff=7.23547e-13
  0.000000	  0.000000	diff=3.49603e-13
 -0.000000	 -0.000000	diff=7.15873e-13
  0.000000	  0.000000	diff=9.79301e-13
  0.000000	  0.000000	diff=2.5666e-14
 -0.000000	 -0.000000	diff=9.65995e-11
 -0.000000	 -0.000000	diff=6.52081e-13
 -0.000000	 -0.000000	diff=8.98269e-13
  0.000000	  0.000000	diff=8.35159e-13
 -0.000000	 -0.000000	diff=8.4386e-13
  0.000000	  0.000000	diff=8.63674e-13
 -0.000000	 -0.000000	diff=1.16667e-12
 -0.000000	 -0.000000	diff=9.05458e-13
  0.000000	  0.000000	diff=1.13585e-12
  0.000000	  0.000000	diff=5.72749e-11
  local_diff=4.30962e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=1.32015e-12
  0.000000	  0.000000	diff=9.83643e-13
  0.000000	  0.000000	diff=4.75665e-13
  0.000000	  0.000000	diff=8.15478e-13
  0.000000	  0.000000	diff=6.00408e-13
 -0.000000	 -0.000000	diff=7.13813e-13
 -0.000003	 -0.000003	diff=6.17396e-14
 -0.000000	 -0.000000	diff=5.70648e-12
 -0.000000	 -0.000000	diff=1.11319e-12
 -0.000000	 -0.000000	diff=6.63345e-13
 -0.000000	 -0.000000	diff=5.07403e-13
 -0.000000	 -0.000000	diff=4.24524e-13
 -0.000000	 -0.000000	diff=9.78044e-13
  0.000000	  0.000000	diff=1.02438e-12
  0.000002	  0.000002	diff=2.79759e-13
 -0.000000	 -0.000000	diff=5.33878e-12
  0.000000	  0.000000	diff=9.66189e-13
  0.000000	  0.000000	diff=3.23317e-13
  0.000000	  0.000000	diff=5.48645e-13
  0.000000	  0.000000	diff=3.6308e-13
  0.000000	  0.000000	diff=1.12691e-12
 -0.000000	 -0.000000	diff=8.63932e-13
 -0.000000	 -0.000000	diff=2.02414e-11
  0.000000	  0.000000	diff=4.41561e-13
 -0.000000	 -0.000000	diff=4.63484e-13
 -0.000000	 -0.000000	diff=5.09307e-13
 -0.000000	 -0.000000	diff=5.86388e-13
 -0.000000	 -0.000000	diff=1.52156e-13
 -0.000000	 -0.000000	diff=6.53564e-13
  0.000000	  0.000000	diff=1.00229e-12
  0.000000	  0.000000	diff=6.3577e-13
 -0.000000	 -0.000000	diff=1.08977e-10
  local_diff=1.58862e-10
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=1.93713e-13
  0.000000	  0.000000	diff=8.44221e-13
  0.000000	  0.000000	diff=5.09466e-13
  0.000000	  0.000000	diff=1.3815e-12
  0.000000	  0.000000	diff=5.36154e-13
  0.000000	  0.000000	diff=1.36081e-12
 -0.000001	 -0.000001	diff=2.15745e-11
 -0.000001	 -0.000001	diff=7.26449e-12
  0.000000	  0.000000	diff=5.92344e-13
 -0.000000	 -0.000000	diff=2.88977e-13
 -0.000000	 -0.000000	diff=1.00583e-12
 -0.000000	 -0.000000	diff=2.4735e-12
 -0.000000	 -0.000000	diff=1.16995e-12
 -0.000000	 -0.000000	diff=1.20169e-14
  0.000001	  0.000001	diff=1.29268e-11
 -0.000004	 -0.000004	diff=1.03891e-10
  0.000000	  0.000000	diff=9.32292e-15
  0.000000	  0.000000	diff=5.85216e-14
  0.000000	 -0.000000	diff=3.84145e-15
  0.000000	 -0.000000	diff=1.23884e-14
  0.000000	 -0.000000	diff=3.89501e-16
  0.000000	  0.000000	diff=7.07818e-14
  0.000000	  0.000000	diff=8.39126e-13
 -0.000000	 -0.000000	diff=1.36343e-13
  0.000000	 -0.000000	diff=1.11938e-14
 -0.000000	  0.000000	diff=7.72808e-13
  0.000000	 -0.000000	diff=1.26599e-14
  0.000000	  0.000000	diff=2.31855e-14
  0.000000	 -0.000000	diff=2.08235e-14
 -0.000000	  0.000000	diff=7.92688e-13
  0.000000	  0.000000	diff=1.06685e-12
  0.000000	  0.000000	diff=6.5568e-13
 -0.000000	 -0.000000	diff=9.95874e-13
  0.000000	  0.000000	diff=1.79201e-12
 -0.000000	 -0.000000	diff=1.16435e-12
 -0.000000	 -0.000000	diff=5.33118e-13
 -0.000000	 -0.000000	diff=9.569e-13
 -0.000000	 -0.000000	diff=1.4488e-12
  0.000000	  0.000000	diff=1.36188e-11
 -0.000000	 -0.000000	diff=3.56121e-12
 -0.000000	 -0.000000	diff=1.7694e-13
 -0.000000	 -0.000000	diff=5.98472e-13
 -0.000000	 -0.000000	diff=1.09665e-12
  0.000000	  0.000000	diff=4.24458e-13
 -0.000000	 -0.000000	diff=8.43067e-13
  0.000000	  0.000000	diff=1.0166e-12
  0.000000	  0.000000	diff=3.23455e-13
  0.000000	  0.000000	diff=2.92974e-10
  local_diff=4.82037e-10
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=6.18776e-13
 -0.000000	 -0.000000	diff=3.30077e-14
 -0.000000	 -0.000000	diff=7.05668e-13
  0.000000	  0.000000	diff=7.71524e-13
  0.000000	  0.000000	diff=7.80736e-13
  0.000000	  0.000000	diff=4.36894e-13
  0.000001	  0.000001	diff=3.24602e-13
  0.000023	  0.000023	diff=5.28648e-11
  0.000000	  0.000000	diff=9.56038e-13
 -0.000000	 -0.000000	diff=1.13858e-12
  0.000000	  0.000000	diff=1.35841e-12
 -0.000000	 -0.000000	diff=7.98475e-13
  0.000000	  0.000000	diff=7.96047e-13
 -0.000000	 -0.000000	diff=1.04437e-13
 -0.000000	 -0.000000	diff=1.30589e-12
 -0.000005	 -0.000005	diff=6.19468e-12
  0.000000	  0.000000	diff=4.85992e-14
 -0.000000	 -0.000000	diff=1.31262e-12
 -0.000000	 -0.000000	diff=1.0016e-14
  0.000000	  0.000000	diff=1.41233e-12
 -0.000000	 -0.000000	diff=7.65954e-13
  0.000000	  0.000000	diff=9.73254e-13
  0.000000	  0.000000	diff=5.72141e-12
  0.000000	  0.000000	diff=1.99763e-12
 -0.000000	 -0.000000	diff=3.31356e-13
  0.000000	  0.000000	diff=1.60471e-12
  0.000000	  0.000000	diff=9.99296e-14
 -0.000000	 -0.000000	diff=1.01011e-12
  0.000000	  0.000000	diff=5.20959e-13
 -0.000000	 -0.000000	diff=5.76106e-13
 -0.000000	 -0.000000	diff=1.00572e-12
 -0.000000	 -0.000000	diff=3.68421e-10
  local_diff=4.55e-10
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=2.34435e-11
 -0.000002	 -0.000002	diff=1.17441e-09
  0.000001	  0.000001	diff=3.58418e-10
 -0.000001	 -0.000001	diff=3.33005e-10
  local_diff=1.88927e-09
# W_emb_tgt, [2 4]
 -0.000004	 -0.000004	diff=3.22593e-10
  0.000001	  0.000001	diff=4.44259e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000004	  0.000004	diff=2.42964e-11
 -0.000000	 -0.000000	diff=7.39318e-11
  0.000001	  0.000001	diff=2.56749e-10
  0.000000	  0.000000	diff=8.1195e-11
  local_diff=1.20302e-09
# W_h, [2 4]
  0.000002	  0.000002	diff=6.76625e-13
  0.000023	  0.000023	diff=3.14575e-13
 -0.000002	 -0.000002	diff=8.53697e-13
 -0.000028	 -0.000028	diff=9.63442e-13
  0.000011	  0.000011	diff=1.0638e-11
 -0.000010	 -0.000010	diff=2.21396e-12
  0.000008	  0.000008	diff=6.88272e-11
 -0.000018	 -0.000018	diff=7.76076e-11
  local_diff=1.62095e-10
# W_soft, [4 2]
  0.000010	  0.000010	diff=6.76735e-13
 -0.000008	 -0.000008	diff=2.35916e-13
  0.000002	  0.000002	diff=9.52099e-13
 -0.000004	 -0.000004	diff=7.3871e-13
  0.000002	  0.000002	diff=4.29033e-13
 -0.000007	 -0.000007	diff=4.2963e-13
  0.000005	  0.000005	diff=1.30932e-12
 -0.000000	 -0.000000	diff=6.7419e-13
  local_diff=5.44563e-12
# Num params=176, abs_diff=4.7867e-09
Elapsed time is 2.513258 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 4
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=2.71687e-13
  0.000000	  0.000000	diff=8.28964e-14
 -0.000000	 -0.000000	diff=1.7857e-13
  0.000000	  0.000000	diff=1.90113e-13
 -0.000000	 -0.000000	diff=6.89225e-14
 -0.000000	 -0.000000	diff=3.57871e-13
  0.000004	  0.000004	diff=1.07605e-11
  0.000003	  0.000003	diff=2.93421e-11
  0.000000	  0.000000	diff=5.04435e-13
 -0.000000	 -0.000000	diff=8.58211e-13
  0.000000	  0.000000	diff=1.39824e-12
 -0.000000	 -0.000000	diff=8.29743e-13
  0.000000	  0.000000	diff=3.15718e-13
  0.000000	  0.000000	diff=6.72157e-13
 -0.000008	 -0.000008	diff=2.33623e-11
 -0.000010	 -0.000010	diff=1.26155e-10
  0.000000	  0.000000	diff=6.78227e-13
 -0.000000	 -0.000000	diff=1.4656e-13
  0.000000	  0.000000	diff=5.10438e-13
 -0.000000	 -0.000000	diff=1.23407e-12
  0.000000	  0.000000	diff=8.56847e-13
  0.000000	  0.000000	diff=4.39557e-13
 -0.000000	 -0.000000	diff=2.07915e-10
 -0.000000	 -0.000000	diff=5.17253e-13
 -0.000000	 -0.000000	diff=7.17614e-13
  0.000000	  0.000000	diff=7.58801e-13
 -0.000000	 -0.000000	diff=6.36763e-13
  0.000000	  0.000000	diff=1.01506e-12
 -0.000000	 -0.000000	diff=1.93524e-13
 -0.000000	 -0.000000	diff=3.61677e-13
  0.000000	  0.000000	diff=8.23499e-13
  0.000000	  0.000000	diff=1.08666e-10
  local_diff=5.2082e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=1.02347e-12
  0.000000	  0.000000	diff=9.18735e-13
  0.000000	  0.000000	diff=2.30604e-13
  0.000000	  0.000000	diff=2.9795e-13
  0.000000	  0.000000	diff=9.87274e-13
 -0.000000	 -0.000000	diff=7.04221e-13
 -0.000006	 -0.000006	diff=2.10753e-12
  0.000003	  0.000003	diff=3.81267e-12
 -0.000000	 -0.000000	diff=5.63104e-14
 -0.000000	 -0.000000	diff=3.55146e-13
 -0.000000	 -0.000000	diff=3.27472e-13
 -0.000000	 -0.000000	diff=7.98446e-13
 -0.000000	 -0.000000	diff=1.22075e-12
  0.000000	  0.000000	diff=1.3376e-12
  0.000005	  0.000005	diff=1.24932e-12
 -0.000006	 -0.000006	diff=4.86803e-12
  0.000000	  0.000000	diff=3.39893e-13
  0.000000	  0.000000	diff=5.03933e-13
  0.000000	  0.000000	diff=3.75673e-13
  0.000000	  0.000000	diff=5.35814e-14
  0.000000	  0.000000	diff=6.8374e-13
 -0.000000	 -0.000000	diff=5.44613e-13
 -0.000000	 -0.000000	diff=7.73482e-11
  0.000000	  0.000000	diff=4.1021e-13
 -0.000000	 -0.000000	diff=2.98706e-13
 -0.000000	 -0.000000	diff=1.58369e-13
 -0.000000	 -0.000000	diff=2.97308e-14
 -0.000000	 -0.000000	diff=1.61023e-13
 -0.000000	 -0.000000	diff=1.15282e-13
  0.000000	  0.000000	diff=3.35517e-13
  0.000000	  0.000000	diff=3.19622e-13
 -0.000000	 -0.000000	diff=2.45057e-10
  local_diff=3.47031e-10
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=5.03167e-13
 -0.000000	 -0.000000	diff=5.74068e-13
  0.000000	  0.000000	diff=2.455e-12
 -0.000000	 -0.000000	diff=1.20897e-12
  0.000000	  0.000000	diff=9.82009e-14
 -0.000000	 -0.000000	diff=9.87182e-14
 -0.000007	 -0.000007	diff=1.22237e-10
  0.000032	  0.000032	diff=2.39761e-10
  0.000000	  0.000000	diff=3.2665e-13
  0.000000	  0.000000	diff=3.49818e-13
 -0.000000	 -0.000000	diff=1.13498e-12
 -0.000000	 -0.000000	diff=2.27461e-12
  0.000000	  0.000000	diff=1.49257e-12
  0.000000	  0.000000	diff=2.8442e-13
  0.000004	  0.000004	diff=3.88136e-11
 -0.000031	 -0.000031	diff=3.71834e-10
 -0.000000	 -0.000000	diff=1.04728e-12
  0.000000	  0.000000	diff=7.14618e-13
 -0.000000	 -0.000000	diff=1.14585e-12
  0.000000	  0.000000	diff=9.14845e-14
 -0.000000	 -0.000000	diff=9.37029e-13
  0.000000	  0.000000	diff=5.66958e-13
  0.000000	  0.000000	diff=1.33375e-13
 -0.000000	 -0.000000	diff=4.97554e-14
  0.000000	  0.000000	diff=3.71943e-13
 -0.000000	 -0.000000	diff=8.14965e-13
 -0.000000	  0.000000	diff=1.62818e-12
 -0.000000	 -0.000000	diff=1.04998e-12
  0.000000	  0.000000	diff=4.93835e-13
 -0.000000	 -0.000000	diff=9.78392e-13
 -0.000000	 -0.000000	diff=6.6155e-13
  0.000000	  0.000000	diff=1.07926e-12
 -0.000000	 -0.000000	diff=1.89555e-13
  0.000000	  0.000000	diff=4.25635e-13
 -0.000000	 -0.000000	diff=2.53682e-13
 -0.000000	 -0.000000	diff=1.61235e-13
 -0.000000	 -0.000000	diff=5.27782e-14
  0.000000	  0.000000	diff=2.48394e-13
  0.000000	  0.000000	diff=5.81092e-10
 -0.000001	 -0.000001	diff=2.48722e-11
 -0.000000	 -0.000000	diff=6.65829e-14
  0.000000	  0.000000	diff=6.93715e-13
  0.000000	  0.000000	diff=7.15414e-14
  0.000000	  0.000000	diff=9.46472e-13
 -0.000000	 -0.000000	diff=4.11023e-13
  0.000000	  0.000000	diff=3.49565e-13
 -0.000000	 -0.000000	diff=5.31746e-12
  0.000000	  0.000000	diff=7.79432e-10
  local_diff=2.18979e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=1.09465e-12
  0.000000	  0.000000	diff=8.29531e-13
  0.000000	  0.000000	diff=3.57942e-13
  0.000000	  0.000000	diff=7.25626e-13
 -0.000000	 -0.000000	diff=3.35214e-13
  0.000000	  0.000000	diff=3.91768e-13
 -0.000014	 -0.000014	diff=5.96309e-12
  0.000019	  0.000019	diff=2.20487e-11
 -0.000000	 -0.000000	diff=2.22214e-13
  0.000000	  0.000000	diff=8.71873e-14
 -0.000000	 -0.000000	diff=5.05379e-14
  0.000000	  0.000000	diff=2.12022e-14
 -0.000000	 -0.000000	diff=4.02202e-13
  0.000000	  0.000000	diff=2.03783e-14
 -0.000018	 -0.000018	diff=4.47466e-11
  0.000021	  0.000021	diff=7.15971e-11
 -0.000000	 -0.000000	diff=5.55991e-13
 -0.000000	 -0.000000	diff=2.31795e-13
  0.000000	  0.000000	diff=5.1202e-13
  0.000000	  0.000000	diff=1.36825e-12
  0.000000	  0.000000	diff=5.01908e-13
  0.000000	  0.000000	diff=7.04833e-13
 -0.000000	 -0.000000	diff=8.09976e-10
  0.000000	  0.000000	diff=2.16895e-11
  0.000000	  0.000000	diff=2.93865e-13
 -0.000000	 -0.000000	diff=7.35344e-13
 -0.000000	 -0.000000	diff=1.16281e-12
 -0.000000	 -0.000000	diff=3.36868e-13
  0.000000	  0.000000	diff=4.6684e-13
 -0.000000	 -0.000000	diff=5.03331e-13
  0.000001	  0.000001	diff=3.81398e-12
 -0.000001	 -0.000001	diff=1.90861e-09
  local_diff=2.90036e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000005	 -0.000005	diff=1.70782e-09
 -0.000001	 -0.000001	diff=5.15328e-10
 -0.000003	 -0.000003	diff=1.28676e-09
 -0.000003	 -0.000003	diff=2.31388e-10
  local_diff=3.7413e-09
# W_emb_tgt, [2 4]
 -0.000016	 -0.000016	diff=4.41144e-09
  0.000002	  0.000002	diff=1.08393e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000014	 -0.000014	diff=5.36535e-09
  0.000002	  0.000002	diff=1.10428e-09
 -0.000005	 -0.000005	diff=2.92347e-09
  0.000002	  0.000002	diff=1.17225e-09
  local_diff=1.60607e-08
# W_pos, [2 2]
  0.000000	  0.000000	diff=3.99914e-15
  0.000000	  0.000000	diff=5.06273e-15
  0.000000	 -0.000000	diff=1.24126e-14
  0.000000	 -0.000000	diff=1.57138e-14
  local_diff=3.71882e-14
# v_pos, [1 2]
 -0.000000	  0.000000	diff=1.49251e-12
  0.000000	  0.000000	diff=2.52354e-13
  local_diff=1.74486e-12
# W_h, [2 4]
 -0.000009	 -0.000009	diff=2.12962e-13
  0.000006	  0.000006	diff=2.9753e-13
  0.000011	  0.000011	diff=3.7415e-13
 -0.000008	 -0.000008	diff=1.09474e-14
  0.000005	  0.000005	diff=3.55734e-12
  0.000000	  0.000000	diff=1.56363e-12
  0.000032	  0.000032	diff=1.59095e-10
 -0.000018	 -0.000018	diff=4.4842e-11
  local_diff=2.09954e-10
# W_soft, [4 2]
 -0.000017	 -0.000017	diff=5.5238e-13
 -0.000002	 -0.000002	diff=3.83745e-13
  0.000013	  0.000013	diff=2.08119e-14
  0.000005	  0.000005	diff=2.0477e-13
  0.000034	  0.000034	diff=1.38478e-13
 -0.000021	 -0.000021	diff=2.47524e-13
 -0.000013	 -0.000013	diff=3.38367e-13
  0.000001	  0.000001	diff=1.38259e-14
  local_diff=1.8999e-12
# Num params=182, abs_diff=2.59737e-08
Elapsed time is 3.134256 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 1
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s> <s> x y
  src mask: 0  0  1  1
  tgt input 1: <s> a </s> </s> </s>
  tgt output 1: a </s> </s> </s> </s>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=7.15497e-13
  0.000000	  0.000000	diff=1.23431e-12
 -0.000000	 -0.000000	diff=5.86063e-13
  0.000000	  0.000000	diff=1.98876e-13
 -0.000000	 -0.000000	diff=1.33938e-12
 -0.000000	 -0.000000	diff=5.19126e-13
  0.000007	  0.000007	diff=3.10466e-11
  0.000002	  0.000002	diff=2.24415e-11
  0.000000	  0.000000	diff=9.69595e-13
 -0.000000	 -0.000000	diff=6.95583e-13
  0.000000	  0.000000	diff=1.27615e-12
 -0.000000	 -0.000000	diff=9.86759e-13
  0.000000	  0.000000	diff=1.14177e-12
  0.000000	  0.000000	diff=6.96363e-13
 -0.000007	 -0.000007	diff=4.28394e-11
 -0.000006	 -0.000006	diff=9.63839e-11
  0.000000	  0.000000	diff=1.04289e-12
 -0.000000	 -0.000000	diff=9.80751e-13
  0.000000	  0.000000	diff=6.99468e-13
 -0.000000	 -0.000000	diff=1.29946e-12
  0.000000	  0.000000	diff=1.02821e-12
  0.000000	  0.000000	diff=5.30759e-13
 -0.000000	 -0.000000	diff=1.58061e-11
 -0.000000	 -0.000000	diff=1.85123e-12
 -0.000000	 -0.000000	diff=1.54009e-12
  0.000000	  0.000000	diff=1.15233e-12
 -0.000000	 -0.000000	diff=1.34923e-12
  0.000000	  0.000000	diff=1.04618e-12
 -0.000000	 -0.000000	diff=1.50836e-12
 -0.000000	 -0.000000	diff=1.49036e-12
  0.000000	  0.000000	diff=1.45484e-12
  0.000000	  0.000000	diff=8.73709e-11
  local_diff=3.23222e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=1.06745e-12
  0.000000	  0.000000	diff=1.65856e-12
 -0.000000	 -0.000000	diff=2.06374e-14
  0.000000	  0.000000	diff=5.17453e-13
  0.000000	  0.000000	diff=9.33436e-13
  0.000000	  0.000000	diff=1.51119e-12
  0.000004	  0.000004	diff=4.6219e-13
  0.000009	  0.000009	diff=1.42127e-12
  0.000000	  0.000000	diff=1.62069e-12
 -0.000000	 -0.000000	diff=6.99373e-13
  0.000000	  0.000000	diff=1.39196e-12
 -0.000000	 -0.000000	diff=1.5112e-12
 -0.000000	 -0.000000	diff=8.90721e-13
 -0.000000	 -0.000000	diff=1.31662e-12
 -0.000007	 -0.000007	diff=8.97335e-13
 -0.000016	 -0.000016	diff=1.4485e-12
 -0.000000	 -0.000000	diff=5.4069e-13
  0.000000	  0.000000	diff=8.68783e-13
 -0.000000	 -0.000000	diff=1.95685e-12
 -0.000000	  0.000000	diff=1.27994e-12
 -0.000000	  0.000000	diff=1.03954e-12
  0.000000	  0.000000	diff=9.34408e-13
  0.000000	  0.000000	diff=2.30868e-11
  0.000000	  0.000000	diff=2.80713e-13
  0.000000	  0.000000	diff=1.19582e-12
 -0.000000	 -0.000000	diff=1.18629e-12
  0.000000	  0.000000	diff=5.67908e-13
 -0.000000	 -0.000000	diff=4.39425e-13
 -0.000000	 -0.000000	diff=1.01533e-12
 -0.000000	 -0.000000	diff=1.48212e-12
 -0.000000	 -0.000000	diff=1.77856e-12
 -0.000000	 -0.000000	diff=3.90921e-11
  local_diff=9.41139e-11
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=9.4306e-13
 -0.000000	 -0.000000	diff=4.20735e-13
 -0.000000	 -0.000000	diff=2.57741e-12
 -0.000000	 -0.000000	diff=1.62176e-12
 -0.000000	 -0.000000	diff=5.93961e-13
 -0.000000	 -0.000000	diff=9.4189e-13
  0.000007	  0.000007	diff=1.62902e-10
  0.000064	  0.000064	diff=1.69202e-10
 -0.000000	 -0.000000	diff=5.09627e-14
  0.000000	  0.000000	diff=2.09573e-13
  0.000000	  0.000000	diff=7.26606e-13
 -0.000000	 -0.000000	diff=3.67989e-12
  0.000000	  0.000000	diff=5.78519e-13
  0.000000	  0.000000	diff=6.18261e-13
 -0.000004	 -0.000004	diff=5.66112e-11
 -0.000036	 -0.000036	diff=2.7279e-10
 -0.000000	 -0.000000	diff=7.42885e-13
 -0.000000	 -0.000000	diff=1.87366e-12
 -0.000000	 -0.000000	diff=1.17378e-12
 -0.000000	 -0.000000	diff=7.91955e-14
 -0.000000	 -0.000000	diff=1.05104e-12
 -0.000000	 -0.000000	diff=9.12185e-13
  0.000000	  0.000000	diff=5.50696e-13
  0.000000	  0.000000	diff=1.06176e-12
 -0.000000	 -0.000000	diff=5.97458e-13
 -0.000000	 -0.000000	diff=4.20832e-13
 -0.000000	 -0.000000	diff=9.09712e-13
 -0.000000	 -0.000000	diff=9.21292e-13
 -0.000000	 -0.000000	diff=4.40944e-13
 -0.000000	 -0.000000	diff=1.26611e-12
  0.000000	  0.000000	diff=7.72589e-13
  0.000000	  0.000000	diff=1.74732e-12
  0.000000	  0.000000	diff=6.67271e-13
  0.000000	  0.000000	diff=1.37855e-12
  0.000000	  0.000000	diff=8.54784e-13
  0.000000	  0.000000	diff=8.62058e-13
  0.000000	  0.000000	diff=8.90355e-13
  0.000000	  0.000000	diff=1.04865e-12
 -0.000000	 -0.000000	diff=3.6321e-10
 -0.000001	 -0.000001	diff=6.29924e-11
  0.000000	  0.000000	diff=1.30645e-12
  0.000000	  0.000000	diff=6.51781e-13
 -0.000000	 -0.000000	diff=1.07332e-12
  0.000000	  0.000000	diff=1.01868e-12
  0.000000	  0.000000	diff=9.59913e-13
  0.000000	  0.000000	diff=1.05668e-12
  0.000000	  0.000000	diff=2.17298e-12
 -0.000000	 -0.000000	diff=5.40922e-10
  local_diff=1.67005e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=4.48074e-13
  0.000000	  0.000000	diff=1.52384e-12
 -0.000000	 -0.000000	diff=1.26242e-12
  0.000000	  0.000000	diff=8.07016e-13
  0.000000	  0.000000	diff=7.22119e-13
  0.000000	  0.000000	diff=9.92003e-13
  0.000015	  0.000015	diff=5.72954e-12
  0.000024	  0.000024	diff=4.50916e-11
  0.000000	  0.000000	diff=5.52091e-13
  0.000000	  0.000000	diff=7.405e-13
  0.000000	  0.000000	diff=9.29764e-13
  0.000000	  0.000000	diff=5.0225e-13
  0.000000	  0.000000	diff=2.00143e-12
  0.000000	  0.000000	diff=1.36181e-12
  0.000024	  0.000024	diff=4.52494e-12
  0.000046	  0.000046	diff=2.54487e-10
  0.000000	  0.000000	diff=9.30304e-13
 -0.000000	 -0.000000	diff=1.54464e-12
 -0.000000	 -0.000000	diff=9.61493e-14
 -0.000000	 -0.000000	diff=1.05703e-12
 -0.000000	 -0.000000	diff=4.79365e-13
 -0.000000	 -0.000000	diff=9.13034e-13
  0.000000	  0.000000	diff=6.50087e-10
  0.000000	  0.000000	diff=2.5456e-11
 -0.000000	 -0.000000	diff=6.14798e-13
 -0.000000	 -0.000000	diff=6.37568e-13
  0.000000	  0.000000	diff=5.85145e-13
 -0.000000	 -0.000000	diff=3.27704e-13
 -0.000000	 -0.000000	diff=6.06951e-13
 -0.000000	 -0.000000	diff=1.30043e-12
 -0.000001	 -0.000001	diff=1.44951e-12
 -0.000001	 -0.000001	diff=2.95349e-09
  local_diff=3.96125e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000006	 -0.000006	diff=2.90495e-09
  0.000004	  0.000004	diff=3.39998e-09
 -0.000004	 -0.000004	diff=2.02112e-09
 -0.000002	 -0.000002	diff=1.11277e-09
  local_diff=9.43881e-09
# W_emb_tgt, [2 4]
 -0.000027	 -0.000027	diff=2.64457e-09
 -0.000001	 -0.000001	diff=1.2386e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000037	 -0.000037	diff=8.67756e-09
  0.000000	  0.000000	diff=6.05625e-10
 -0.000024	 -0.000024	diff=1.27183e-09
 -0.000000	 -0.000000	diff=7.30178e-10
  local_diff=1.51684e-08
# W_a, [2 2]
  0.000000	  0.000000	diff=1.04519e-15
  0.000000	 -0.000000	diff=1.27218e-15
  0.000000	  0.000000	diff=8.32883e-16
  0.000000	 -0.000000	diff=1.03476e-15
  local_diff=4.18501e-15
# W_h, [2 4]
  0.000026	  0.000026	diff=1.29117e-12
 -0.000018	 -0.000018	diff=1.33861e-12
 -0.000036	 -0.000036	diff=7.44123e-13
  0.000025	  0.000025	diff=1.20443e-13
 -0.000015	 -0.000015	diff=4.89753e-12
 -0.000003	 -0.000003	diff=4.94468e-12
 -0.000069	 -0.000069	diff=4.91035e-10
  0.000023	  0.000023	diff=2.51736e-12
  local_diff=5.06889e-10
# W_soft, [4 2]
  0.000062	  0.000062	diff=1.3487e-12
 -0.000030	 -0.000030	diff=1.38333e-12
 -0.000034	 -0.000034	diff=1.49799e-12
  0.000002	  0.000002	diff=2.16486e-12
  0.000023	  0.000023	diff=6.7947e-13
 -0.000003	 -0.000003	diff=3.5828e-13
 -0.000016	 -0.000016	diff=1.19813e-12
 -0.000005	 -0.000005	diff=1.31683e-12
  local_diff=9.9476e-12
# Num params=180, abs_diff=3.11727e-08
Elapsed time is 2.409768 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 2, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 2
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s> <s> x y
  src mask: 0  0  1  1
  tgt input 1: <s> a </s> </s> </s>
  tgt output 1: a </s> </s> </s> </s>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=9.72413e-14
  0.000000	  0.000000	diff=1.15009e-13
  0.000000	  0.000000	diff=1.10573e-12
  0.000000	  0.000000	diff=3.42578e-13
 -0.000000	 -0.000000	diff=6.53281e-13
 -0.000000	 -0.000000	diff=1.67805e-13
  0.000005	  0.000005	diff=2.07117e-11
  0.000002	  0.000002	diff=2.52482e-11
  0.000000	  0.000000	diff=2.63503e-13
 -0.000000	 -0.000000	diff=4.6752e-13
 -0.000000	 -0.000000	diff=6.71263e-15
 -0.000000	 -0.000000	diff=1.42783e-12
  0.000000	  0.000000	diff=1.06158e-12
  0.000000	  0.000000	diff=3.54695e-13
 -0.000005	 -0.000005	diff=2.89537e-11
 -0.000007	 -0.000007	diff=1.03535e-10
 -0.000000	 -0.000000	diff=5.02891e-14
 -0.000000	 -0.000000	diff=6.32724e-13
 -0.000000	 -0.000000	diff=7.18996e-13
 -0.000000	 -0.000000	diff=4.08329e-13
 -0.000000	 -0.000000	diff=1.67195e-13
  0.000000	  0.000000	diff=6.23693e-13
 -0.000000	 -0.000000	diff=1.16645e-11
 -0.000000	 -0.000000	diff=1.18003e-14
  0.000000	  0.000000	diff=5.28442e-13
  0.000000	  0.000000	diff=7.66118e-13
  0.000000	  0.000000	diff=5.03172e-14
  0.000000	  0.000000	diff=8.00686e-13
  0.000000	  0.000000	diff=1.03165e-15
 -0.000000	 -0.000000	diff=4.38287e-13
 -0.000000	 -0.000000	diff=1.95881e-13
  0.000000	  0.000000	diff=1.41895e-10
  local_diff=3.43465e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=1.13934e-12
  0.000000	  0.000000	diff=4.25476e-13
 -0.000000	 -0.000000	diff=4.41644e-14
 -0.000000	 -0.000000	diff=3.77204e-13
  0.000000	  0.000000	diff=7.38561e-13
  0.000000	  0.000000	diff=7.22774e-14
  0.000004	  0.000004	diff=1.85882e-12
  0.000007	  0.000007	diff=2.92232e-13
  0.000000	  0.000000	diff=5.79613e-13
 -0.000000	 -0.000000	diff=1.03607e-12
  0.000000	  0.000000	diff=7.12232e-13
  0.000000	  0.000000	diff=3.06438e-13
 -0.000000	 -0.000000	diff=4.90761e-14
 -0.000000	 -0.000000	diff=2.50542e-13
 -0.000007	 -0.000007	diff=3.1155e-12
 -0.000013	 -0.000013	diff=1.71777e-12
 -0.000000	 -0.000000	diff=9.3792e-15
 -0.000000	 -0.000000	diff=1.08057e-13
 -0.000000	 -0.000000	diff=1.02695e-13
 -0.000000	 -0.000000	diff=1.70174e-13
  0.000000	  0.000000	diff=1.5391e-13
 -0.000000	 -0.000000	diff=1.47483e-12
  0.000000	  0.000000	diff=2.32233e-11
  0.000000	  0.000000	diff=9.46921e-13
  0.000000	  0.000000	diff=9.74034e-13
  0.000000	  0.000000	diff=1.02999e-13
  0.000000	  0.000000	diff=9.43817e-13
  0.000000	  0.000000	diff=9.11628e-14
 -0.000000	 -0.000000	diff=2.35102e-14
  0.000000	  0.000000	diff=4.23845e-13
 -0.000000	 -0.000000	diff=2.48701e-13
 -0.000000	 -0.000000	diff=4.41025e-11
  local_diff=8.58151e-11
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=5.04231e-13
 -0.000000	 -0.000000	diff=1.72037e-12
 -0.000000	 -0.000000	diff=2.55622e-12
 -0.000000	 -0.000000	diff=5.86692e-13
 -0.000000	 -0.000000	diff=1.39075e-13
 -0.000000	 -0.000000	diff=1.13512e-12
  0.000007	  0.000007	diff=1.62352e-10
  0.000064	  0.000064	diff=1.7138e-10
 -0.000000	 -0.000000	diff=7.48683e-14
  0.000000	  0.000000	diff=1.02724e-12
  0.000000	  0.000000	diff=3.00996e-14
 -0.000000	 -0.000000	diff=4.48604e-12
  0.000000	  0.000000	diff=5.73323e-13
  0.000000	  0.000000	diff=1.84129e-13
 -0.000004	 -0.000004	diff=5.51789e-11
 -0.000036	 -0.000036	diff=2.72886e-10
 -0.000000	 -0.000000	diff=3.76325e-14
 -0.000000	 -0.000000	diff=5.10561e-13
  0.000000	 -0.000000	diff=9.73806e-13
 -0.000000	 -0.000000	diff=2.32378e-13
 -0.000000	 -0.000000	diff=3.96578e-13
 -0.000000	 -0.000000	diff=9.39364e-14
  0.000000	  0.000000	diff=7.58511e-13
  0.000000	  0.000000	diff=6.41601e-13
 -0.000000	 -0.000000	diff=5.33736e-13
 -0.000000	 -0.000000	diff=4.73949e-13
  0.000000	 -0.000000	diff=5.26041e-13
 -0.000000	 -0.000000	diff=1.32477e-13
 -0.000000	 -0.000000	diff=2.93316e-13
 -0.000000	 -0.000000	diff=4.83632e-13
  0.000000	  0.000000	diff=4.10012e-13
  0.000000	  0.000000	diff=2.47235e-13
  0.000000	  0.000000	diff=4.25127e-14
  0.000000	  0.000000	diff=5.55249e-14
  0.000000	  0.000000	diff=5.64746e-13
  0.000000	  0.000000	diff=1.26096e-12
  0.000000	  0.000000	diff=1.81144e-13
  0.000000	  0.000000	diff=3.21937e-13
 -0.000000	 -0.000000	diff=3.61532e-10
 -0.000001	 -0.000001	diff=6.44567e-11
  0.000000	  0.000000	diff=1.133e-13
  0.000000	  0.000000	diff=7.92137e-14
 -0.000000	 -0.000000	diff=3.66487e-13
  0.000000	  0.000000	diff=3.92571e-13
  0.000000	  0.000000	diff=2.52716e-13
  0.000000	  0.000000	diff=3.88587e-13
  0.000000	  0.000000	diff=3.23862e-12
 -0.000000	 -0.000000	diff=5.4137e-10
  local_diff=1.65618e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=2.61147e-13
  0.000000	  0.000000	diff=8.00279e-13
 -0.000000	 -0.000000	diff=1.59097e-13
  0.000000	  0.000000	diff=1.0207e-13
  0.000000	  0.000000	diff=1.07961e-14
  0.000000	  0.000000	diff=4.40095e-13
  0.000015	  0.000015	diff=6.86927e-12
  0.000024	  0.000024	diff=4.3329e-11
  0.000000	  0.000000	diff=1.56138e-13
  0.000000	  0.000000	diff=6.32378e-15
  0.000000	  0.000000	diff=2.12255e-13
  0.000000	  0.000000	diff=2.12455e-13
  0.000000	  0.000000	diff=1.37478e-13
  0.000000	  0.000000	diff=8.17193e-13
  0.000024	  0.000024	diff=4.20835e-12
  0.000046	  0.000046	diff=2.52319e-10
  0.000000	  0.000000	diff=4.90733e-13
 -0.000000	 -0.000000	diff=1.24278e-13
 -0.000000	 -0.000000	diff=6.14423e-13
 -0.000000	 -0.000000	diff=1.0747e-12
 -0.000000	 -0.000000	diff=2.31137e-13
 -0.000000	 -0.000000	diff=5.07287e-13
  0.000000	  0.000000	diff=6.51303e-10
  0.000000	  0.000000	diff=2.36151e-11
 -0.000000	 -0.000000	diff=9.59285e-14
 -0.000000	 -0.000000	diff=7.83323e-13
  0.000000	  0.000000	diff=1.25518e-13
 -0.000000	 -0.000000	diff=3.83333e-13
 -0.000000	 -0.000000	diff=1.03759e-13
 -0.000000	 -0.000000	diff=1.20229e-13
 -0.000001	 -0.000001	diff=3.37866e-12
 -0.000001	 -0.000001	diff=2.95262e-09
  local_diff=3.94561e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000006	 -0.000006	diff=2.89927e-09
  0.000002	  0.000002	diff=2.30418e-09
 -0.000003	 -0.000003	diff=1.42498e-09
 -0.000004	 -0.000004	diff=3.08329e-09
  local_diff=9.71172e-09
# W_emb_tgt, [2 4]
 -0.000027	 -0.000027	diff=2.64193e-09
 -0.000001	 -0.000001	diff=1.23719e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000037	 -0.000037	diff=8.67594e-09
  0.000000	  0.000000	diff=6.0449e-10
 -0.000024	 -0.000024	diff=1.27152e-09
 -0.000000	 -0.000000	diff=7.28786e-10
  local_diff=1.51599e-08
# W_a, [2 2]
  0.000000	  0.000000	diff=5.30534e-16
  0.000000	 -0.000000	diff=6.47668e-16
  0.000000	  0.000000	diff=7.92437e-16
  0.000000	 -0.000000	diff=9.79503e-16
  local_diff=2.95014e-15
# W_h, [2 4]
  0.000024	  0.000024	diff=6.3531e-13
 -0.000018	 -0.000018	diff=5.27107e-13
 -0.000033	 -0.000033	diff=1.49603e-12
  0.000026	  0.000026	diff=1.54116e-12
 -0.000015	 -0.000015	diff=3.58529e-12
 -0.000003	 -0.000003	diff=3.8745e-12
 -0.000069	 -0.000069	diff=4.90543e-10
  0.000023	  0.000023	diff=3.37539e-12
  local_diff=5.05578e-10
# W_soft, [4 2]
  0.000061	  0.000061	diff=2.71542e-12
 -0.000028	 -0.000028	diff=1.84409e-12
 -0.000033	 -0.000033	diff=2.16887e-12
  0.000000	  0.000000	diff=2.50868e-12
  0.000023	  0.000023	diff=8.20287e-14
 -0.000001	 -0.000001	diff=6.18686e-13
 -0.000015	 -0.000015	diff=6.19599e-13
 -0.000007	 -0.000007	diff=8.11315e-13
  local_diff=1.13687e-11
# Num params=180, abs_diff=3.14196e-08
Elapsed time is 3.361492 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 186, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_a=4 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 4
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 186
  src input 1: <s> <s> <s> x
  src mask: 0  0  0  1
  tgt input 1: <s> b a </s> </s>
  tgt output 1: b a </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=7.49632e-14
  0.000000	  0.000000	diff=1.06914e-12
  0.000000	  0.000000	diff=2.68773e-13
  0.000000	  0.000000	diff=5.87417e-14
  0.000000	  0.000000	diff=5.11404e-13
  0.000000	  0.000000	diff=4.01231e-14
 -0.000016	 -0.000016	diff=6.43114e-11
  0.000003	  0.000003	diff=1.8695e-11
 -0.000000	 -0.000000	diff=7.06735e-13
 -0.000000	 -0.000000	diff=3.79144e-13
 -0.000000	 -0.000000	diff=8.99085e-13
 -0.000000	 -0.000000	diff=5.00883e-13
 -0.000000	 -0.000000	diff=4.28678e-13
 -0.000000	 -0.000000	diff=5.90242e-13
  0.000025	  0.000025	diff=1.60339e-10
 -0.000011	 -0.000011	diff=8.93193e-11
 -0.000000	 -0.000000	diff=3.13067e-13
 -0.000000	 -0.000000	diff=5.407e-13
 -0.000000	 -0.000000	diff=4.21995e-13
 -0.000000	 -0.000000	diff=6.17944e-13
 -0.000000	 -0.000000	diff=2.9932e-13
 -0.000000	 -0.000000	diff=7.77501e-13
  0.000000	  0.000000	diff=9.37199e-11
 -0.000000	 -0.000000	diff=5.50664e-13
  0.000000	  0.000000	diff=2.42123e-14
  0.000000	  0.000000	diff=3.64374e-13
  0.000000	  0.000000	diff=7.00854e-13
  0.000000	  0.000000	diff=1.00088e-12
  0.000000	  0.000000	diff=5.30452e-13
  0.000000	  0.000000	diff=6.76457e-13
 -0.000000	 -0.000000	diff=2.88092e-13
  0.000000	  0.000000	diff=1.21673e-11
  local_diff=4.51186e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=7.60221e-13
 -0.000000	 -0.000000	diff=4.9071e-14
 -0.000000	 -0.000000	diff=1.49271e-13
 -0.000000	 -0.000000	diff=5.66233e-13
 -0.000000	 -0.000000	diff=9.06105e-14
 -0.000000	 -0.000000	diff=2.99922e-13
  0.000004	  0.000004	diff=6.9018e-13
 -0.000021	 -0.000021	diff=3.04504e-13
  0.000000	  0.000000	diff=6.15422e-14
  0.000000	  0.000000	diff=5.44366e-13
  0.000000	  0.000000	diff=5.00474e-13
  0.000000	  0.000000	diff=1.8366e-13
  0.000000	  0.000000	diff=8.93935e-13
  0.000000	  0.000000	diff=2.29105e-13
 -0.000009	 -0.000009	diff=6.74594e-13
  0.000028	  0.000028	diff=4.53604e-13
 -0.000000	 -0.000000	diff=6.24524e-13
 -0.000000	 -0.000000	diff=8.47645e-13
 -0.000000	 -0.000000	diff=8.76316e-13
 -0.000000	 -0.000000	diff=5.56024e-13
 -0.000000	 -0.000000	diff=2.41605e-13
 -0.000000	 -0.000000	diff=7.68132e-13
  0.000000	  0.000000	diff=9.01528e-11
 -0.000000	 -0.000000	diff=6.3442e-13
  0.000000	  0.000000	diff=5.50743e-13
  0.000000	  0.000000	diff=1.98539e-13
  0.000000	  0.000000	diff=1.29866e-13
  0.000000	  0.000000	diff=4.16492e-14
  0.000000	  0.000000	diff=1.15472e-12
  0.000000	  0.000000	diff=5.08326e-13
 -0.000000	 -0.000000	diff=8.60329e-13
  0.000000	  0.000000	diff=6.27624e-11
  local_diff=1.67359e-10
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=8.33691e-13
  0.000000	  0.000000	diff=1.58051e-13
 -0.000000	 -0.000000	diff=2.5124e-13
  0.000000	  0.000000	diff=1.91276e-14
 -0.000000	 -0.000000	diff=4.82648e-14
  0.000000	  0.000000	diff=5.83626e-13
  0.000001	  0.000001	diff=2.51605e-12
 -0.000009	 -0.000009	diff=4.15731e-11
 -0.000000	 -0.000000	diff=4.11586e-13
 -0.000000	 -0.000000	diff=2.85119e-13
 -0.000000	 -0.000000	diff=1.4263e-12
 -0.000000	 -0.000000	diff=1.00797e-12
 -0.000000	 -0.000000	diff=9.5137e-13
 -0.000000	 -0.000000	diff=3.95721e-13
  0.000001	  0.000001	diff=4.2096e-11
  0.000007	  0.000007	diff=8.89194e-11
  0.000000	  0.000000	diff=7.05071e-13
  0.000000	 -0.000000	diff=2.41402e-13
  0.000000	  0.000000	diff=7.09905e-13
  0.000000	  0.000000	diff=1.52094e-13
  0.000000	 -0.000000	diff=7.23625e-13
  0.000000	  0.000000	diff=6.96398e-13
 -0.000000	 -0.000000	diff=5.19482e-13
  0.000000	  0.000000	diff=1.54301e-13
  0.000000	  0.000000	diff=6.76052e-13
  0.000000	  0.000000	diff=4.79259e-13
  0.000000	  0.000000	diff=4.40739e-14
  0.000000	  0.000000	diff=1.0776e-12
  0.000000	  0.000000	diff=6.3904e-13
  0.000000	  0.000000	diff=4.02024e-13
 -0.000000	 -0.000000	diff=1.14481e-13
 -0.000000	 -0.000000	diff=1.08589e-13
  0.000000	  0.000000	diff=3.68773e-13
 -0.000000	 -0.000000	diff=8.41321e-13
  0.000000	  0.000000	diff=4.90544e-13
 -0.000000	 -0.000000	diff=1.10391e-12
  0.000000	  0.000000	diff=2.31735e-13
 -0.000000	 -0.000000	diff=4.17725e-13
 -0.000000	 -0.000000	diff=1.21048e-10
  0.000000	  0.000000	diff=8.11253e-12
  0.000000	  0.000000	diff=6.80448e-13
 -0.000000	 -0.000000	diff=5.58061e-13
 -0.000000	 -0.000000	diff=1.3767e-13
 -0.000000	 -0.000000	diff=4.26863e-13
  0.000000	  0.000000	diff=1.34821e-12
 -0.000000	 -0.000000	diff=8.81411e-13
  0.000000	  0.000000	diff=1.82265e-12
  0.000000	  0.000000	diff=1.89854e-10
  local_diff=5.17243e-10
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=6.30588e-13
 -0.000000	 -0.000000	diff=7.87059e-13
 -0.000000	 -0.000000	diff=2.44135e-13
 -0.000000	 -0.000000	diff=5.89238e-13
  0.000000	  0.000000	diff=4.92036e-13
 -0.000000	 -0.000000	diff=2.61486e-13
  0.000004	  0.000004	diff=2.65625e-12
 -0.000006	 -0.000006	diff=8.75563e-12
  0.000000	  0.000000	diff=1.0375e-13
 -0.000000	 -0.000000	diff=4.5547e-13
  0.000000	  0.000000	diff=9.73974e-14
 -0.000000	 -0.000000	diff=5.3061e-13
  0.000000	  0.000000	diff=5.74224e-13
 -0.000000	 -0.000000	diff=3.86312e-13
  0.000004	  0.000004	diff=2.37736e-11
 -0.000007	 -0.000007	diff=2.10834e-11
  0.000000	  0.000000	diff=3.04935e-13
  0.000000	  0.000000	diff=6.85082e-13
 -0.000000	 -0.000000	diff=7.75202e-13
 -0.000000	 -0.000000	diff=6.58302e-13
 -0.000000	 -0.000000	diff=8.631e-13
  0.000000	  0.000000	diff=1.81483e-13
  0.000000	  0.000000	diff=1.46954e-10
 -0.000000	 -0.000000	diff=5.51265e-12
 -0.000000	 -0.000000	diff=4.73179e-13
  0.000000	  0.000000	diff=4.79527e-13
  0.000000	  0.000000	diff=4.44912e-13
  0.000000	  0.000000	diff=3.77708e-13
  0.000000	  0.000000	diff=4.72247e-13
  0.000000	  0.000000	diff=5.45526e-13
 -0.000000	 -0.000000	diff=1.23014e-12
  0.000000	  0.000000	diff=7.08647e-10
  local_diff=9.30026e-10
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000012	  0.000012	diff=5.93541e-09
 -0.000017	 -0.000017	diff=1.56654e-08
  0.000013	  0.000013	diff=6.58969e-09
 -0.000025	 -0.000025	diff=2.31218e-08
  local_diff=5.13123e-08
# W_emb_tgt, [2 4]
  0.000002	  0.000002	diff=8.51802e-10
 -0.000000	 -0.000000	diff=3.25315e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000007	  0.000007	diff=8.28018e-10
  0.000000	  0.000000	diff=2.91888e-10
  0.000002	  0.000002	diff=1.28061e-09
 -0.000001	 -0.000001	diff=4.51894e-10
  local_diff=4.02953e-09
# W_pos, [2 2]
  0.000000	 -0.000000	diff=7.31859e-13
  0.000000	 -0.000000	diff=7.37528e-13
  0.000000	 -0.000000	diff=8.83437e-13
  0.000000	 -0.000000	diff=2.18876e-13
  local_diff=2.5717e-12
# v_pos, [1 2]
  0.000000	  0.000000	diff=4.03889e-13
  0.000000	  0.000000	diff=1.25345e-12
  local_diff=1.65734e-12
# W_a, [2 2]
  0.000000	  0.000000	diff=1.22777e-16
  0.000000	 -0.000000	diff=1.60267e-16
  0.000000	  0.000000	diff=1.12093e-15
  0.000000	 -0.000000	diff=1.46691e-15
  local_diff=2.87089e-15
# W_h, [2 4]
  0.000006	  0.000006	diff=2.76357e-13
 -0.000021	 -0.000021	diff=4.96934e-13
 -0.000008	 -0.000008	diff=5.75129e-13
  0.000026	  0.000026	diff=8.80268e-13
 -0.000000	 -0.000000	diff=2.04252e-12
  0.000009	  0.000009	diff=2.65329e-12
 -0.000018	 -0.000018	diff=6.00361e-12
  0.000070	  0.000070	diff=3.18415e-10
  local_diff=3.31344e-10
# W_soft, [4 2]
  0.000002	  0.000002	diff=7.44367e-13
 -0.000016	 -0.000016	diff=6.54516e-13
  0.000008	  0.000008	diff=7.27773e-14
  0.000006	  0.000006	diff=6.59968e-13
  0.000027	  0.000027	diff=6.04032e-13
 -0.000007	 -0.000007	diff=1.35956e-12
 -0.000016	 -0.000016	diff=1.38012e-12
 -0.000004	 -0.000004	diff=1.63009e-12
  local_diff=7.10543e-12
# Num params=186, abs_diff=5.77503e-08
Elapsed time is 3.210911 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 2, 'normLocalAttn', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 186, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_a=4 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 4
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 1
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 186
  src input 1: <s> <s> <s> x
  src mask: 0  0  0  1
  tgt input 1: <s> b a </s> </s>
  tgt output 1: b a </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=1.31796e-12
  0.000000	  0.000000	diff=1.4299e-12
  0.000000	  0.000000	diff=5.49444e-13
  0.000000	  0.000000	diff=6.57097e-13
  0.000000	  0.000000	diff=4.08248e-13
  0.000000	  0.000000	diff=4.82013e-13
 -0.000036	 -0.000036	diff=1.25766e-10
  0.000009	  0.000009	diff=6.23814e-11
 -0.000000	 -0.000000	diff=1.77036e-14
 -0.000000	 -0.000000	diff=2.14659e-12
 -0.000000	 -0.000000	diff=1.91539e-12
 -0.000000	 -0.000000	diff=3.8166e-13
 -0.000000	 -0.000000	diff=8.34903e-13
 -0.000000	 -0.000000	diff=6.13941e-13
  0.000061	  0.000061	diff=3.15392e-10
 -0.000025	 -0.000025	diff=2.19832e-10
 -0.000000	 -0.000000	diff=7.39998e-13
 -0.000000	 -0.000000	diff=6.77226e-13
 -0.000000	 -0.000000	diff=7.29501e-13
 -0.000000	 -0.000000	diff=2.93338e-13
 -0.000000	 -0.000000	diff=1.10332e-12
 -0.000000	 -0.000000	diff=2.95135e-13
  0.000001	  0.000001	diff=8.02147e-10
 -0.000000	 -0.000000	diff=2.32088e-12
  0.000000	  0.000000	diff=1.03485e-12
  0.000000	  0.000000	diff=1.05642e-12
  0.000000	  0.000000	diff=1.44202e-12
  0.000000	  0.000000	diff=1.17422e-12
  0.000000	  0.000000	diff=1.48558e-12
  0.000000	  0.000000	diff=7.06082e-13
 -0.000001	 -0.000001	diff=3.77956e-12
  0.000000	  0.000000	diff=1.65457e-10
  local_diff=1.71857e-09
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=1.77788e-12
 -0.000000	 -0.000000	diff=5.28479e-14
 -0.000000	 -0.000000	diff=4.94117e-13
 -0.000000	 -0.000000	diff=1.4434e-12
 -0.000000	 -0.000000	diff=1.22058e-12
 -0.000000	 -0.000000	diff=4.92965e-13
  0.000007	  0.000007	diff=9.14997e-13
 -0.000050	 -0.000050	diff=1.02747e-11
  0.000000	  0.000000	diff=2.18718e-12
  0.000000	  0.000000	diff=1.48921e-12
  0.000000	  0.000000	diff=1.58981e-12
  0.000000	  0.000000	diff=1.36542e-12
  0.000000	  0.000000	diff=1.34223e-12
  0.000000	  0.000000	diff=1.08524e-12
 -0.000015	 -0.000015	diff=4.98996e-13
  0.000064	  0.000064	diff=9.27143e-12
 -0.000000	 -0.000000	diff=9.02116e-13
 -0.000000	 -0.000000	diff=6.49775e-13
 -0.000000	 -0.000000	diff=1.06472e-12
 -0.000000	 -0.000000	diff=9.53109e-13
 -0.000000	 -0.000000	diff=7.42006e-13
 -0.000000	 -0.000000	diff=1.90698e-13
  0.000000	  0.000000	diff=1.94827e-10
 -0.000001	 -0.000001	diff=1.17106e-12
  0.000000	  0.000000	diff=1.31922e-12
  0.000000	  0.000000	diff=4.82203e-13
  0.000000	  0.000000	diff=1.34579e-12
  0.000000	  0.000000	diff=1.30831e-12
  0.000000	  0.000000	diff=9.04268e-13
  0.000000	  0.000000	diff=1.67234e-12
 -0.000000	 -0.000000	diff=1.78166e-12
  0.000001	  0.000001	diff=8.5105e-10
  local_diff=1.09586e-09
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=5.66545e-13
  0.000000	  0.000000	diff=2.1394e-12
 -0.000000	 -0.000000	diff=1.663e-12
  0.000000	  0.000000	diff=1.39892e-12
 -0.000000	 -0.000000	diff=6.35846e-13
  0.000000	  0.000000	diff=1.39901e-12
  0.000001	  0.000001	diff=3.3305e-12
 -0.000009	 -0.000009	diff=4.17252e-11
 -0.000000	 -0.000000	diff=9.91977e-13
 -0.000000	 -0.000000	diff=1.24096e-12
 -0.000000	 -0.000000	diff=7.21573e-13
 -0.000000	 -0.000000	diff=3.13319e-12
 -0.000000	 -0.000000	diff=4.34245e-13
 -0.000000	 -0.000000	diff=4.36178e-13
  0.000001	  0.000001	diff=4.05952e-11
  0.000007	  0.000007	diff=9.1087e-11
 -0.000000	  0.000000	diff=1.54097e-12
 -0.000000	 -0.000000	diff=4.87258e-13
 -0.000000	  0.000000	diff=1.42276e-12
 -0.000000	 -0.000000	diff=1.41899e-12
 -0.000000	  0.000000	diff=1.50554e-12
 -0.000000	 -0.000000	diff=7.68624e-13
 -0.000000	 -0.000000	diff=1.29021e-12
  0.000000	  0.000000	diff=1.43157e-12
 -0.000000	 -0.000000	diff=1.32076e-12
  0.000000	  0.000000	diff=8.67985e-13
 -0.000000	  0.000000	diff=1.44998e-12
  0.000000	  0.000000	diff=5.51151e-13
 -0.000000	 -0.000000	diff=1.36136e-12
  0.000000	  0.000000	diff=9.51285e-13
  0.000000	  0.000000	diff=3.9518e-13
 -0.000000	 -0.000000	diff=8.74783e-13
  0.000000	  0.000000	diff=1.05292e-12
 -0.000000	 -0.000000	diff=1.29309e-12
  0.000000	  0.000000	diff=9.30678e-13
 -0.000000	 -0.000000	diff=3.1675e-13
  0.000000	  0.000000	diff=1.19001e-12
 -0.000000	 -0.000000	diff=1.71662e-12
 -0.000000	 -0.000000	diff=1.2163e-10
  0.000000	  0.000000	diff=1.01354e-11
  0.000000	  0.000000	diff=2.99168e-14
 -0.000000	 -0.000000	diff=8.61936e-13
 -0.000000	 -0.000000	diff=1.99396e-12
 -0.000000	 -0.000000	diff=9.9424e-13
  0.000000	  0.000000	diff=7.83262e-13
 -0.000000	 -0.000000	diff=1.24918e-12
  0.000000	  0.000000	diff=3.24199e-13
  0.000000	  0.000000	diff=1.91209e-10
  local_diff=5.44849e-10
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=2.05379e-12
 -0.000000	 -0.000000	diff=1.34805e-12
 -0.000000	 -0.000000	diff=1.17659e-12
 -0.000000	 -0.000000	diff=1.54184e-12
  0.000000	  0.000000	diff=2.20571e-13
 -0.000000	 -0.000000	diff=1.87327e-12
  0.000004	  0.000004	diff=1.42757e-12
 -0.000006	 -0.000006	diff=7.14718e-12
  0.000000	  0.000000	diff=1.52695e-12
 -0.000000	 -0.000000	diff=9.70151e-13
  0.000000	  0.000000	diff=6.1202e-13
 -0.000000	 -0.000000	diff=1.24462e-12
  0.000000	  0.000000	diff=1.28534e-12
 -0.000000	 -0.000000	diff=1.04267e-12
  0.000004	  0.000004	diff=2.18581e-11
 -0.000007	 -0.000007	diff=2.06371e-11
  0.000000	  0.000000	diff=4.0562e-13
  0.000000	  0.000000	diff=1.44667e-12
 -0.000000	 -0.000000	diff=6.45881e-13
 -0.000000	 -0.000000	diff=5.22455e-14
 -0.000000	 -0.000000	diff=1.26854e-12
 -0.000000	  0.000000	diff=1.60268e-12
  0.000000	  0.000000	diff=1.45565e-10
 -0.000000	 -0.000000	diff=4.01294e-12
 -0.000000	 -0.000000	diff=9.4788e-13
  0.000000	  0.000000	diff=4.79381e-13
  0.000000	  0.000000	diff=1.86599e-12
  0.000000	  0.000000	diff=1.08826e-12
  0.000000	  0.000000	diff=1.65935e-12
  0.000000	  0.000000	diff=8.75417e-13
 -0.000000	 -0.000000	diff=6.57518e-14
  0.000000	  0.000000	diff=7.0717e-10
  local_diff=9.35117e-10
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000030	  0.000030	diff=1.38044e-08
 -0.000048	 -0.000048	diff=4.24015e-08
  0.000029	  0.000029	diff=1.40758e-08
 -0.000056	 -0.000056	diff=5.07332e-08
  local_diff=1.21015e-07
# W_emb_tgt, [2 4]
  0.000002	  0.000002	diff=8.49672e-10
 -0.000000	 -0.000000	diff=3.26383e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000007	  0.000007	diff=8.26968e-10
  0.000000	  0.000000	diff=2.90201e-10
  0.000002	  0.000002	diff=1.27998e-09
 -0.000001	 -0.000001	diff=4.53548e-10
  local_diff=4.02675e-09
# W_pos, [2 2]
  0.000000	  0.000000	diff=3.85055e-24
  0.000000	  0.000000	diff=4.87461e-24
  0.000000	  0.000000	diff=1.50916e-23
  0.000000	  0.000000	diff=1.91053e-23
  local_diff=4.29221e-23
# v_pos, [1 2]
  0.000000	 -0.000000	diff=1.00366e-22
  0.000000	 -0.000000	diff=3.72501e-22
  local_diff=4.72867e-22
# W_a, [2 2]
  0.000000	  0.000000	diff=1.30949e-16
  0.000000	 -0.000000	diff=1.60573e-16
  0.000000	  0.000000	diff=1.17917e-15
  0.000000	 -0.000000	diff=1.4548e-15
  local_diff=2.92549e-15
# W_h, [2 4]
  0.000015	  0.000015	diff=3.84247e-14
 -0.000051	 -0.000051	diff=9.35612e-13
 -0.000019	 -0.000019	diff=1.02586e-12
  0.000065	  0.000065	diff=4.82935e-13
 -0.000000	 -0.000000	diff=6.34861e-13
  0.000009	  0.000009	diff=4.3872e-12
 -0.000018	 -0.000018	diff=7.0435e-12
  0.000070	  0.000070	diff=3.16481e-10
  local_diff=3.31029e-10
# W_soft, [4 2]
 -0.000022	 -0.000022	diff=7.79541e-13
 -0.000012	 -0.000012	diff=9.88338e-13
  0.000023	  0.000023	diff=9.39254e-13
  0.000012	  0.000012	diff=1.35039e-13
  0.000053	  0.000053	diff=4.98596e-13
 -0.000011	 -0.000011	diff=4.17587e-13
 -0.000032	 -0.000032	diff=1.59916e-13
 -0.000010	 -0.000010	diff=1.05553e-12
  local_diff=4.9738e-12
# Num params=186, abs_diff=1.29672e-07
Elapsed time is 3.997059 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 1
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=2.77786e-13
  0.000000	  0.000000	diff=9.25455e-13
 -0.000000	 -0.000000	diff=1.35419e-12
  0.000000	  0.000000	diff=7.7862e-13
 -0.000000	 -0.000000	diff=3.06384e-13
 -0.000000	 -0.000000	diff=1.50102e-12
  0.000003	  0.000003	diff=3.55653e-11
  0.000004	  0.000004	diff=3.41696e-11
  0.000000	  0.000000	diff=1.41953e-12
 -0.000000	 -0.000000	diff=3.86126e-13
  0.000000	  0.000000	diff=1.08444e-12
 -0.000000	 -0.000000	diff=8.29179e-13
  0.000000	  0.000000	diff=5.37066e-13
  0.000000	  0.000000	diff=3.07371e-13
 -0.000005	 -0.000005	diff=7.40579e-11
 -0.000012	 -0.000012	diff=1.49435e-10
  0.000000	  0.000000	diff=6.49985e-13
 -0.000000	 -0.000000	diff=8.33679e-13
  0.000000	  0.000000	diff=2.98745e-13
 -0.000000	 -0.000000	diff=5.01319e-13
  0.000000	  0.000000	diff=1.16449e-13
  0.000000	  0.000000	diff=1.81674e-13
 -0.000000	 -0.000000	diff=1.32626e-10
 -0.000000	 -0.000000	diff=4.73432e-13
 -0.000000	 -0.000000	diff=7.56616e-13
  0.000000	  0.000000	diff=4.51725e-13
 -0.000000	 -0.000000	diff=1.08716e-12
  0.000000	  0.000000	diff=7.39819e-16
 -0.000000	 -0.000000	diff=5.08205e-13
 -0.000000	 -0.000000	diff=8.71953e-13
  0.000000	  0.000000	diff=5.32992e-13
  0.000000	  0.000000	diff=1.33294e-10
  local_diff=5.76119e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=1.17346e-12
 -0.000000	 -0.000000	diff=1.41357e-12
  0.000000	  0.000000	diff=2.64011e-13
  0.000000	  0.000000	diff=9.04877e-13
  0.000000	  0.000000	diff=9.18958e-13
 -0.000000	 -0.000000	diff=5.42138e-13
 -0.000009	 -0.000009	diff=1.01197e-12
 -0.000002	 -0.000002	diff=6.33117e-12
 -0.000000	 -0.000000	diff=7.13829e-13
  0.000000	  0.000000	diff=8.83701e-14
 -0.000000	 -0.000000	diff=9.78904e-13
 -0.000000	 -0.000000	diff=5.76728e-13
 -0.000000	 -0.000000	diff=1.19709e-12
  0.000000	  0.000000	diff=6.43872e-13
  0.000006	  0.000006	diff=1.06282e-12
  0.000002	  0.000002	diff=6.10409e-12
  0.000000	  0.000000	diff=3.42414e-13
  0.000000	  0.000000	diff=3.25708e-13
  0.000000	  0.000000	diff=5.36954e-13
  0.000000	  0.000000	diff=1.57927e-13
  0.000000	  0.000000	diff=7.11598e-13
 -0.000000	 -0.000000	diff=1.14787e-12
 -0.000000	 -0.000000	diff=1.12719e-10
  0.000000	  0.000000	diff=7.49301e-13
 -0.000000	 -0.000000	diff=5.75032e-13
 -0.000000	 -0.000000	diff=9.56549e-13
 -0.000000	 -0.000000	diff=7.959e-13
 -0.000000	 -0.000000	diff=3.80142e-14
 -0.000000	 -0.000000	diff=4.53936e-13
  0.000000	  0.000000	diff=2.08717e-13
  0.000000	  0.000000	diff=2.99644e-13
 -0.000000	 -0.000000	diff=1.08467e-10
  local_diff=2.52412e-10
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=3.01334e-13
 -0.000000	 -0.000000	diff=8.03811e-14
  0.000000	  0.000000	diff=2.53235e-12
 -0.000000	 -0.000000	diff=6.86954e-13
  0.000000	  0.000000	diff=5.9926e-13
 -0.000000	 -0.000000	diff=1.58022e-13
 -0.000007	 -0.000007	diff=1.21583e-10
  0.000032	  0.000032	diff=2.3914e-10
  0.000000	  0.000000	diff=2.46741e-13
  0.000000	  0.000000	diff=7.52069e-13
 -0.000000	 -0.000000	diff=1.12646e-12
 -0.000000	 -0.000000	diff=2.87428e-12
  0.000000	  0.000000	diff=1.26489e-13
  0.000000	  0.000000	diff=1.318e-12
  0.000004	  0.000004	diff=3.93043e-11
 -0.000031	 -0.000031	diff=3.72793e-10
 -0.000000	 -0.000000	diff=1.87903e-13
  0.000000	  0.000000	diff=2.65115e-13
 -0.000000	 -0.000000	diff=3.27152e-13
  0.000000	  0.000000	diff=1.50691e-13
 -0.000000	 -0.000000	diff=2.56643e-14
  0.000000	  0.000000	diff=8.14697e-13
  0.000000	  0.000000	diff=1.37937e-13
 -0.000000	 -0.000000	diff=3.00142e-13
  0.000000	 -0.000000	diff=2.53584e-14
 -0.000000	 -0.000000	diff=4.1065e-13
 -0.000000	 -0.000000	diff=6.45866e-13
 -0.000000	 -0.000000	diff=6.19426e-13
 -0.000000	 -0.000000	diff=7.10069e-13
 -0.000000	 -0.000000	diff=1.49374e-13
  0.000000	  0.000000	diff=1.25771e-12
  0.000000	  0.000000	diff=9.42006e-13
 -0.000000	 -0.000000	diff=1.96633e-13
  0.000000	  0.000000	diff=2.55468e-13
 -0.000000	 -0.000000	diff=4.60343e-13
 -0.000000	 -0.000000	diff=1.50087e-13
 -0.000000	 -0.000000	diff=6.66411e-13
  0.000000	  0.000000	diff=2.16386e-13
  0.000000	  0.000000	diff=5.80746e-10
 -0.000001	 -0.000001	diff=2.49131e-11
 -0.000000	 -0.000000	diff=7.87749e-14
  0.000000	  0.000000	diff=6.61431e-13
  0.000000	  0.000000	diff=6.46749e-13
  0.000000	  0.000000	diff=9.29232e-13
 -0.000000	 -0.000000	diff=4.27616e-13
  0.000000	  0.000000	diff=3.03627e-13
 -0.000000	 -0.000000	diff=4.39268e-12
  0.000000	  0.000000	diff=7.79251e-10
  local_diff=2.18489e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=4.02603e-13
  0.000000	  0.000000	diff=7.67483e-13
  0.000000	  0.000000	diff=3.57693e-13
  0.000000	  0.000000	diff=6.69867e-13
 -0.000000	 -0.000000	diff=3.52914e-13
  0.000000	  0.000000	diff=9.58641e-13
 -0.000014	 -0.000014	diff=5.95072e-12
  0.000019	  0.000019	diff=2.31737e-11
 -0.000000	 -0.000000	diff=2.61053e-13
  0.000000	  0.000000	diff=6.95797e-13
 -0.000000	 -0.000000	diff=7.68082e-13
  0.000000	  0.000000	diff=6.39587e-13
 -0.000000	 -0.000000	diff=3.43851e-13
  0.000000	  0.000000	diff=9.86064e-14
 -0.000018	 -0.000018	diff=4.59772e-11
  0.000021	  0.000021	diff=7.20044e-11
 -0.000000	 -0.000000	diff=1.54667e-13
 -0.000000	 -0.000000	diff=2.31953e-13
  0.000000	  0.000000	diff=5.11938e-13
  0.000000	  0.000000	diff=5.26596e-14
  0.000000	  0.000000	diff=5.0172e-13
  0.000000	  0.000000	diff=7.05294e-13
 -0.000000	 -0.000000	diff=8.11008e-10
  0.000000	  0.000000	diff=2.14856e-11
  0.000000	  0.000000	diff=4.15957e-13
 -0.000000	 -0.000000	diff=2.67884e-14
 -0.000000	 -0.000000	diff=4.51977e-13
 -0.000000	 -0.000000	diff=3.72777e-13
  0.000000	  0.000000	diff=4.65999e-13
 -0.000000	 -0.000000	diff=5.05718e-13
  0.000001	  0.000001	diff=3.8147e-12
 -0.000001	 -0.000001	diff=1.90661e-09
  local_diff=2.90074e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000004	 -0.000004	diff=1.30274e-09
 -0.000003	 -0.000003	diff=1.71342e-09
 -0.000001	 -0.000001	diff=6.69352e-10
 -0.000007	 -0.000007	diff=2.71291e-09
  local_diff=6.39842e-09
# W_emb_tgt, [2 4]
 -0.000016	 -0.000016	diff=4.41213e-09
  0.000002	  0.000002	diff=1.08452e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000014	 -0.000014	diff=5.36458e-09
  0.000002	  0.000002	diff=1.10432e-09
 -0.000005	 -0.000005	diff=2.92451e-09
  0.000002	  0.000002	diff=1.17304e-09
  local_diff=1.60631e-08
# W_a, [2 2]
  0.000000	 -0.000000	diff=4.79723e-23
  0.000000	 -0.000000	diff=7.96157e-23
  0.000000	 -0.000000	diff=1.5194e-22
  0.000000	 -0.000000	diff=2.70324e-22
  local_diff=5.49852e-22
# v_a, [1 2]
 -0.000000	 -0.000000	diff=6.26457e-14
  0.000000	  0.000000	diff=1.93066e-14
  local_diff=8.19523e-14
# W_h, [2 4]
 -0.000022	 -0.000022	diff=4.41379e-13
  0.000014	  0.000014	diff=3.71291e-13
  0.000027	  0.000027	diff=3.11359e-13
 -0.000019	 -0.000019	diff=4.82606e-14
  0.000005	  0.000005	diff=3.34947e-12
  0.000000	  0.000000	diff=1.57056e-12
  0.000032	  0.000032	diff=1.60219e-10
 -0.000018	 -0.000018	diff=4.64481e-11
  local_diff=2.1276e-10
# W_soft, [4 2]
 -0.000023	 -0.000023	diff=3.70484e-13
 -0.000001	 -0.000001	diff=1.09104e-13
  0.000017	  0.000017	diff=2.2966e-13
  0.000007	  0.000007	diff=1.29491e-15
  0.000013	  0.000013	diff=2.76154e-13
 -0.000018	 -0.000018	diff=1.82187e-13
  0.000000	  0.000000	diff=7.4157e-13
  0.000005	  0.000005	diff=5.85548e-13
  local_diff=2.496e-12
# Num params=182, abs_diff=2.8591e-08
Elapsed time is 2.785277 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 2, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 2
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=7.5073e-13
  0.000000	  0.000000	diff=4.02832e-13
 -0.000000	 -0.000000	diff=1.64241e-12
  0.000000	  0.000000	diff=1.16456e-12
 -0.000000	 -0.000000	diff=8.9223e-13
 -0.000000	 -0.000000	diff=4.04668e-13
  0.000003	  0.000003	diff=3.60203e-11
  0.000003	  0.000003	diff=3.28194e-11
  0.000000	  0.000000	diff=7.83338e-13
 -0.000000	 -0.000000	diff=1.06571e-12
  0.000000	  0.000000	diff=7.59777e-15
 -0.000000	 -0.000000	diff=1.10887e-12
  0.000000	  0.000000	diff=9.91883e-13
  0.000000	  0.000000	diff=1.25188e-12
 -0.000005	 -0.000005	diff=7.52803e-11
 -0.000012	 -0.000012	diff=1.48014e-10
  0.000000	  0.000000	diff=1.67972e-12
 -0.000000	 -0.000000	diff=2.49008e-13
  0.000000	  0.000000	diff=1.59328e-12
 -0.000000	 -0.000000	diff=2.26683e-12
  0.000000	  0.000000	diff=9.94035e-13
  0.000000	  0.000000	diff=5.35607e-13
 -0.000000	 -0.000000	diff=9.51466e-11
 -0.000000	 -0.000000	diff=3.22197e-13
 -0.000000	 -0.000000	diff=1.11248e-12
  0.000000	  0.000000	diff=4.94262e-13
 -0.000000	 -0.000000	diff=1.33854e-12
  0.000000	  0.000000	diff=8.04286e-13
 -0.000000	 -0.000000	diff=1.32781e-12
 -0.000000	 -0.000000	diff=1.44916e-12
  0.000000	  0.000000	diff=1.99534e-12
  0.000000	  0.000000	diff=1.35613e-10
  local_diff=5.49523e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=1.01881e-12
 -0.000000	 -0.000000	diff=9.49157e-13
  0.000000	  0.000000	diff=1.56485e-12
  0.000000	  0.000000	diff=6.51918e-13
  0.000000	  0.000000	diff=1.40691e-12
 -0.000000	 -0.000000	diff=1.3245e-12
 -0.000009	 -0.000009	diff=8.41935e-13
 -0.000002	 -0.000002	diff=3.6431e-12
 -0.000000	 -0.000000	diff=9.67868e-13
  0.000000	  0.000000	diff=1.05578e-13
 -0.000000	 -0.000000	diff=1.30341e-12
 -0.000000	 -0.000000	diff=1.18709e-12
 -0.000000	 -0.000000	diff=1.64383e-12
  0.000000	  0.000000	diff=4.31719e-13
  0.000006	  0.000006	diff=1.98402e-13
  0.000002	  0.000002	diff=5.98937e-12
  0.000000	  0.000000	diff=3.61089e-13
  0.000000	  0.000000	diff=1.00011e-12
  0.000000	  0.000000	diff=9.67708e-13
  0.000000	  0.000000	diff=2.68249e-14
  0.000000	  0.000000	diff=6.02297e-14
 -0.000000	 -0.000000	diff=1.18593e-12
 -0.000000	 -0.000000	diff=6.11625e-11
  0.000000	  0.000000	diff=1.38369e-12
 -0.000000	 -0.000000	diff=1.63866e-12
 -0.000000	 -0.000000	diff=8.83508e-13
 -0.000000	 -0.000000	diff=1.48238e-12
 -0.000000	 -0.000000	diff=1.05411e-12
 -0.000000	 -0.000000	diff=2.47063e-13
  0.000000	  0.000000	diff=1.12639e-12
  0.000000	  0.000000	diff=9.3615e-13
 -0.000000	 -0.000000	diff=1.21165e-10
  local_diff=2.1791e-10
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=1.14228e-12
 -0.000000	 -0.000000	diff=1.80696e-12
  0.000000	  0.000000	diff=3.96655e-12
 -0.000000	 -0.000000	diff=3.40627e-12
  0.000000	  0.000000	diff=8.45382e-13
 -0.000000	 -0.000000	diff=9.84353e-13
 -0.000007	 -0.000007	diff=1.22989e-10
  0.000032	  0.000032	diff=2.40478e-10
  0.000000	  0.000000	diff=9.47129e-13
  0.000000	  0.000000	diff=1.43724e-12
 -0.000000	 -0.000000	diff=2.94055e-13
 -0.000000	 -0.000000	diff=4.23974e-12
  0.000000	  0.000000	diff=1.28838e-12
  0.000000	  0.000000	diff=7.16884e-13
  0.000004	  0.000004	diff=3.99667e-11
 -0.000031	 -0.000031	diff=3.73493e-10
  0.000000	 -0.000000	diff=5.41387e-13
  0.000000	  0.000000	diff=3.90407e-13
  0.000000	 -0.000000	diff=3.95997e-13
  0.000000	  0.000000	diff=5.53182e-13
  0.000000	 -0.000000	diff=7.09147e-13
  0.000000	  0.000000	diff=5.62691e-13
  0.000000	  0.000000	diff=1.06055e-12
 -0.000000	 -0.000000	diff=1.125e-12
  0.000000	 -0.000000	diff=6.79022e-14
 -0.000000	 -0.000000	diff=1.3012e-13
  0.000000	 -0.000000	diff=7.91834e-14
 -0.000000	 -0.000000	diff=5.63864e-14
  0.000000	 -0.000000	diff=3.18999e-14
  0.000000	 -0.000000	diff=1.43213e-12
  0.000000	  0.000000	diff=9.23646e-13
  0.000000	  0.000000	diff=1.34364e-12
 -0.000000	 -0.000000	diff=1.93428e-12
  0.000000	  0.000000	diff=1.17007e-12
 -0.000000	 -0.000000	diff=9.60205e-13
 -0.000000	 -0.000000	diff=1.27315e-12
 -0.000000	 -0.000000	diff=4.32081e-14
  0.000000	  0.000000	diff=1.20978e-12
  0.000000	  0.000000	diff=5.80898e-10
 -0.000001	 -0.000001	diff=2.5972e-11
 -0.000000	 -0.000000	diff=1.34079e-12
  0.000000	  0.000000	diff=1.47621e-12
  0.000000	  0.000000	diff=7.73121e-13
  0.000000	  0.000000	diff=4.9563e-13
 -0.000000	 -0.000000	diff=2.80834e-13
  0.000000	  0.000000	diff=1.1266e-12
 -0.000000	 -0.000000	diff=4.57818e-12
  0.000000	  0.000000	diff=7.80889e-10
  local_diff=2.21182e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=1.72749e-12
  0.000000	  0.000000	diff=1.37587e-12
  0.000000	  0.000000	diff=1.06315e-12
  0.000000	  0.000000	diff=1.46748e-12
 -0.000000	 -0.000000	diff=1.06726e-12
  0.000000	  0.000000	diff=1.18678e-12
 -0.000014	 -0.000014	diff=7.23302e-12
  0.000019	  0.000019	diff=2.19557e-11
 -0.000000	 -0.000000	diff=1.1568e-12
  0.000000	  0.000000	diff=7.41949e-13
 -0.000000	 -0.000000	diff=1.36422e-12
  0.000000	  0.000000	diff=8.02092e-14
 -0.000000	 -0.000000	diff=3.65562e-13
  0.000000	  0.000000	diff=8.28146e-13
 -0.000018	 -0.000018	diff=4.66252e-11
  0.000021	  0.000021	diff=7.14434e-11
 -0.000000	 -0.000000	diff=1.54666e-13
 -0.000000	 -0.000000	diff=1.18913e-12
  0.000000	  0.000000	diff=9.09159e-13
  0.000000	  0.000000	diff=1.47371e-12
  0.000000	  0.000000	diff=2.08832e-13
  0.000000	  0.000000	diff=5.1753e-15
 -0.000000	 -0.000000	diff=8.09366e-10
  0.000000	  0.000000	diff=2.03999e-11
  0.000000	  0.000000	diff=2.94669e-13
 -0.000000	 -0.000000	diff=6.83388e-13
 -0.000000	 -0.000000	diff=9.69152e-13
 -0.000000	 -0.000000	diff=1.08313e-12
  0.000000	  0.000000	diff=9.55184e-13
 -0.000000	 -0.000000	diff=1.62546e-12
  0.000001	  0.000001	diff=2.23965e-12
 -0.000001	 -0.000001	diff=1.90646e-09
  local_diff=2.9077e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000003	 -0.000003	diff=1.12952e-09
 -0.000004	 -0.000004	diff=2.12459e-09
 -0.000001	 -0.000001	diff=7.21567e-10
 -0.000007	 -0.000007	diff=2.53515e-09
  local_diff=6.51083e-09
# W_emb_tgt, [2 4]
 -0.000016	 -0.000016	diff=4.41071e-09
  0.000002	  0.000002	diff=1.08592e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000014	 -0.000014	diff=5.36499e-09
  0.000002	  0.000002	diff=1.10504e-09
 -0.000005	 -0.000005	diff=2.92351e-09
  0.000002	  0.000002	diff=1.1745e-09
  local_diff=1.60647e-08
# W_a, [2 2]
  0.000000	 -0.000000	diff=4.79995e-23
  0.000000	 -0.000000	diff=8.35553e-23
  0.000000	 -0.000000	diff=1.11391e-22
  0.000000	 -0.000000	diff=1.96696e-22
  local_diff=4.39642e-22
# v_a, [1 2]
 -0.000000	 -0.000000	diff=1.13326e-12
  0.000000	  0.000000	diff=1.30921e-12
  local_diff=2.44247e-12
# W_h, [2 4]
 -0.000021	 -0.000021	diff=1.70008e-12
  0.000014	  0.000014	diff=2.21143e-12
  0.000027	  0.000027	diff=1.39708e-12
 -0.000019	 -0.000019	diff=1.37104e-12
  0.000005	  0.000005	diff=1.86665e-12
  0.000000	  0.000000	diff=2.62419e-12
  0.000032	  0.000032	diff=1.61538e-10
 -0.000018	 -0.000018	diff=4.51716e-11
  local_diff=2.1788e-10
# W_soft, [4 2]
 -0.000023	 -0.000023	diff=1.38969e-12
 -0.000002	 -0.000002	diff=9.09446e-13
  0.000017	  0.000017	diff=1.13014e-12
  0.000008	  0.000008	diff=1.54453e-12
  0.000013	  0.000013	diff=1.37698e-12
 -0.000022	 -0.000022	diff=2.57786e-12
  0.000001	  0.000001	diff=2.37095e-12
  0.000008	  0.000008	diff=1.49018e-12
  local_diff=1.27898e-11
# Num params=182, abs_diff=2.86956e-08
Elapsed time is 2.595114 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 188, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_a=4 v_a=2 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 4
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 188
  src input 1: <s> <s> y x
  src mask: 0  0  1  1
  tgt input 1: <s> b </s> </s> </s>
  tgt output 1: b </s> </s> </s> </s>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=6.26491e-13
  0.000000	  0.000000	diff=4.76285e-13
  0.000000	  0.000000	diff=1.78881e-14
  0.000000	  0.000000	diff=1.72345e-13
  0.000000	  0.000000	diff=4.32928e-13
  0.000000	  0.000000	diff=3.26636e-14
 -0.000004	 -0.000004	diff=2.2812e-12
  0.000001	  0.000001	diff=7.60286e-13
 -0.000000	 -0.000000	diff=8.78025e-14
 -0.000000	 -0.000000	diff=8.10155e-13
 -0.000000	 -0.000000	diff=3.41608e-13
 -0.000000	 -0.000000	diff=1.27115e-13
 -0.000000	 -0.000000	diff=9.46739e-13
 -0.000000	 -0.000000	diff=1.21398e-12
  0.000009	  0.000009	diff=5.00069e-12
 -0.000004	 -0.000004	diff=2.74243e-11
 -0.000000	 -0.000000	diff=4.40497e-13
 -0.000000	 -0.000000	diff=5.50288e-14
 -0.000000	 -0.000000	diff=3.927e-13
 -0.000000	 -0.000000	diff=9.53362e-13
 -0.000000	 -0.000000	diff=3.49505e-13
 -0.000000	 -0.000000	diff=2.08621e-13
  0.000000	  0.000000	diff=3.58041e-11
 -0.000000	 -0.000000	diff=2.96195e-13
  0.000000	  0.000000	diff=4.54727e-13
  0.000000	  0.000000	diff=9.18707e-14
  0.000000	  0.000000	diff=3.53771e-13
  0.000000	  0.000000	diff=3.94439e-13
  0.000000	  0.000000	diff=1.19528e-13
  0.000000	  0.000000	diff=3.04584e-13
 -0.000000	 -0.000000	diff=7.66778e-14
  0.000000	  0.000000	diff=8.01999e-11
  local_diff=1.61248e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=1.10856e-12
 -0.000000	 -0.000000	diff=6.93347e-13
 -0.000000	 -0.000000	diff=1.53687e-13
 -0.000000	 -0.000000	diff=3.84829e-14
 -0.000000	 -0.000000	diff=6.38006e-13
 -0.000000	 -0.000000	diff=8.56788e-13
  0.000005	  0.000005	diff=5.01229e-13
 -0.000003	 -0.000003	diff=1.94047e-13
  0.000000	  0.000000	diff=1.29681e-14
  0.000000	  0.000000	diff=3.53129e-13
  0.000000	  0.000000	diff=1.61647e-13
  0.000000	  0.000000	diff=6.25646e-14
  0.000000	  0.000000	diff=5.75943e-14
  0.000000	  0.000000	diff=3.01837e-13
 -0.000006	 -0.000006	diff=2.18806e-14
  0.000005	  0.000005	diff=4.24299e-13
 -0.000000	 -0.000000	diff=3.00173e-14
 -0.000000	 -0.000000	diff=1.92303e-13
 -0.000000	 -0.000000	diff=3.18924e-13
 -0.000000	 -0.000000	diff=5.37123e-13
 -0.000000	 -0.000000	diff=8.46485e-13
 -0.000000	 -0.000000	diff=3.14979e-14
  0.000000	  0.000000	diff=1.67092e-11
 -0.000000	 -0.000000	diff=1.0686e-12
  0.000000	  0.000000	diff=7.92984e-13
  0.000000	  0.000000	diff=3.85405e-13
  0.000000	  0.000000	diff=1.07225e-13
  0.000000	  0.000000	diff=2.75109e-13
  0.000000	  0.000000	diff=3.87192e-13
  0.000000	  0.000000	diff=1.45479e-13
 -0.000000	 -0.000000	diff=1.02661e-12
  0.000000	  0.000000	diff=5.07912e-11
  local_diff=7.92254e-11
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=9.37135e-13
 -0.000000	 -0.000000	diff=8.73638e-13
  0.000000	  0.000000	diff=3.34515e-12
 -0.000000	 -0.000000	diff=6.96876e-13
  0.000000	  0.000000	diff=3.39113e-13
 -0.000000	 -0.000000	diff=6.67818e-13
 -0.000004	 -0.000004	diff=7.85823e-11
  0.000017	  0.000017	diff=1.39181e-10
  0.000000	  0.000000	diff=6.9869e-14
 -0.000000	 -0.000000	diff=4.39043e-13
  0.000000	  0.000000	diff=7.84949e-13
 -0.000000	 -0.000000	diff=3.28856e-14
  0.000000	  0.000000	diff=1.29087e-12
 -0.000000	 -0.000000	diff=6.59371e-13
 -0.000002	 -0.000002	diff=4.11083e-11
  0.000006	  0.000006	diff=1.83436e-07
  0.000000	 -0.000000	diff=5.69777e-13
  0.000000	  0.000000	diff=5.6902e-14
  0.000000	 -0.000000	diff=3.12195e-13
  0.000000	  0.000000	diff=2.37763e-14
  0.000000	 -0.000000	diff=6.43581e-13
  0.000000	  0.000000	diff=5.97888e-13
  0.000000	  0.000000	diff=5.36407e-14
 -0.000000	 -0.000000	diff=4.42274e-13
  0.000000	 -0.000000	diff=7.58221e-13
  0.000000	 -0.000000	diff=7.67494e-14
  0.000000	  0.000000	diff=6.32053e-13
  0.000000	  0.000000	diff=5.1152e-14
  0.000000	 -0.000000	diff=7.2237e-13
  0.000000	 -0.000000	diff=1.30129e-13
 -0.000000	 -0.000000	diff=3.13528e-13
  0.000000	  0.000000	diff=2.97599e-13
 -0.000000	 -0.000000	diff=2.92992e-13
  0.000000	  0.000000	diff=5.08362e-13
 -0.000000	 -0.000000	diff=3.96904e-13
  0.000000	  0.000000	diff=4.6379e-13
 -0.000000	 -0.000000	diff=3.01509e-13
  0.000000	  0.000000	diff=1.68319e-13
  0.000000	  0.000000	diff=3.84127e-10
 -0.000000	 -0.000000	diff=3.53928e-11
 -0.000000	 -0.000000	diff=1.74199e-13
  0.000000	  0.000000	diff=1.31085e-12
 -0.000000	 -0.000000	diff=7.19353e-14
  0.000000	  0.000000	diff=5.68524e-13
 -0.000000	 -0.000000	diff=1.47267e-13
  0.000000	  0.000000	diff=4.01596e-14
  0.000000	  0.000000	diff=4.05835e-12
 -0.000000	 -0.000000	diff=5.86644e-10
  local_diff=1.84725e-07
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=8.66683e-13
  0.000000	  0.000000	diff=5.88501e-13
 -0.000000	 -0.000000	diff=4.07656e-13
  0.000000	  0.000000	diff=6.57486e-13
 -0.000000	 -0.000000	diff=1.89333e-13
  0.000000	  0.000000	diff=5.92187e-13
 -0.000007	 -0.000007	diff=1.3889e-12
  0.000017	  0.000017	diff=8.48831e-12
 -0.000000	 -0.000000	diff=7.32117e-13
  0.000000	  0.000000	diff=1.15566e-13
 -0.000000	 -0.000000	diff=2.48052e-13
  0.000000	  0.000000	diff=5.09251e-13
 -0.000000	 -0.000000	diff=6.86298e-13
  0.000000	  0.000000	diff=4.6857e-13
 -0.000006	 -0.000006	diff=4.88364e-12
  0.000015	  0.000015	diff=3.07096e-11
  0.000000	  0.000000	diff=6.71412e-14
 -0.000000	 -0.000000	diff=4.33729e-13
  0.000000	  0.000000	diff=6.63295e-13
 -0.000000	 -0.000000	diff=3.12048e-13
  0.000000	  0.000000	diff=3.02436e-13
 -0.000000	 -0.000000	diff=7.19205e-14
  0.000000	  0.000000	diff=4.36986e-10
 -0.000000	 -0.000000	diff=3.15565e-11
  0.000000	  0.000000	diff=1.85254e-13
 -0.000000	 -0.000000	diff=2.72775e-13
  0.000000	  0.000000	diff=1.27213e-13
 -0.000000	 -0.000000	diff=3.32229e-13
  0.000000	  0.000000	diff=3.19968e-13
 -0.000000	 -0.000000	diff=7.27631e-13
  0.000000	  0.000000	diff=3.15372e-12
 -0.000000	 -0.000000	diff=2.19756e-09
  local_diff=2.72461e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000007	  0.000007	diff=2.96322e-09
 -0.000014	 -0.000014	diff=1.10131e-08
  0.000002	  0.000002	diff=1.49923e-09
 -0.000004	 -0.000004	diff=5.13623e-09
  local_diff=2.06118e-08
# W_emb_tgt, [2 4]
  0.000002	  0.000002	diff=4.97011e-10
 -0.000001	 -0.000001	diff=7.48847e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000003	 -0.000003	diff=3.08474e-09
  0.000000	  0.000000	diff=1.28569e-10
 -0.000010	 -0.000010	diff=5.1988e-09
  0.000001	  0.000001	diff=7.82569e-10
  local_diff=1.04405e-08
# W_pos, [2 2]
  0.000000	 -0.000000	diff=2.83273e-14
  0.000000	 -0.000000	diff=3.5861e-14
  0.000000	 -0.000000	diff=1.13595e-13
  0.000000	 -0.000000	diff=1.43806e-13
  local_diff=3.21589e-13
# v_pos, [1 2]
  0.000000	  0.000000	diff=4.38951e-14
  0.000000	  0.000000	diff=7.53839e-13
  local_diff=7.97734e-13
# W_a, [2 2]
  0.000000	  0.000000	diff=4.82961e-21
  0.000000	  0.000000	diff=8.30587e-22
  0.000000	  0.000000	diff=1.38847e-20
  0.000000	  0.000000	diff=2.33878e-21
  local_diff=2.18837e-20
# v_a, [1 2]
  0.000000	  0.000000	diff=4.92342e-16
 -0.000000	 -0.000000	diff=5.12794e-14
  local_diff=5.17718e-14
# W_h, [2 4]
 -0.000003	 -0.000003	diff=6.3205e-13
  0.000004	  0.000004	diff=8.7609e-15
  0.000005	  0.000005	diff=4.66431e-13
 -0.000005	 -0.000005	diff=3.4086e-13
  0.000012	  0.000012	diff=3.82409e-12
  0.000006	  0.000006	diff=5.58478e-12
  0.000020	  0.000020	diff=1.50395e-10
 -0.000006	 -0.000006	diff=6.45575e-11
  local_diff=2.25809e-10
# W_soft, [4 2]
 -0.000006	 -0.000006	diff=3.17263e-13
  0.000006	  0.000006	diff=2.03743e-13
 -0.000001	 -0.000001	diff=2.8879e-16
  0.000002	  0.000002	diff=1.89248e-13
 -0.000029	 -0.000029	diff=2.06252e-13
  0.000007	  0.000007	diff=1.14036e-12
  0.000006	  0.000006	diff=1.11459e-13
  0.000017	  0.000017	diff=5.98439e-13
  local_diff=2.76705e-12
# Num params=188, abs_diff=2.18972e-07
Elapsed time is 3.135785 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'attnFunc', 0, 'feedInput', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 104, individual sizes:  W_src{1}=32 W_tgt{1}=48 W_emb_src=8 W_emb_tgt=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 0
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 1
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# attnGlobal = 0
# attnLocalMono = 0
# attnLocalPred = 0
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 104
  src input 1: y y x y
  src mask: 1  1  1  1
  tgt input 1: <s> a b a
  tgt output 1: a b a </s>
  tgt mask: 1  1  1  1
# W_src{1}, [8 4]
  0.000000	 -0.000000	diff=6.82914e-27
  0.000000	 -0.000000	diff=1.95177e-30
  0.000000	  0.000000	diff=5.93316e-31
  0.000000	  0.000000	diff=1.85467e-30
  0.000000	  0.000000	diff=7.88768e-13
  0.000033	  0.000033	diff=1.27003e-07
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=5.11769e-35
  0.000000	 -0.000000	diff=9.28012e-28
  0.000000	 -0.000000	diff=2.65226e-31
  0.000000	  0.000000	diff=7.67726e-30
  0.000000	  0.000000	diff=2.52031e-31
  0.000000	  0.000000	diff=5.62715e-13
  0.000450	  0.000428	diff=2.19286e-05
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=6.95443e-36
  0.000000	  0.000000	diff=1.11817e-28
  0.000000	  0.000000	diff=1.76192e-31
  0.000000	  0.000000	diff=5.90119e-31
  0.000000	 -0.000000	diff=1.67428e-31
  0.000000	 -0.000000	diff=5.70229e-13
  0.000000	  0.000000	diff=7.35255e-11
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=6.99214e-37
  0.000000	 -0.000000	diff=6.40794e-33
  0.000000	 -0.000000	diff=1.01069e-35
  0.000000	  0.000000	diff=8.40257e-36
  0.000000	  0.000000	diff=4.81695e-36
  0.000000	  0.000000	diff=3.26791e-17
 -0.000000	 -0.000000	diff=7.55856e-13
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=4.00763e-41
  local_diff=2.20557e-05
# W_tgt{1}, [8 6]
  0.665977	  0.690935	diff=0.0249579
  0.000000	  0.000000	diff=4.854e-10
  0.000000	  0.000000	diff=1.09604e-10
 -0.000000	 -0.000000	diff=8.31765e-13
-18.274228	-18.730010	diff=0.455782
  1.109839	  1.149613	diff=0.0397738
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.847529	 -0.811348	diff=0.0361808
  0.000000	  0.000000	diff=6.54257e-10
  0.000000	  0.000000	diff=6.09258e-12
  0.000000	  0.000000	diff=1.25222e-12
 22.609305	 21.994195	diff=0.61511
 -1.407330	 -1.349962	diff=0.0573681
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.60996e-36
  0.000000	  0.000000	diff=4.20065e-13
  0.000000	 -0.000000	diff=1.66166e-13
  0.000000	  0.000000	diff=5.21662e-62
  0.000000	 -0.000000	diff=6.33113e-39
  0.000000	 -0.000000	diff=2.09809e-30
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=3.86709e-32
  0.000000	  0.000000	diff=1.27216e-30
  0.000000	  0.000000	diff=8.70148e-13
  0.000000	 -0.000000	diff=9.14735e-60
  0.000000	  0.000000	diff=4.32829e-40
  0.000000	 -0.000000	diff=1.59049e-31
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000331	  0.000330	diff=1.19105e-06
  0.000000	  0.000000	diff=4.20065e-13
  0.000000	 -0.000000	diff=1.66166e-13
  0.000000	  0.000000	diff=2.63438e-13
 -0.006521	 -0.006498	diff=2.29323e-05
 -0.111675	 -0.111293	diff=0.000381317
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=3.24856e-13
  0.000000	  0.000000	diff=1.27216e-30
  0.000000	  0.000000	diff=8.70148e-13
  0.000000	 -0.000000	diff=1.38642e-16
  0.000000	  0.000000	diff=1.48915e-13
  0.000008	  0.000008	diff=2.68628e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.22958
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000333	 -0.000347	diff=1.35904e-05
 -0.000013	 -0.000013	diff=1.84116e-08
 -0.000000	 -0.000000	diff=5.60943e-13
 -0.000000	 -0.000000	diff=2.59528e-13
  local_diff=1.36088e-05
# W_emb_tgt, [2 4]
-16.316047	-16.677489	diff=0.361442
-14.005769	-14.271785	diff=0.266017
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.00937e-09
 -0.000000	 -0.000000	diff=3.29865e-10
 -0.000000	 -0.000000	diff=1.12724e-12
 -0.000000	 -0.000000	diff=1.23536e-10
  local_diff=0.627458
# W_soft, [4 2]
  0.014631	  0.014616	diff=1.50311e-05
  0.151565	  0.151456	diff=0.000108968
 -0.406862	 -0.406893	diff=3.06572e-05
  0.240940	  0.240821	diff=0.000119271
 -1.424838	 -1.429208	diff=0.0043695
  2.618666	  2.617254	diff=0.00141252
  0.105468	  0.099156	diff=0.00631253
 -1.280499	 -1.287202	diff=0.00670337
  local_diff=0.0190718
# Num params=104, abs_diff=1.87614
Elapsed time is 0.668635 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'attnFunc', 0, 'feedInput', 1, 'numLayers', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 0
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# attnGlobal = 0
# attnLocalMono = 0
# attnLocalPred = 0
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s> x y y
  src mask: 0  1  1  1
  tgt input 1: <s> b b </s> </s>
  tgt output 1: b b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=2.15445e-24
 -0.000000	  0.000000	diff=7.14491e-13
  0.000000	  0.000000	diff=1.7299e-28
  0.000000	  0.000000	diff=1.69429e-23
  0.000000	  0.000000	diff=3.77489e-25
 -0.000000	  0.000000	diff=7.14484e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=2.75108e-24
  0.000000	 -0.000000	diff=1.71075e-14
  0.000000	 -0.000000	diff=2.19901e-28
  0.000000	 -0.000000	diff=7.34087e-23
  0.000000	 -0.000000	diff=1.63511e-24
  0.000000	 -0.000000	diff=1.70785e-14
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=7.59486e-54
  0.000000	 -0.000000	diff=1.36095e-41
  0.000000	 -0.000000	diff=1.24309e-59
  0.000000	 -0.000000	diff=6.76941e-54
  0.000000	 -0.000000	diff=1.39484e-51
  0.000000	 -0.000000	diff=1.35864e-41
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.47202e-42
  0.000000	  0.000000	diff=5.71942e-31
  0.000000	  0.000000	diff=1.16737e-47
  0.000000	  0.000000	diff=3.03682e-44
  0.000000	  0.000000	diff=4.74941e-41
  0.000000	  0.000000	diff=5.70972e-31
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.46316e-12
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=4.53762e-42
  0.000000	 -0.000000	diff=2.14155e-41
  0.000000	 -0.000000	diff=8.9099e-43
  0.000000	 -0.000000	diff=5.20718e-42
  0.000000	  0.000000	diff=4.77974e-42
  0.000000	 -0.000000	diff=2.66897e-41
  0.000000	 -0.000000	diff=1.81382e-26
  0.000000	 -0.000000	diff=6.06482e-26
  0.000000	 -0.000000	diff=1.05573e-31
  0.000000	  0.000000	diff=9.68972e-31
  0.000000	  0.000000	diff=7.73067e-33
  0.000000	  0.000000	diff=3.14478e-31
  0.000000	 -0.000000	diff=1.29258e-31
  0.000000	  0.000000	diff=1.32984e-30
  0.000000	  0.000000	diff=1.20203e-15
  0.000000	  0.000000	diff=1.88219e-15
  0.000000	  0.000000	diff=1.03886e-33
  0.000000	 -0.000000	diff=6.18645e-32
  0.000000	 -0.000000	diff=1.43998e-33
  0.000000	 -0.000000	diff=1.91375e-32
  0.000000	  0.000000	diff=2.32774e-33
  0.000000	 -0.000000	diff=5.9028e-32
  0.000000	  0.000000	diff=2.42931e-16
  0.000000	 -0.000000	diff=5.10375e-17
  0.000000	 -0.000000	diff=1.36325e-32
  0.000000	  0.000000	diff=1.66374e-30
  0.000000	 -0.000000	diff=4.04483e-33
  0.000000	  0.000000	diff=6.04443e-31
  0.000000	 -0.000000	diff=1.73299e-32
  0.000000	  0.000000	diff=2.94736e-30
  0.000000	  0.000000	diff=3.58103e-16
  0.000000	  0.000000	diff=2.20533e-15
  local_diff=5.94161e-15
# W_tgt{1}, [8 6]
 -0.000001	 -0.000001	diff=1.88913e-09
  0.000000	  0.000000	diff=3.15788e-18
 -0.000000	 -0.000000	diff=2.53582e-11
  0.000000	  0.000000	diff=1.01535e-25
 -0.000001	 -0.000001	diff=5.03243e-08
  0.000000	  0.000000	diff=9.90328e-12
  0.000000	 -0.000000	diff=1.00033e-43
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=8.50309e-10
  0.000000	 -0.000000	diff=5.35104e-18
 -0.000000	 -0.000000	diff=1.05437e-11
  0.000000	  0.000000	diff=6.51967e-26
 -0.000001	 -0.000001	diff=2.05349e-08
  0.000000	  0.000000	diff=3.66505e-12
  0.000000	  0.000000	diff=1.69504e-43
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.15066e-15
  0.000000	 -0.000000	diff=8.37396e-37
  0.000000	 -0.000000	diff=3.42575e-18
  0.000000	  0.000000	diff=2.42584e-34
  0.000000	 -0.000000	diff=2.01804e-15
  0.000000	  0.000000	diff=5.14885e-19
  0.000000	 -0.000000	diff=9.01108e-75
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.73834e-16
  0.000000	 -0.000000	diff=5.54152e-37
  0.000000	  0.000000	diff=5.17539e-19
  0.000000	 -0.000000	diff=3.66478e-35
  0.000000	  0.000000	diff=3.04872e-16
  0.000000	 -0.000000	diff=7.7785e-20
  0.000000	  0.000000	diff=4.38452e-75
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.21901e-15
  0.000000	 -0.000000	diff=5.65528e-39
  0.000000	  0.000000	diff=3.62924e-18
  0.000000	 -0.000000	diff=2.56993e-34
  0.000000	  0.000000	diff=2.13791e-15
  0.000000	 -0.000000	diff=5.45468e-19
  0.000000	  0.000000	diff=2.57998e-74
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=3.67957e-20
  0.000000	 -0.000000	diff=2.2675e-35
  0.000000	  0.000000	diff=1.09958e-22
  0.000000	 -0.000000	diff=7.81482e-39
  0.000000	  0.000000	diff=6.45327e-20
  0.000000	 -0.000000	diff=1.65384e-23
  0.000000	  0.000000	diff=2.90062e-67
  0.000000	  0.000000	diff=0
  local_diff=7.36481e-08
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=1.14953e-15
  0.000000	  0.000000	diff=2.43245e-15
  0.000000	  0.000000	diff=2.30865e-16
  0.000000	  0.000000	diff=3.0348e-16
  0.000000	  0.000000	diff=6.88977e-16
  0.000000	  0.000000	diff=1.82705e-15
  0.000000	  0.000000	diff=1.8177e-13
 -0.000000	 -0.000000	diff=6.47252e-13
  0.000000	  0.000000	diff=3.82377e-20
  0.000000	  0.000000	diff=7.59735e-20
  0.000000	  0.000000	diff=7.20752e-21
  0.000000	  0.000000	diff=9.47454e-21
  0.000000	  0.000000	diff=2.40474e-20
  0.000000	  0.000000	diff=5.73201e-20
  0.000000	  0.000000	diff=8.13338e-14
 -0.000000	 -0.000000	diff=1.0627e-12
  0.000000	  0.000000	diff=1.90747e-15
  0.000000	 -0.000000	diff=2.9684e-15
  0.000000	 -0.000000	diff=6.52651e-16
  0.000000	 -0.000000	diff=8.57925e-16
  0.000000	  0.000000	diff=1.25482e-15
  0.000000	 -0.000000	diff=3.82632e-15
 -0.000000	 -0.000000	diff=4.43623e-13
  0.000000	  0.000000	diff=3.79858e-13
  0.000000	 -0.000000	diff=2.88163e-16
  0.000000	  0.000000	diff=4.48441e-16
  0.000000	  0.000000	diff=9.85969e-17
  0.000000	  0.000000	diff=1.29608e-16
  0.000000	 -0.000000	diff=1.89566e-16
  0.000000	  0.000000	diff=5.78049e-16
  0.000000	  0.000000	diff=1.37163e-13
 -0.000000	 -0.000000	diff=1.49624e-13
  local_diff=3.10316e-12
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=3.37314e-16
 -0.000000	  0.000000	diff=7.48364e-13
  0.000000	 -0.000000	diff=2.52839e-20
  0.000000	 -0.000000	diff=2.88587e-20
  local_diff=7.48701e-13
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=4.02888e-13
 -0.000000	 -0.000000	diff=1.3518e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=7.89532e-19
  0.000000	 -0.000000	diff=4.08172e-19
  0.000001	  0.000001	diff=4.94941e-08
 -0.000002	 -0.000001	diff=7.63413e-08
  local_diff=1.25836e-07
# W_soft, [4 2]
  0.000000	  0.000000	diff=1.63336e-13
 -0.000000	 -0.000000	diff=5.70279e-13
 -0.000000	 -0.000000	diff=1.78709e-13
  0.000000	  0.000000	diff=2.0178e-13
 -0.000000	 -0.000000	diff=6.28554e-13
  0.000000	  0.000000	diff=4.0722e-13
 -0.000000	 -0.000000	diff=1.98809e-13
 -0.000000	 -0.000000	diff=2.25247e-14
  local_diff=2.37121e-12
# Num params=168, abs_diff=1.99492e-07
Elapsed time is 1.411587 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'attnFunc', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 0
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# attnGlobal = 0
# attnLocalMono = 0
# attnLocalPred = 0
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s> x y y
  src mask: 0  1  1  1
  tgt input 1: <s> b b </s> </s>
  tgt output 1: b b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=4.94782e-29
  0.000000	  0.000000	diff=2.62773e-17
  0.000000	  0.000000	diff=1.20299e-32
  0.000000	  0.000000	diff=3.98999e-27
  0.000000	  0.000000	diff=1.34912e-09
  0.000000	  0.000000	diff=6.48803e-20
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.1804e-37
  0.000000	 -0.000000	diff=6.3016e-29
  0.000000	 -0.000000	diff=3.36015e-17
  0.000000	 -0.000000	diff=1.5292e-32
  0.000000	 -0.000000	diff=5.15717e-27
  0.000000	 -0.000000	diff=6.21514e-31
  0.000000	 -0.000000	diff=2.81112e-19
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.69906e-66
  0.000000	 -0.000000	diff=4.38391e-52
  0.000000	 -0.000000	diff=1.96685e-71
  0.000000	 -0.000000	diff=6.34695e-66
  0.000000	 -0.000000	diff=1.04107e-64
  0.000000	 -0.000000	diff=4.38199e-52
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.5472e-50
  0.000000	  0.000000	diff=4.94712e-39
  0.000000	  0.000000	diff=1.08246e-56
  0.000000	  0.000000	diff=1.26422e-55
  0.000000	  0.000000	diff=1.52539e-51
  0.000000	  0.000000	diff=4.94541e-39
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.34912e-09
# W_src{2}, [8 4]
  0.000038	  0.000038	diff=1.80882e-07
  0.000415	  0.000413	diff=1.98257e-06
  0.000000	 -0.000000	diff=3.63844e-53
  0.000000	 -0.000000	diff=2.06029e-52
  0.005013	  0.005034	diff=2.04479e-05
 -0.017474	 -0.017408	diff=6.5837e-05
 -0.000000	 -0.000000	diff=4.08246e-12
  0.000000	  0.000000	diff=1.79006e-09
  0.000000	 -0.000000	diff=4.61099e-39
  0.000000	  0.000000	diff=6.91356e-39
  0.000000	  0.000000	diff=7.42599e-40
  0.000000	  0.000000	diff=2.34178e-39
  0.000000	 -0.000000	diff=5.13193e-39
  0.000000	  0.000000	diff=9.82144e-39
  0.000000	  0.000000	diff=2.00637e-19
  0.000000	  0.000000	diff=9.34894e-20
  0.000000	  0.000000	diff=3.3088e-40
  0.000000	  0.000000	diff=5.28168e-40
  0.000000	 -0.000000	diff=1.76609e-40
  0.000000	  0.000000	diff=2.94944e-40
  0.000000	  0.000000	diff=2.38521e-40
  0.000000	  0.000000	diff=2.33133e-39
  0.000000	  0.000000	diff=7.04271e-20
  0.000000	  0.000000	diff=1.01853e-20
  0.000000	 -0.000000	diff=3.98453e-39
  0.000000	  0.000000	diff=1.07568e-38
  0.000000	  0.000000	diff=1.04197e-39
  0.000000	  0.000000	diff=3.68464e-39
  0.000000	 -0.000000	diff=3.69414e-39
  0.000000	  0.000000	diff=1.8885e-38
  0.000000	 -0.000000	diff=1.2146e-20
  0.000000	  0.000000	diff=1.30199e-19
  local_diff=8.84501e-05
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=3.45527e-10
  0.000000	 -0.000000	diff=3.73798e-21
  0.000000	 -0.000000	diff=3.66215e-24
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=2.0097e-09
 -0.000000	 -0.000000	diff=2.30805e-10
  0.000000	  0.000000	diff=8.73997e-64
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=1.45361e-10
  0.000000	  0.000000	diff=6.16526e-15
  0.000000	  0.000000	diff=1.87866e-24
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=8.17618e-10
  0.000000	  0.000000	diff=7.06152e-13
  0.000000	 -0.000000	diff=1.48098e-63
  0.000000	 -0.000000	diff=4.25443e-14
  0.000000	 -0.000000	diff=3.49673e-27
  0.000000	  0.000000	diff=1.70264e-32
  0.000000	 -0.000000	diff=1.22029e-43
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=5.76264e-27
  0.000000	 -0.000000	diff=2.62114e-23
  0.000000	 -0.000000	diff=1.57043e-93
  0.000000	 -0.000000	diff=2.64791e-34
  0.000000	  0.000000	diff=2.568e-13
  0.000000	  0.000000	diff=1.43274e-31
  0.000000	 -0.000000	diff=9.47536e-27
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=7.86381e-14
  0.000000	 -0.000000	diff=1.8717e-23
  0.000000	  0.000000	diff=9.11343e-77
  0.000000	 -0.000000	diff=2.22816e-33
  0.000000	 -0.000000	diff=7.71721e-56
  0.000000	 -0.000000	diff=1.3346e-41
  0.000000	  0.000000	diff=1.2448e-25
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.44065e-40
  0.000000	 -0.000000	diff=2.45677e-34
  0.000000	 -0.000000	diff=1.28386e-71
  0.000000	 -0.000000	diff=1.01822e-52
  0.000000	  0.000000	diff=1.07974e-34
  0.000000	 -0.000000	diff=4.40654e-32
  0.000000	  0.000000	diff=3.16473e-43
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.60383e-34
  0.000000	  0.000000	diff=2.17694e-23
  0.000000	  0.000000	diff=2.46413e-84
  0.000000	  0.000000	diff=6.85295e-34
  local_diff=3.5501e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=3.62451e-13
 -0.000000	 -0.000000	diff=1.3623e-13
 -0.000000	 -0.000000	diff=5.02925e-13
  0.000000	  0.000000	diff=5.4452e-14
  0.000000	  0.000000	diff=3.39417e-13
  0.000000	  0.000000	diff=2.12804e-14
  0.000000	  0.000000	diff=3.71072e-13
 -0.000000	 -0.000000	diff=5.09008e-13
  0.000000	 -0.000000	diff=6.03028e-20
  0.000000	  0.000000	diff=3.21492e-19
  0.000000	  0.000000	diff=2.83234e-24
  0.000000	  0.000000	diff=6.51055e-24
  0.000000	 -0.000000	diff=6.81393e-20
  0.000000	 -0.000000	diff=6.34477e-20
 -0.000000	 -0.000000	diff=3.17136e-13
  0.000000	  0.000000	diff=1.10669e-13
  0.021660	  0.021644	diff=1.62213e-05
 -0.010074	 -0.010082	diff=8.10324e-06
 -0.004782	 -0.004781	diff=9.56961e-07
  0.002654	  0.002654	diff=1.45711e-07
  0.035377	  0.035371	diff=5.56391e-06
 -0.003264	 -0.003268	diff=3.61935e-06
  0.015890	  0.015869	diff=2.0875e-05
  0.257396	  0.256733	diff=0.000663085
 -0.009115	 -0.009121	diff=5.81019e-06
  0.006978	  0.006988	diff=9.83407e-06
 -0.001094	 -0.001094	diff=4.8922e-07
 -0.041693	 -0.041925	diff=0.000231937
 -0.003097	 -0.003101	diff=4.02777e-06
  0.003241	  0.003238	diff=2.98127e-06
  0.032197	  0.032157	diff=3.96739e-05
 -0.488926	 -0.493737	diff=0.00481123
  local_diff=0.00582455
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=4.79244e-21
  0.000000	  0.000000	diff=6.21663e-19
  0.000000	  0.000000	diff=3.97312e-10
  0.000000	  0.000000	diff=4.98006e-17
  local_diff=3.97312e-10
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=3.56072e-10
  0.000000	 -0.000000	diff=4.47895e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.40444e-13
  0.000000	  0.000000	diff=6.05501e-16
  0.000000	  0.000000	diff=2.16515e-09
 -0.000000	 -0.000000	diff=3.52464e-09
  local_diff=6.04645e-09
# W_soft, [4 2]
  0.003314	  0.003257	diff=5.74002e-05
  0.063391	  0.063336	diff=5.48146e-05
 -0.169196	 -0.169247	diff=5.09466e-05
  0.102698	  0.102653	diff=4.43992e-05
 -0.035975	 -0.036002	diff=2.75974e-05
  0.098266	  0.098237	diff=2.84965e-05
 -0.088545	 -0.088565	diff=2.06253e-05
  0.026354	  0.026330	diff=2.37666e-05
  local_diff=0.000308046
# Num params=168, abs_diff=0.00622106
Elapsed time is 1.442464 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 1
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s> y x x
  src mask: 0  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000393	  0.000395	diff=2.31435e-06
  0.000000	  0.000000	diff=5.90717e-17
  0.000000	 -0.000000	diff=1.01121e-31
  0.000000	 -0.000000	diff=1.79704e-29
  0.049545	  0.049856	diff=0.000311143
  0.000000	  0.000000	diff=3.05592e-16
 -0.000078	 -0.000078	diff=9.18558e-07
  0.000000	  0.000000	diff=9.05392e-17
  0.000000	  0.000000	diff=5.19006e-25
  0.000000	 -0.000000	diff=8.89841e-17
  0.000000	  0.000000	diff=1.28543e-31
  0.000000	  0.000000	diff=7.78683e-29
  0.000000	  0.000000	diff=1.28878e-31
  0.000000	 -0.000000	diff=1.96825e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.922e-61
  0.000000	 -0.000000	diff=2.64522e-53
  0.000000	  0.000000	diff=4.25152e-68
  0.000000	  0.000000	diff=1.43935e-67
  0.000000	 -0.000000	diff=1.91907e-69
  0.000000	 -0.000000	diff=3.53224e-54
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=9.83931e-46
  0.000000	  0.000000	diff=1.27465e-37
  0.000000	 -0.000000	diff=2.17623e-52
  0.000000	  0.000000	diff=4.91486e-54
  0.000000	  0.000000	diff=1.12147e-54
  0.000000	  0.000000	diff=1.01476e-38
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.000314376
# W_src{2}, [8 4]
  0.000526	  0.000524	diff=2.33011e-06
 -0.000008	 -0.000008	diff=6.88403e-07
  0.000000	  0.000000	diff=1.00658e-53
  0.000000	  0.000000	diff=6.75654e-53
  0.034292	  0.034446	diff=0.000153561
 -0.121218	 -0.120598	diff=0.000619542
 -0.000000	 -0.000000	diff=9.19263e-11
  0.000001	  0.000001	diff=5.4531e-09
  0.000000	  0.000000	diff=3.01642e-38
  0.000000	  0.000000	diff=6.80411e-38
  0.000000	 -0.000000	diff=6.33768e-39
  0.000000	  0.000000	diff=2.07794e-38
  0.000000	  0.000000	diff=3.26842e-38
  0.000000	  0.000000	diff=1.10584e-37
  0.000000	 -0.000000	diff=5.76365e-19
  0.000000	  0.000000	diff=1.10704e-18
  0.000000	 -0.000000	diff=3.7436e-39
  0.000000	 -0.000000	diff=1.28035e-38
  0.000000	  0.000000	diff=1.71235e-39
  0.000000	 -0.000000	diff=5.53862e-39
  0.000000	 -0.000000	diff=2.27834e-39
  0.000000	 -0.000000	diff=3.03046e-38
  0.000000	 -0.000000	diff=4.84965e-19
  0.000000	 -0.000000	diff=1.45422e-19
  0.000000	  0.000000	diff=3.58745e-38
  0.000000	  0.000000	diff=1.02634e-37
  0.000000	 -0.000000	diff=1.12148e-38
  0.000000	  0.000000	diff=3.62376e-38
  0.000000	  0.000000	diff=3.17327e-38
  0.000000	  0.000000	diff=2.14264e-37
  0.000000	  0.000000	diff=3.77412e-19
  0.000000	  0.000000	diff=6.31387e-19
  local_diff=0.000776127
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=2.06512e-11
  0.000000	 -0.000000	diff=4.20559e-22
  0.000000	  0.000000	diff=8.85418e-13
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=4.22543e-10
  0.000000	  0.000000	diff=6.95415e-13
  0.000000	 -0.000000	diff=1.36226e-55
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=7.42768e-12
  0.016850	  0.017432	diff=0.000581548
 -0.000005	 -0.000005	diff=1.63486e-07
  0.000000	  0.000000	diff=6.27819e-18
 -0.000000	 -0.000000	diff=1.71087e-10
  0.000044	  0.000046	diff=1.54441e-06
  0.000000	  0.000000	diff=2.30833e-55
  3.273790	  3.530125	diff=0.256335
 -0.000000	 -0.000000	diff=6.66674e-13
 -0.002587	 -0.002574	diff=1.34491e-05
  0.000001	  0.000001	diff=3.91209e-09
  0.000000	 -0.000000	diff=9.58608e-19
 -0.000000	 -0.000000	diff=7.17863e-13
 -0.000007	 -0.000007	diff=3.46445e-08
  0.000000	 -0.000000	diff=8.35222e-94
 -0.000002	 -0.000002	diff=1.77157e-08
 -0.000000	 -0.000000	diff=2.97545e-13
 -0.002502	 -0.002489	diff=1.25791e-05
  0.000001	  0.000001	diff=3.65966e-09
  0.000000	 -0.000000	diff=9.27136e-19
 -0.000000	 -0.000000	diff=9.29854e-14
 -0.000006	 -0.000006	diff=3.24026e-08
  0.000000	  0.000000	diff=6.0275e-93
 -0.000002	 -0.000002	diff=1.65686e-08
  0.000000	 -0.000000	diff=1.00608e-19
 -0.001870	 -0.001862	diff=7.0359e-06
  0.000001	  0.000001	diff=2.04647e-09
  0.000000	 -0.000000	diff=6.93683e-19
 -0.000000	 -0.000000	diff=4.18674e-13
 -0.000005	 -0.000005	diff=1.81249e-08
  0.000000	  0.000000	diff=1.27021e-59
 -0.000001	 -0.000001	diff=9.25933e-09
  0.000000	 -0.000000	diff=1.88469e-25
  0.001802	  0.001809	diff=6.60194e-06
 -0.000001	 -0.000001	diff=1.91948e-09
  0.000000	  0.000000	diff=6.73598e-19
  0.000000	  0.000000	diff=1.7224e-16
  0.000005	  0.000005	diff=1.70042e-08
  0.000000	 -0.000000	diff=5.23542e-81
  0.000001	  0.000001	diff=8.64488e-09
  local_diff=0.256958
# W_tgt{2}, [8 4]
  0.000482	  0.000487	diff=4.30136e-06
 -0.129208	 -0.128560	diff=0.000648313
  0.000000	  0.000000	diff=3.92053e-10
 -0.000203	 -0.000202	diff=1.22106e-06
 -0.000000	 -0.000000	diff=1.35503e-11
 -2.188387	 -2.180283	diff=0.00810429
 -0.000023	 -0.000022	diff=2.11441e-07
  0.000000	  0.000000	diff=4.03029e-09
 -0.000167	 -0.000166	diff=8.42193e-07
  0.121537	  0.122118	diff=0.000580739
 -0.000000	 -0.000000	diff=2.39892e-10
  0.000159	  0.000159	diff=7.54626e-07
  0.000000	  0.000000	diff=1.33638e-10
  2.025519	  2.033286	diff=0.00776719
  0.000022	  0.000022	diff=1.97718e-07
 -0.000000	 -0.000000	diff=3.79194e-09
 -0.024677	 -0.024648	diff=2.91065e-05
  0.000328	  0.000334	diff=5.85217e-06
  0.006198	  0.006197	diff=1.09709e-06
  0.005354	  0.005355	diff=1.22397e-06
 -0.041750	 -0.041714	diff=3.61893e-05
  0.002963	  0.002970	diff=6.5142e-06
 -0.018507	 -0.018477	diff=2.95755e-05
 -0.261233	 -0.258622	diff=0.00261134
 -0.036828	 -0.036703	diff=0.000125186
  0.017313	  0.017314	diff=1.03327e-06
 -0.006158	 -0.006130	diff=2.80337e-05
  0.025949	  0.026236	diff=0.000286322
 -0.011835	 -0.011836	diff=9.2967e-07
 -0.053136	 -0.053227	diff=9.17339e-05
 -0.015070	 -0.015036	diff=3.40434e-05
 -0.314725	 -0.297261	diff=0.0174643
  local_diff=0.0378605
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.140807	  0.143386	diff=0.00257852
  0.000000	  0.000000	diff=4.3527e-17
 -0.000000	 -0.000000	diff=2.11479e-09
  0.000000	  0.000000	diff=1.03568e-16
  local_diff=0.00257852
# W_emb_tgt, [2 4]
 -0.000000	 -0.000000	diff=7.65681e-13
 -0.000000	 -0.000000	diff=4.97275e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=6.41432e-23
  0.000000	 -0.000000	diff=1.95704e-14
  0.000000	  0.000000	diff=3.92794e-10
  0.174029	  0.174701	diff=0.000671944
  local_diff=0.000671945
# W_h, [2 4]
  0.010789	  0.010789	diff=6.83588e-07
  0.024449	  0.024454	diff=4.77301e-06
 -0.261230	 -0.261774	diff=0.000543994
 -0.922887	 -0.916190	diff=0.00669664
  1.097887	  1.097456	diff=0.000431449
 -0.084006	 -0.083814	diff=0.000191251
 -0.368926	 -0.369438	diff=0.000512338
  1.021960	  1.023282	diff=0.00132243
  local_diff=0.00970356
# W_soft, [4 2]
 -5.793578	 -5.796186	diff=0.00260783
  2.180922	  2.180867	diff=5.49837e-05
  3.327966	  3.327960	diff=5.7865e-06
  0.289928	  0.287358	diff=0.00256992
 -8.666501	 -8.670328	diff=0.00382729
  2.884374	  2.884318	diff=5.56152e-05
  4.954382	  4.954377	diff=5.16442e-06
  0.835411	  0.831633	diff=0.00377831
  local_diff=0.0129049
# Num params=176, abs_diff=0.321768
Elapsed time is 2.346386 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 2, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 2
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s> y x x
  src mask: 0  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000393	  0.000395	diff=2.31435e-06
  0.000000	  0.000000	diff=5.86357e-17
  0.000000	 -0.000000	diff=1.01121e-31
  0.000000	 -0.000000	diff=1.56101e-29
  0.049545	  0.049856	diff=0.000311143
  0.000000	  0.000000	diff=3.05156e-16
 -0.000078	 -0.000078	diff=9.18558e-07
  0.000000	  0.000000	diff=9.05392e-17
  0.000000	  0.000000	diff=5.19006e-25
  0.000000	 -0.000000	diff=8.70954e-17
  0.000000	  0.000000	diff=1.28543e-31
  0.000000	  0.000000	diff=6.76419e-29
  0.000000	  0.000000	diff=1.10378e-31
  0.000000	 -0.000000	diff=1.77944e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.922e-61
  0.000000	 -0.000000	diff=2.58988e-53
  0.000000	  0.000000	diff=4.25152e-68
  0.000000	  0.000000	diff=1.24915e-67
  0.000000	 -0.000000	diff=1.47745e-69
  0.000000	 -0.000000	diff=2.97903e-54
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=9.83931e-46
  0.000000	  0.000000	diff=1.23586e-37
  0.000000	 -0.000000	diff=2.17623e-52
  0.000000	  0.000000	diff=4.81602e-54
  0.000000	 -0.000000	diff=2.05461e-54
  0.000000	  0.000000	diff=6.26916e-39
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.000314376
# W_src{2}, [8 4]
  0.000526	  0.000524	diff=2.33011e-06
 -0.000008	 -0.000008	diff=6.88403e-07
  0.000000	  0.000000	diff=9.33329e-54
  0.000000	  0.000000	diff=5.87228e-53
  0.034292	  0.034446	diff=0.000153561
 -0.121218	 -0.120598	diff=0.000619542
 -0.000000	 -0.000000	diff=9.19263e-11
  0.000001	  0.000001	diff=5.4531e-09
  0.000000	  0.000000	diff=3.03845e-38
  0.000000	  0.000000	diff=6.09627e-38
  0.000000	 -0.000000	diff=6.37107e-39
  0.000000	  0.000000	diff=1.88035e-38
  0.000000	  0.000000	diff=3.29517e-38
  0.000000	  0.000000	diff=1.04235e-37
  0.000000	 -0.000000	diff=5.86128e-19
  0.000000	  0.000000	diff=9.76649e-19
  0.000000	 -0.000000	diff=3.78723e-39
  0.000000	 -0.000000	diff=1.19126e-38
  0.000000	  0.000000	diff=1.72892e-39
  0.000000	 -0.000000	diff=5.33636e-39
  0.000000	 -0.000000	diff=2.31035e-39
  0.000000	 -0.000000	diff=2.95415e-38
  0.000000	 -0.000000	diff=4.89206e-19
  0.000000	 -0.000000	diff=1.36941e-19
  0.000000	  0.000000	diff=3.56754e-38
  0.000000	  0.000000	diff=8.87688e-38
  0.000000	 -0.000000	diff=1.11926e-38
  0.000000	  0.000000	diff=3.07266e-38
  0.000000	  0.000000	diff=3.15014e-38
  0.000000	  0.000000	diff=1.97248e-37
  0.000000	  0.000000	diff=3.67221e-19
  0.000000	  0.000000	diff=4.75352e-19
  local_diff=0.000776127
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=2.06512e-11
  0.000000	 -0.000000	diff=4.20559e-22
  0.000000	  0.000000	diff=8.85418e-13
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=4.22543e-10
  0.000000	  0.000000	diff=6.95415e-13
  0.000000	 -0.000000	diff=1.36226e-55
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=7.42768e-12
  0.016850	  0.017432	diff=0.000581548
 -0.000005	 -0.000005	diff=1.63486e-07
  0.000000	  0.000000	diff=6.27819e-18
 -0.000000	 -0.000000	diff=1.71087e-10
  0.000044	  0.000046	diff=1.54441e-06
  0.000000	  0.000000	diff=2.30833e-55
  3.273790	  3.530125	diff=0.256335
 -0.000000	 -0.000000	diff=6.66674e-13
 -0.002587	 -0.002574	diff=1.34491e-05
  0.000001	  0.000001	diff=3.91209e-09
  0.000000	 -0.000000	diff=9.58608e-19
 -0.000000	 -0.000000	diff=7.17863e-13
 -0.000007	 -0.000007	diff=3.46445e-08
  0.000000	 -0.000000	diff=8.35222e-94
 -0.000002	 -0.000002	diff=1.77157e-08
 -0.000000	 -0.000000	diff=2.97545e-13
 -0.002502	 -0.002489	diff=1.25791e-05
  0.000001	  0.000001	diff=3.65966e-09
  0.000000	 -0.000000	diff=9.27136e-19
 -0.000000	 -0.000000	diff=9.29854e-14
 -0.000006	 -0.000006	diff=3.24026e-08
  0.000000	  0.000000	diff=6.01707e-93
 -0.000002	 -0.000002	diff=1.65686e-08
  0.000000	 -0.000000	diff=1.00608e-19
 -0.001870	 -0.001862	diff=7.0359e-06
  0.000001	  0.000001	diff=2.04647e-09
  0.000000	 -0.000000	diff=6.93683e-19
 -0.000000	 -0.000000	diff=4.18674e-13
 -0.000005	 -0.000005	diff=1.81249e-08
  0.000000	  0.000000	diff=1.27021e-59
 -0.000001	 -0.000001	diff=9.25933e-09
  0.000000	 -0.000000	diff=1.88469e-25
  0.001802	  0.001809	diff=6.60194e-06
 -0.000001	 -0.000001	diff=1.91948e-09
  0.000000	  0.000000	diff=6.73598e-19
  0.000000	  0.000000	diff=1.7224e-16
  0.000005	  0.000005	diff=1.70042e-08
  0.000000	 -0.000000	diff=5.23542e-81
  0.000001	  0.000001	diff=8.64488e-09
  local_diff=0.256958
# W_tgt{2}, [8 4]
  0.000482	  0.000487	diff=4.30136e-06
 -0.129208	 -0.128560	diff=0.000648313
  0.000000	  0.000000	diff=3.92053e-10
 -0.000203	 -0.000202	diff=1.22106e-06
 -0.000000	 -0.000000	diff=1.35503e-11
 -2.188387	 -2.180283	diff=0.00810429
 -0.000023	 -0.000022	diff=2.11441e-07
  0.000000	  0.000000	diff=4.03029e-09
 -0.000167	 -0.000166	diff=8.42193e-07
  0.121537	  0.122118	diff=0.000580739
 -0.000000	 -0.000000	diff=2.39892e-10
  0.000159	  0.000159	diff=7.54626e-07
  0.000000	  0.000000	diff=1.33638e-10
  2.025519	  2.033286	diff=0.00776719
  0.000022	  0.000022	diff=1.97718e-07
 -0.000000	 -0.000000	diff=3.79194e-09
 -0.024677	 -0.024648	diff=2.91065e-05
  0.000328	  0.000334	diff=5.85217e-06
  0.006198	  0.006197	diff=1.09709e-06
  0.005354	  0.005355	diff=1.22397e-06
 -0.041750	 -0.041714	diff=3.61893e-05
  0.002963	  0.002970	diff=6.5142e-06
 -0.018507	 -0.018477	diff=2.95755e-05
 -0.261233	 -0.258622	diff=0.00261134
 -0.036828	 -0.036703	diff=0.000125186
  0.017313	  0.017314	diff=1.03327e-06
 -0.006158	 -0.006130	diff=2.80337e-05
  0.025949	  0.026236	diff=0.000286322
 -0.011835	 -0.011836	diff=9.2967e-07
 -0.053136	 -0.053227	diff=9.17339e-05
 -0.015070	 -0.015036	diff=3.40434e-05
 -0.314725	 -0.297261	diff=0.0174643
  local_diff=0.0378605
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.140807	  0.143386	diff=0.00257852
  0.000000	  0.000000	diff=3.93516e-17
 -0.000000	 -0.000000	diff=2.11479e-09
  0.000000	  0.000000	diff=1.03568e-16
  local_diff=0.00257852
# W_emb_tgt, [2 4]
 -0.000000	 -0.000000	diff=7.65681e-13
 -0.000000	 -0.000000	diff=4.97275e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=6.41432e-23
  0.000000	 -0.000000	diff=1.95704e-14
  0.000000	  0.000000	diff=3.92794e-10
  0.174029	  0.174701	diff=0.000671944
  local_diff=0.000671945
# W_h, [2 4]
  0.010789	  0.010789	diff=6.83588e-07
  0.024449	  0.024454	diff=4.77301e-06
 -0.261230	 -0.261774	diff=0.000543994
 -0.922887	 -0.916190	diff=0.00669664
  1.097887	  1.097456	diff=0.000431449
 -0.084006	 -0.083814	diff=0.000191251
 -0.368926	 -0.369438	diff=0.000512338
  1.021960	  1.023282	diff=0.00132243
  local_diff=0.00970356
# W_soft, [4 2]
 -5.793578	 -5.796186	diff=0.00260783
  2.180922	  2.180867	diff=5.49837e-05
  3.327966	  3.327960	diff=5.7865e-06
  0.289928	  0.287358	diff=0.00256992
 -8.666501	 -8.670328	diff=0.00382729
  2.884374	  2.884318	diff=5.56152e-05
  4.954382	  4.954377	diff=5.16442e-06
  0.835411	  0.831633	diff=0.00377831
  local_diff=0.0129049
# Num params=176, abs_diff=0.321768
Elapsed time is 2.468738 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 4
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000020	  0.000020	diff=1.19702e-07
  0.000158	 -0.000005	diff=0.00016318
 -0.000000	 -0.000000	diff=3.79136e-10
  0.000006	  0.000006	diff=3.00514e-08
 -0.019692	 -0.019538	diff=0.000154198
 -0.000104	 -0.000103	diff=7.06928e-07
 -0.000005	 -0.000005	diff=6.23523e-08
  0.000053	  0.000053	diff=5.21627e-07
  0.000000	  0.000000	diff=5.1051e-09
 -0.000194	 -0.000000	diff=0.000193484
  0.000000	  0.000000	diff=1.4879e-33
  0.000000	 -0.000000	diff=1.14551e-25
  0.000000	 -0.000000	diff=5.91303e-30
  0.000000	 -0.000000	diff=1.80097e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000005	  0.000005	diff=1.77024e-08
  0.000003	  0.000003	diff=9.95974e-09
  0.000000	  0.000000	diff=1.75556e-10
 -0.000003	 -0.000003	diff=1.16707e-08
  0.014496	  0.014553	diff=5.7821e-05
  0.000049	  0.000049	diff=1.73519e-07
 -0.000000	 -0.000000	diff=2.80262e-13
 -0.000000	 -0.000000	diff=3.79726e-10
 -0.000000	 -0.000000	diff=1.31348e-12
  0.000000	  0.000000	diff=1.83824e-13
 -0.000000	 -0.000000	diff=2.43885e-13
  0.000000	  0.000000	diff=2.91847e-13
 -0.000028	 -0.000028	diff=3.71991e-09
  0.000001	  0.000001	diff=4.99505e-11
  0.000000	  0.000000	diff=4.66506e-13
 -0.000000	 -0.000000	diff=3.07049e-13
  local_diff=0.000570346
# W_src{2}, [8 4]
 -0.000588	 -0.000585	diff=2.5476e-06
  0.000125	  0.000124	diff=4.85875e-07
 -0.000023	 -0.000023	diff=7.97532e-08
 -0.000000	 -0.000000	diff=9.0729e-10
 -0.023150	 -0.023019	diff=0.00013055
 -0.011376	 -0.011347	diff=2.97192e-05
  0.000782	  0.000789	diff=6.62581e-06
 -0.000000	 -0.000000	diff=7.15729e-11
  0.000000	 -0.000000	diff=1.80015e-38
  0.000000	  0.000000	diff=1.054e-37
  0.000000	  0.000000	diff=7.52237e-39
  0.000000	  0.000000	diff=4.32932e-38
  0.000000	 -0.000000	diff=1.16579e-38
  0.000000	  0.000000	diff=1.68256e-37
  0.000000	 -0.000000	diff=9.09115e-19
  0.000000	  0.000000	diff=6.2568e-19
 -0.000317	 -0.000316	diff=1.11321e-06
  0.000267	  0.000266	diff=9.09454e-07
 -0.000001	 -0.000001	diff=1.85421e-09
  0.000001	  0.000001	diff=2.90036e-09
 -0.000668	 -0.000667	diff=6.24788e-07
 -0.000226	 -0.000226	diff=3.62964e-08
  0.000726	  0.000732	diff=5.71225e-06
  0.000000	  0.000000	diff=1.58999e-11
  0.000089	  0.000089	diff=8.98581e-08
  0.000092	  0.000093	diff=5.47743e-07
  0.000024	  0.000024	diff=8.78324e-08
  0.000001	  0.000001	diff=4.91936e-09
  0.026478	  0.026652	diff=0.00017376
  0.008571	  0.008574	diff=3.07465e-06
 -0.000205	 -0.000204	diff=4.4998e-07
 -0.000000	 -0.000000	diff=1.0598e-12
  local_diff=0.000356425
# W_tgt{1}, [8 6]
 -0.000001	 -0.000001	diff=4.19801e-09
  0.000000	 -0.000000	diff=5.93927e-20
  0.000000	  0.000000	diff=3.33753e-12
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=5.0626e-08
 -0.000000	 -0.000000	diff=7.51526e-13
  0.000000	  0.000000	diff=5.90485e-53
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=1.82159e-09
  0.000000	  0.000000	diff=1.2389e-12
  0.000000	  0.000000	diff=1.68655e-12
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=2.06042e-08
  0.000000	  0.000000	diff=1.6857e-12
  0.000000	 -0.000000	diff=1.00057e-52
 -0.000000	 -0.000000	diff=4.0213e-13
  0.000000	  0.000000	diff=6.94016e-12
  0.000000	  0.000000	diff=3.58775e-13
 -0.000000	 -0.000000	diff=2.42289e-13
  0.000000	  0.000000	diff=6.20853e-14
 -0.000000	 -0.000000	diff=1.43713e-11
  0.000000	  0.000000	diff=1.08379e-14
 -0.000000	 -0.000001	diff=4.99793e-07
  0.000003	  0.000002	diff=1.07353e-06
  0.000000	  0.000000	diff=7.01618e-12
 -0.000000	 -0.000000	diff=2.58601e-13
 -0.000000	 -0.000000	diff=1.05059e-12
 -0.000000	 -0.000000	diff=3.99415e-13
 -0.000000	 -0.000000	diff=1.39014e-11
 -0.000000	 -0.000000	diff=2.61914e-13
  0.000003	  0.000005	diff=1.97835e-06
 -0.000013	 -0.000009	diff=4.20626e-06
 -0.000027	 -0.000027	diff=6.56326e-08
  0.000000	  0.000000	diff=5.73235e-13
 -0.000031	 -0.000031	diff=9.11821e-08
  0.000000	  0.000000	diff=1.02302e-12
 -0.000012	 -0.000012	diff=3.45513e-08
 -0.000000	 -0.000000	diff=5.12906e-13
 -0.000000	 -0.000000	diff=4.22781e-11
  0.000000	  0.000000	diff=6.80762e-12
 -0.000001	 -0.000001	diff=1.01452e-10
  0.000000	  0.000000	diff=1.20733e-13
 -0.000001	 -0.000001	diff=1.46778e-10
  0.000000	  0.000000	diff=8.33417e-14
 -0.000000	 -0.000000	diff=6.25166e-11
  0.000000	  0.000000	diff=2.63575e-13
 -0.000000	 -0.000000	diff=6.84447e-08
  0.000000	  0.000000	diff=1.46928e-07
  local_diff=8.24234e-06
# W_tgt{2}, [8 4]
  0.001410	  0.001412	diff=1.464e-06
 -0.000000	 -0.000000	diff=2.93398e-10
 -0.000000	 -0.000000	diff=8.25959e-10
  0.000002	  0.000002	diff=9.62961e-10
 -0.000062	 -0.000061	diff=2.88258e-07
  0.000004	  0.000004	diff=1.78148e-08
  0.000001	  0.000002	diff=2.03498e-07
 -0.000003	 -0.000003	diff=4.4258e-08
 -0.000000	 -0.000000	diff=2.96047e-13
  0.000000	  0.000000	diff=6.09366e-13
 -0.000000	 -0.000000	diff=3.24934e-13
  0.000000	  0.000000	diff=8.44173e-14
 -0.000000	 -0.000000	diff=8.03062e-14
  0.000000	  0.000000	diff=5.43826e-13
  0.000000	  0.000005	diff=4.31779e-06
 -0.000013	 -0.000010	diff=2.86293e-06
  0.001093	  0.001093	diff=5.90998e-07
 -0.000000	 -0.000000	diff=1.58349e-10
 -0.000000	 -0.000000	diff=4.53642e-10
  0.000001	  0.000001	diff=5.24e-10
 -0.000052	 -0.000051	diff=2.05837e-07
  0.000003	  0.000003	diff=9.64209e-09
 -0.000000	 -0.000000	diff=3.65474e-09
  0.000000	  0.000000	diff=5.19358e-10
 -0.000300	 -0.000300	diff=7.34139e-08
  0.000000	  0.000000	diff=1.68296e-11
  0.000000	  0.000000	diff=4.80336e-11
 -0.000000	 -0.000000	diff=5.85121e-11
  0.000009	  0.000009	diff=1.02734e-08
 -0.000001	 -0.000001	diff=1.06621e-09
 -0.000000	 -0.000000	diff=3.09226e-08
  0.000000	  0.000000	diff=6.99742e-09
  local_diff=1.01352e-05
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.055225	 -0.053908	diff=0.00131691
  0.000000	  0.000000	diff=3.14847e-17
  0.000276	  0.000000	diff=0.000276148
  0.000319	  0.000000	diff=0.000318753
  local_diff=0.00191182
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=8.73261e-16
 -0.000000	 -0.000000	diff=6.5708e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.21566e-20
  0.000000	 -0.000000	diff=9.68362e-16
  0.000001	  0.000001	diff=5.11986e-08
 -0.000001	 -0.000001	diff=8.12709e-08
  local_diff=1.3247e-07
# W_pos, [2 2]
  0.013483	  0.013517	diff=3.4179e-05
  0.005323	  0.005291	diff=3.21478e-05
 -0.000000	 -0.000000	diff=8.69149e-14
 -0.000000	 -0.000000	diff=3.00446e-13
  local_diff=6.63268e-05
# v_pos, [1 2]
 -0.022079	 -0.021905	diff=0.000174608
 -0.076306	 -0.074289	diff=0.00201677
  local_diff=0.00219138
# W_h, [2 4]
 -0.000001	 -0.000001	diff=2.4264e-09
  0.018819	  0.018878	diff=5.95072e-05
  0.000000	  0.000000	diff=5.93914e-10
 -0.009100	 -0.009086	diff=1.38216e-05
 -0.000003	 -0.000004	diff=7.33727e-07
  0.055878	  0.056410	diff=0.000531996
 -0.000002	 -0.000007	diff=5.38299e-06
  0.000011	  0.000006	diff=4.7819e-06
  local_diff=0.000616227
# W_soft, [4 2]
 -0.009536	 -0.009583	diff=4.76194e-05
 -0.007614	 -0.010962	diff=0.00334772
  0.991862	  0.991821	diff=4.06572e-05
 -0.967893	 -0.971276	diff=0.00338334
 -0.009489	 -0.009536	diff=4.69765e-05
 -0.009284	 -0.012587	diff=0.00330246
  0.986164	  0.986124	diff=4.01076e-05
 -0.960663	 -0.964000	diff=0.00333755
  local_diff=0.0135464
# Num params=182, abs_diff=0.0192775
Elapsed time is 2.856958 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 1
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s> <s> x y
  src mask: 0  0  1  1
  tgt input 1: <s> a </s> </s> </s>
  tgt output 1: a </s> </s> </s> </s>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
 -0.000002	 -0.000002	diff=1.20741e-08
  0.000000	  0.000000	diff=2.74564e-16
  0.000000	  0.000000	diff=2.544e-23
  0.000000	  0.000000	diff=1.52722e-33
 -0.000258	 -0.000260	diff=1.54711e-06
  0.000000	  0.000000	diff=9.00347e-14
  0.000000	  0.000000	diff=4.79336e-09
  0.000000	  0.000000	diff=3.15532e-13
  0.000000	  0.000000	diff=2.32785e-30
  0.000000	  0.000000	diff=2.57265e-17
  0.000000	  0.000000	diff=5.53782e-34
  0.000000	 -0.000000	diff=1.8157e-33
  0.000000	  0.000000	diff=8.62016e-33
  0.000000	  0.000000	diff=2.39131e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.14417e-67
  0.000000	  0.000000	diff=1.76282e-54
  0.000000	 -0.000000	diff=3.03592e-24
  0.000000	  0.000000	diff=4.24793e-71
 -0.000000	 -0.000000	diff=8.56778e-11
  0.000000	 -0.000000	diff=3.28532e-28
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=8.31242e-28
  0.000000	 -0.000000	diff=2.0401e-51
  0.000000	 -0.000000	diff=1.79874e-38
  0.000000	  0.000000	diff=2.07649e-28
  0.000000	 -0.000000	diff=4.59754e-55
  0.000000	  0.000000	diff=1.59146e-13
  0.000000	  0.000000	diff=2.33491e-32
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=5.90772e-32
  local_diff=1.56406e-06
# W_src{2}, [8 4]
 -0.000011	 -0.000011	diff=5.16662e-08
 -0.000105	 -0.000105	diff=5.16232e-07
 -0.000000	 -0.000000	diff=6.18951e-12
 -0.000001	 -0.000001	diff=4.66882e-09
 -0.000861	 -0.000863	diff=1.93291e-06
 -0.008980	 -0.008942	diff=3.85545e-05
  0.000000	  0.000000	diff=6.89996e-11
  0.000000	  0.000000	diff=3.9987e-12
  0.000000	  0.000000	diff=9.56847e-39
  0.000000	 -0.000000	diff=5.28236e-38
  0.000000	 -0.000000	diff=1.03611e-39
  0.000000	 -0.000000	diff=4.3962e-39
  0.000000	  0.000000	diff=1.20524e-38
  0.000000	 -0.000000	diff=3.24414e-38
  0.000000	 -0.000000	diff=5.83042e-19
  0.000000	 -0.000000	diff=1.94339e-18
 -0.000000	 -0.000000	diff=1.26302e-10
 -0.000042	 -0.000042	diff=9.96454e-08
 -0.000000	 -0.000000	diff=2.90008e-12
 -0.000000	 -0.000000	diff=7.25785e-10
 -0.000004	 -0.000004	diff=3.7967e-08
 -0.000312	 -0.000311	diff=2.86149e-07
  0.000000	  0.000000	diff=1.54662e-11
 -0.000000	 -0.000000	diff=2.59366e-13
  0.000000	  0.000000	diff=8.67902e-11
  0.000050	  0.000050	diff=1.25869e-07
  0.000000	  0.000000	diff=1.43853e-12
  0.000001	  0.000001	diff=1.46111e-09
 -0.000250	 -0.000248	diff=1.99212e-06
  0.006935	  0.006959	diff=2.38335e-05
 -0.000000	 -0.000000	diff=1.09531e-11
  0.000000	  0.000000	diff=1.37493e-13
  local_diff=6.74377e-05
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.84309e-09
  0.000000	  0.000000	diff=6.60538e-20
  0.000000	  0.000000	diff=7.84351e-21
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=2.2236e-08
  0.000000	  0.000000	diff=5.80138e-09
  0.000000	  0.000000	diff=2.90095e-53
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=7.99902e-10
  0.000000	  0.000000	diff=4.25713e-20
  0.000000	 -0.000000	diff=1.584e-21
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=9.04928e-09
 -0.000000	 -0.000000	diff=5.30955e-13
  0.000000	 -0.000000	diff=4.91562e-53
  0.000000	 -0.000000	diff=6.9622e-64
  0.000000	 -0.000000	diff=3.04511e-18
  0.000000	 -0.000000	diff=1.17092e-36
  0.000000	 -0.000000	diff=2.28769e-30
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=5.01836e-18
  0.000000	 -0.000000	diff=7.90179e-21
  0.000000	 -0.000000	diff=5.15549e-85
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.62986e-18
  0.000000	  0.000000	diff=1.52167e-36
  0.000000	  0.000000	diff=2.73768e-31
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.68602e-18
  0.000000	  0.000000	diff=3.30789e-21
  0.000000	  0.000000	diff=6.69984e-85
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.47916e-52
  0.000000	  0.000000	diff=4.08275e-37
  0.000000	 -0.000000	diff=4.66753e-27
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=4.75758e-27
  0.000000	  0.000000	diff=4.44014e-33
  0.000000	  0.000000	diff=1.34661e-66
  0.000000	 -0.000000	diff=6.70149e-65
  0.000000	  0.000000	diff=1.79091e-26
  0.000000	  0.000000	diff=3.96354e-41
  0.000000	 -0.000000	diff=8.20729e-37
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.95143e-26
  0.000000	  0.000000	diff=1.24571e-22
  0.000000	  0.000000	diff=1.50638e-83
  0.000000	 -0.000000	diff=1.74576e-83
  local_diff=3.97302e-08
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=3.56574e-17
  0.000000	 -0.000000	diff=9.58074e-18
  0.000000	 -0.000000	diff=1.87329e-19
  0.000000	 -0.000000	diff=6.38997e-19
  0.000000	  0.000000	diff=2.45419e-17
  0.000000	 -0.000000	diff=1.20626e-17
  0.000000	  0.000000	diff=1.24724e-13
  0.000000	  0.000000	diff=8.52086e-13
  0.000000	 -0.000000	diff=5.80114e-19
  0.000000	 -0.000000	diff=5.98519e-18
  0.000000	  0.000000	diff=5.94903e-23
  0.000000	  0.000000	diff=4.88193e-23
  0.000000	 -0.000000	diff=8.32051e-19
  0.000000	 -0.000000	diff=7.64317e-18
 -0.000000	 -0.000000	diff=9.81896e-13
 -0.000000	 -0.000000	diff=1.19011e-12
 -0.000007	 -0.000007	diff=1.3028e-09
 -0.000000	 -0.000000	diff=1.32969e-11
 -0.000005	 -0.000005	diff=9.02633e-10
  0.000001	  0.000001	diff=2.70092e-11
 -0.000000	 -0.000000	diff=1.90534e-11
  0.000000	  0.000000	diff=4.80034e-12
 -0.000000	 -0.000000	diff=2.90673e-11
  0.000011	  0.000011	diff=2.05118e-08
  0.000135	  0.000135	diff=4.95587e-07
  0.000001	  0.000001	diff=5.01565e-09
  0.000093	  0.000092	diff=3.43302e-07
 -0.000021	 -0.000021	diff=1.03708e-08
  0.000002	  0.000002	diff=7.24965e-09
 -0.000000	 -0.000000	diff=1.7136e-09
 -0.000000	 -0.000000	diff=5.39858e-12
 -0.000216	 -0.000208	diff=7.8755e-06
  local_diff=8.76156e-06
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000735	 -0.000748	diff=1.28823e-05
  0.000000	 -0.000000	diff=5.70026e-17
  0.000000	  0.000000	diff=1.73405e-09
  0.000000	  0.000000	diff=4.13406e-23
  local_diff=1.28841e-05
# W_emb_tgt, [2 4]
 -0.000000	 -0.000000	diff=8.95706e-09
  0.000000	  0.000000	diff=5.66152e-16
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=6.14206e-13
  0.000000	  0.000000	diff=5.20232e-22
  0.000000	  0.000000	diff=2.24878e-08
 -0.000001	 -0.000001	diff=3.56963e-08
  local_diff=6.71418e-08
# W_a, [2 2]
 -0.000027	 -0.000027	diff=3.87915e-10
 -0.000022	 -0.000022	diff=2.67602e-10
  0.000369	  0.000369	diff=7.85086e-08
  0.000307	  0.000307	diff=5.42513e-08
  local_diff=1.33415e-07
# W_h, [2 4]
 -0.000168	 -0.000167	diff=3.13738e-07
 -0.003946	 -0.003938	diff=7.38065e-06
  0.000543	  0.000547	diff=3.33507e-06
  0.012800	  0.012878	diff=7.84985e-05
 -0.000005	 -0.000005	diff=6.47255e-11
 -0.000116	 -0.000116	diff=6.17288e-09
  0.000068	  0.000068	diff=5.15355e-08
  0.001596	  0.001597	diff=1.21124e-06
  local_diff=9.0797e-05
# W_soft, [4 2]
  0.000032	  0.000032	diff=1.59956e-07
  0.999323	  0.999321	diff=1.61562e-06
 -0.999354	 -0.999356	diff=1.45248e-06
  0.000003	  0.000003	diff=1.40278e-08
  0.000032	  0.000032	diff=1.59991e-07
  0.998291	  0.998289	diff=1.61594e-06
 -0.998322	 -0.998324	diff=1.45276e-06
  0.000003	  0.000003	diff=1.40321e-08
  local_diff=6.4848e-06
# Num params=180, abs_diff=0.000188169
Elapsed time is 2.192310 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 2, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 2
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s> <s> x y
  src mask: 0  0  1  1
  tgt input 1: <s> a </s> </s> </s>
  tgt output 1: a </s> </s> </s> </s>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
 -0.000010	 -0.000010	diff=5.85277e-08
  0.000000	  0.000000	diff=8.07076e-16
  0.000000	  0.000000	diff=7.39025e-23
  0.000000	  0.000000	diff=1.53197e-33
 -0.001254	 -0.001261	diff=7.34774e-06
  0.000000	  0.000000	diff=3.07425e-13
  0.000002	  0.000002	diff=2.32409e-08
  0.000000	  0.000000	diff=6.23595e-14
  0.000000	  0.000000	diff=2.32687e-30
  0.000000	  0.000000	diff=2.23426e-17
  0.000000	  0.000000	diff=5.53781e-34
  0.000000	 -0.000000	diff=1.83624e-33
  0.000000	  0.000000	diff=7.63865e-33
  0.000000	  0.000000	diff=2.1405e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.14352e-67
  0.000000	  0.000000	diff=1.55926e-54
  0.000000	 -0.000000	diff=8.81991e-24
  0.000000	  0.000000	diff=3.72937e-71
 -0.000000	 -0.000000	diff=2.48591e-10
  0.000000	 -0.000000	diff=9.9815e-28
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=2.52549e-27
  0.000000	 -0.000000	diff=2.03945e-51
  0.000000	 -0.000000	diff=1.5653e-38
  0.000000	  0.000000	diff=6.02178e-28
  0.000000	 -0.000000	diff=4.06666e-55
  0.000000	  0.000000	diff=3.91156e-13
  0.000000	  0.000000	diff=7.09395e-32
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.79489e-31
  local_diff=7.42975e-06
# W_src{2}, [8 4]
 -0.000034	 -0.000034	diff=1.5233e-07
 -0.000287	 -0.000286	diff=1.41967e-06
 -0.000000	 -0.000000	diff=4.33281e-12
 -0.000003	 -0.000003	diff=1.33199e-08
 -0.002717	 -0.002723	diff=5.04518e-06
 -0.023619	 -0.023501	diff=0.000117965
  0.000000	  0.000000	diff=1.42167e-10
  0.000000	  0.000000	diff=7.90364e-11
  0.000000	  0.000000	diff=9.57621e-39
  0.000000	 -0.000000	diff=4.72908e-38
  0.000000	 -0.000000	diff=1.03384e-39
  0.000000	 -0.000000	diff=3.6352e-39
  0.000000	  0.000000	diff=1.20524e-38
  0.000000	 -0.000000	diff=2.85192e-38
  0.000000	 -0.000000	diff=5.84963e-19
  0.000000	 -0.000000	diff=1.717e-18
 -0.000000	 -0.000000	diff=2.57568e-10
 -0.000118	 -0.000118	diff=2.81746e-07
 -0.000000	 -0.000000	diff=4.82893e-12
 -0.000001	 -0.000001	diff=2.04615e-09
  0.000007	  0.000007	diff=5.36676e-08
 -0.000921	 -0.000920	diff=9.11242e-07
  0.000000	  0.000000	diff=3.1952e-11
 -0.000000	 -0.000000	diff=1.14061e-14
  0.000000	  0.000000	diff=1.76598e-10
  0.000142	  0.000143	diff=3.6249e-07
 -0.000000	 -0.000000	diff=7.58504e-12
  0.000002	  0.000001	diff=4.21854e-09
 -0.000596	 -0.000590	diff=6.0065e-06
  0.020251	  0.020348	diff=9.6823e-05
 -0.000000	 -0.000000	diff=2.22239e-11
  0.000000	  0.000000	diff=2.17747e-13
  local_diff=0.000229041
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.84309e-09
  0.000000	  0.000000	diff=6.60538e-20
  0.000000	  0.000000	diff=7.84351e-21
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=2.2236e-08
  0.000000	  0.000000	diff=5.80138e-09
  0.000000	  0.000000	diff=2.90095e-53
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=7.99902e-10
  0.000000	  0.000000	diff=4.25713e-20
  0.000000	 -0.000000	diff=1.58406e-21
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=9.04928e-09
 -0.000000	 -0.000000	diff=5.30955e-13
  0.000000	 -0.000000	diff=4.91562e-53
  0.000000	 -0.000000	diff=7.0048e-64
  0.000000	 -0.000000	diff=3.04511e-18
  0.000000	 -0.000000	diff=1.17092e-36
  0.000000	 -0.000000	diff=2.28769e-30
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=5.01836e-18
  0.000000	 -0.000000	diff=7.90179e-21
  0.000000	 -0.000000	diff=5.15549e-85
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.62986e-18
  0.000000	  0.000000	diff=1.52167e-36
  0.000000	  0.000000	diff=2.73768e-31
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.68602e-18
  0.000000	  0.000000	diff=3.30789e-21
  0.000000	  0.000000	diff=6.69984e-85
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=3.3215e-52
  0.000000	  0.000000	diff=4.08275e-37
  0.000000	 -0.000000	diff=1.04805e-26
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.06832e-26
  0.000000	  0.000000	diff=4.44014e-33
  0.000000	  0.000000	diff=3.02383e-66
  0.000000	 -0.000000	diff=6.74249e-65
  0.000000	  0.000000	diff=1.79091e-26
  0.000000	  0.000000	diff=3.96354e-41
  0.000000	 -0.000000	diff=8.20729e-37
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.95143e-26
  0.000000	  0.000000	diff=1.24571e-22
  0.000000	  0.000000	diff=1.55008e-83
  0.000000	 -0.000000	diff=1.75644e-83
  local_diff=3.97302e-08
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=3.56574e-17
  0.000000	 -0.000000	diff=9.58074e-18
  0.000000	 -0.000000	diff=1.87329e-19
  0.000000	 -0.000000	diff=6.38997e-19
  0.000000	  0.000000	diff=2.45419e-17
  0.000000	 -0.000000	diff=1.20626e-17
  0.000000	  0.000000	diff=1.24724e-13
  0.000000	  0.000000	diff=8.52086e-13
  0.000000	 -0.000000	diff=5.80114e-19
  0.000000	 -0.000000	diff=5.98519e-18
  0.000000	  0.000000	diff=5.94903e-23
  0.000000	  0.000000	diff=4.88193e-23
  0.000000	 -0.000000	diff=8.32051e-19
  0.000000	 -0.000000	diff=7.64317e-18
 -0.000000	 -0.000000	diff=9.81896e-13
 -0.000000	 -0.000000	diff=1.19011e-12
 -0.000014	 -0.000014	diff=2.66908e-09
 -0.000000	 -0.000000	diff=6.28815e-11
 -0.000010	 -0.000010	diff=1.8484e-09
  0.000005	  0.000005	diff=7.00647e-10
 -0.000000	 -0.000000	diff=3.87015e-11
  0.000000	  0.000000	diff=2.3616e-11
 -0.000000	 -0.000000	diff=2.88952e-11
  0.000053	  0.000053	diff=4.66195e-08
  0.000277	  0.000276	diff=1.01507e-06
  0.000006	  0.000006	diff=2.40057e-08
  0.000190	  0.000189	diff=7.03188e-07
 -0.000104	 -0.000105	diff=2.65943e-07
  0.000004	  0.000004	diff=1.48545e-08
 -0.000002	 -0.000002	diff=8.58948e-09
 -0.000000	 -0.000000	diff=2.53756e-11
 -0.001046	 -0.001028	diff=1.78373e-05
  local_diff=1.9921e-05
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.003567	 -0.003628	diff=6.11295e-05
  0.000000	 -0.000000	diff=4.94591e-17
  0.000000	  0.000000	diff=5.04143e-09
  0.000000	  0.000000	diff=4.13408e-23
  local_diff=6.11345e-05
# W_emb_tgt, [2 4]
 -0.000000	 -0.000000	diff=8.95706e-09
  0.000000	  0.000000	diff=5.66152e-16
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=6.14206e-13
  0.000000	  0.000000	diff=5.20232e-22
  0.000000	  0.000000	diff=2.24878e-08
 -0.000001	 -0.000001	diff=3.56963e-08
  local_diff=6.71418e-08
# W_a, [2 2]
 -0.000058	 -0.000058	diff=6.9435e-10
 -0.000051	 -0.000051	diff=5.24304e-10
  0.000806	  0.000806	diff=1.36739e-07
  0.000699	  0.000699	diff=1.02905e-07
  local_diff=2.40863e-07
# W_h, [2 4]
 -0.000503	 -0.000502	diff=1.33268e-06
 -0.011313	 -0.011283	diff=2.98804e-05
  0.001046	  0.001052	diff=5.82073e-06
  0.023523	  0.023654	diff=0.000130603
 -0.000010	 -0.000010	diff=3.6825e-10
 -0.000235	 -0.000235	diff=1.27064e-08
  0.000144	  0.000144	diff=1.0928e-07
  0.003232	  0.003235	diff=2.44983e-06
  local_diff=0.000170209
# W_soft, [4 2]
  0.000032	  0.000032	diff=1.60184e-07
  0.998924	  0.998922	diff=1.62356e-06
 -0.998955	 -0.998957	diff=1.46017e-06
  0.000003	  0.000003	diff=1.41015e-08
  0.000032	  0.000032	diff=1.60055e-07
  0.996866	  0.996864	diff=1.62219e-06
 -0.996897	 -0.996899	diff=1.45892e-06
  0.000003	  0.000003	diff=1.40907e-08
  local_diff=6.51327e-06
# Num params=180, abs_diff=0.000494596
Elapsed time is 2.478257 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 186, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_a=4 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 4
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 186
  src input 1: <s> <s> <s> x
  src mask: 0  0  0  1
  tgt input 1: <s> b a </s> </s>
  tgt output 1: b a </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.002852	  0.002869	diff=1.68403e-05
 -0.000163	  0.000002	diff=0.000165013
  0.000000	 -0.000000	diff=1.9284e-33
  0.000000	  0.000000	diff=2.13506e-26
 -0.033502	 -0.033684	diff=0.00018148
 -0.000015	 -0.000015	diff=9.03487e-08
 -0.000570	 -0.000563	diff=6.67202e-06
  0.010410	  0.010526	diff=0.000115766
 -0.000000	 -0.000000	diff=8.32442e-09
  0.000196	  0.000000	diff=0.000195687
  0.000000	  0.000000	diff=2.45131e-33
  0.000000	 -0.000000	diff=2.94158e-26
  0.000000	 -0.000000	diff=7.97046e-30
  0.000000	 -0.000000	diff=2.64003e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=6.27815e-67
  0.000000	 -0.000000	diff=9.00771e-51
  0.000000	  0.000000	diff=3.51066e-72
  0.000000	 -0.000000	diff=3.81407e-65
  0.000000	 -0.000000	diff=9.00417e-64
  0.000000	 -0.000000	diff=9.00439e-51
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=8.18273e-51
  0.000000	  0.000000	diff=1.28775e-37
  0.000000	 -0.000000	diff=5.68668e-57
  0.000000	  0.000000	diff=3.28786e-54
  0.000000	  0.000000	diff=1.31902e-50
  0.000000	  0.000000	diff=1.28887e-37
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.000681556
# W_src{2}, [8 4]
 -0.130410	 -0.129772	diff=0.000638243
 -0.000831	 -0.000827	diff=3.77125e-06
  0.000000	 -0.000000	diff=6.72534e-52
  0.000000	 -0.000000	diff=4.24885e-51
 -0.319916	 -0.320999	diff=0.00108304
  0.056188	  0.056241	diff=5.23718e-05
  0.000002	  0.000002	diff=2.08617e-08
 -0.000001	 -0.000001	diff=5.06921e-09
  0.000000	 -0.000000	diff=3.09068e-38
  0.000000	  0.000000	diff=1.60793e-37
  0.000000	  0.000000	diff=9.50646e-39
  0.000000	  0.000000	diff=6.14627e-38
  0.000000	 -0.000000	diff=2.31329e-38
  0.000000	  0.000000	diff=2.3479e-37
  0.000000	 -0.000000	diff=4.74238e-19
  0.000000	  0.000000	diff=1.52014e-18
  0.000000	  0.000000	diff=9.55718e-39
  0.000000	 -0.000000	diff=2.27605e-38
  0.000000	 -0.000000	diff=4.09388e-39
  0.000000	 -0.000000	diff=7.23805e-39
  0.000000	  0.000000	diff=5.6329e-39
  0.000000	 -0.000000	diff=4.06846e-38
  0.000000	 -0.000000	diff=9.87248e-19
  0.000000	 -0.000000	diff=3.73543e-19
  0.000000	  0.000000	diff=4.85092e-38
  0.000000	  0.000000	diff=1.10025e-37
  0.000000	 -0.000000	diff=1.4567e-38
  0.000000	  0.000000	diff=1.00357e-38
  0.000000	  0.000000	diff=4.57124e-38
  0.000000	  0.000000	diff=1.44746e-37
  0.000000	  0.000000	diff=4.29446e-19
  0.000000	 -0.000000	diff=1.28924e-18
  local_diff=0.00177745
# W_tgt{1}, [8 6]
 -0.000001	 -0.000001	diff=9.88934e-09
  0.000000	 -0.000000	diff=5.09269e-20
  0.000000	  0.000000	diff=1.06708e-12
  0.000000	  0.000000	diff=0
 -0.000002	 -0.000002	diff=1.19269e-07
 -0.000000	 -0.000000	diff=2.54875e-12
  0.000000	  0.000000	diff=1.17089e-52
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=4.29101e-09
  0.000000	  0.000000	diff=3.38601e-13
  0.000000	  0.000000	diff=4.21821e-13
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=4.85403e-08
  0.000000	 -0.000000	diff=1.37542e-12
  0.000000	 -0.000000	diff=1.98405e-52
  0.000000	 -0.000000	diff=2.37043e-13
 -0.000204	 -0.000203	diff=1.18465e-06
  0.000000	  0.000000	diff=9.53204e-13
 -0.000004	 -0.000004	diff=2.19991e-08
  0.000000	  0.000000	diff=6.22127e-10
 -0.015005	 -0.014923	diff=8.2303e-05
  0.000000	  0.000000	diff=1.62902e-13
  0.000991	  0.001001	diff=9.41853e-06
 -0.000036	 -0.000039	diff=2.44967e-06
  0.000218	  0.000219	diff=1.35985e-06
  0.000000	  0.000000	diff=1.00864e-12
  0.000003	  0.000003	diff=2.15834e-08
 -0.000000	 -0.000000	diff=6.08832e-10
  0.016908	  0.017014	diff=0.000106056
  0.000000	 -0.000000	diff=5.33032e-13
 -0.001155	 -0.001141	diff=1.37453e-05
  0.000046	  0.000045	diff=1.60175e-06
 -0.052887	 -0.053044	diff=0.000157446
  0.003169	  0.003163	diff=6.10135e-06
 -0.072196	 -0.071894	diff=0.000302704
 -0.002897	 -0.002889	diff=7.68223e-06
 -0.028603	 -0.028481	diff=0.000122758
  0.000001	  0.000001	diff=5.05412e-09
  0.000872	  0.000881	diff=8.5602e-06
 -0.000026	 -0.000026	diff=1.95984e-07
 -0.000096	 -0.000096	diff=3.72698e-07
 -0.000000	 -0.000000	diff=2.36167e-12
  0.000005	  0.000005	diff=5.58962e-10
  0.000000	  0.000000	diff=1.36109e-11
 -0.011128	 -0.011082	diff=4.59419e-05
 -0.000000	 -0.000000	diff=1.65651e-12
  0.000750	  0.000757	diff=6.49544e-06
 -0.000007	 -0.000007	diff=1.65042e-07
  local_diff=0.000876775
# W_tgt{2}, [8 4]
  3.511382	  3.523108	diff=0.0117257
  0.002798	  0.002785	diff=1.36797e-05
 -0.859587	 -0.853574	diff=0.00601368
 -0.003957	 -0.003938	diff=1.88041e-05
  0.000653	  0.000650	diff=3.91462e-06
 -0.092569	 -0.092638	diff=6.9014e-05
  0.001222	  0.001212	diff=9.22802e-06
 -0.305499	 -0.308138	diff=0.00263887
 -0.000000	 -0.000000	diff=4.50215e-13
 -0.000000	 -0.000000	diff=5.32168e-13
  0.000000	 -0.000000	diff=3.29918e-14
  0.000000	 -0.000000	diff=3.6336e-13
 -0.000000	 -0.000000	diff=1.00294e-12
 -0.000000	 -0.000000	diff=5.35645e-13
  0.000019	  0.000010	diff=8.4068e-06
  0.000011	  0.000007	diff=3.86961e-06
  0.927915	  0.928277	diff=0.000362215
  0.000072	  0.000072	diff=4.28042e-09
 -0.019015	 -0.019012	diff=2.97191e-06
 -0.000077	 -0.000077	diff=2.06029e-08
  0.000000	  0.000000	diff=9.07396e-09
 -0.002031	 -0.002031	diff=3.32647e-08
 -0.000000	 -0.000000	diff=1.86976e-08
 -0.006883	 -0.006885	diff=1.31117e-06
 -0.013619	 -0.013643	diff=2.40441e-05
 -0.002393	 -0.002402	diff=8.78548e-06
  0.659947	  0.663551	diff=0.00360419
  0.003065	  0.003076	diff=1.12775e-05
 -0.000062	 -0.000062	diff=2.28049e-07
  0.071202	  0.071164	diff=3.76021e-05
 -0.000229	 -0.000227	diff=1.79457e-06
  0.241961	  0.240348	diff=0.00161326
  local_diff=0.0261729
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.061853	 -0.062338	diff=0.000484892
  0.000000	  0.000000	diff=5.58021e-17
 -0.000279	 -0.000000	diff=0.00027927
 -0.000322	 -0.000000	diff=0.000322353
  local_diff=0.00108652
# W_emb_tgt, [2 4]
  0.000000	 -0.000000	diff=6.6643e-15
 -0.000000	 -0.000000	diff=3.52353e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=3.94482e-20
  0.000000	  0.000000	diff=1.29263e-15
  0.000002	  0.000002	diff=1.20621e-07
 -0.000003	 -0.000003	diff=1.91469e-07
  local_diff=3.12091e-07
# W_pos, [2 2]
  0.003251	  0.003291	diff=4.02582e-05
 -0.016120	 -0.016192	diff=7.19685e-05
 -0.000737	 -0.000737	diff=1.59332e-08
 -0.000471	 -0.000471	diff=3.94105e-08
  local_diff=0.000112282
# v_pos, [1 2]
 -0.001657	 -0.001484	diff=0.000173199
  0.029201	  0.032142	diff=0.00294171
  local_diff=0.00311491
# W_a, [2 2]
  0.000000	 -0.000000	diff=2.97579e-48
  0.000000	 -0.000000	diff=4.93321e-48
  0.000000	 -0.000000	diff=1.18557e-48
  0.000000	  0.000000	diff=1.42623e-48
  local_diff=1.05208e-47
# W_h, [2 4]
  0.039032	  0.039034	diff=2.69019e-06
 -0.002371	 -0.002371	diff=2.80041e-07
 -1.365650	 -1.362372	diff=0.00327817
  0.082413	  0.082753	diff=0.00034017
 -0.281156	 -0.281040	diff=0.000115608
 -0.117074	 -0.116237	diff=0.000836786
  0.000494	  0.000503	diff=8.60043e-06
  0.002478	  0.002486	diff=8.60148e-06
  local_diff=0.00459091
# W_soft, [4 2]
 -2.143238	 -2.143238	diff=1.38043e-08
  0.270314	  0.270314	diff=4.1181e-09
  0.872934	  0.872934	diff=6.60427e-10
  0.999990	  0.999990	diff=8.94784e-09
  2.992462	  2.992462	diff=3.22852e-08
 -0.999503	 -0.999503	diff=1.10855e-08
 -0.999216	 -0.999216	diff=5.50643e-09
 -0.993743	 -0.993743	diff=1.59102e-08
  local_diff=9.2318e-08
# Num params=186, abs_diff=0.0384137
Elapsed time is 2.920812 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 2, 'normLocalAttn', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 186, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_a=4 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 4
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 1
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 186
  src input 1: <s> <s> <s> x
  src mask: 0  0  0  1
  tgt input 1: <s> b a </s> </s>
  tgt output 1: b a </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000649	  0.000653	diff=3.83074e-06
 -0.000165	  0.000000	diff=0.000165005
  0.000000	 -0.000000	diff=1.92839e-33
  0.000000	  0.000000	diff=2.14595e-26
 -0.012823	 -0.012895	diff=7.2624e-05
 -0.000004	 -0.000004	diff=2.22098e-08
 -0.000130	 -0.000128	diff=1.51945e-06
  0.002052	  0.002077	diff=2.52102e-05
 -0.000000	 -0.000000	diff=8.32442e-09
  0.000196	  0.000000	diff=0.000195687
  0.000000	  0.000000	diff=2.45131e-33
  0.000000	 -0.000000	diff=2.98876e-26
  0.000000	 -0.000000	diff=9.28517e-30
  0.000000	 -0.000000	diff=5.57178e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=7.44599e-67
  0.000000	 -0.000000	diff=9.71285e-51
  0.000000	  0.000000	diff=3.51027e-72
  0.000000	 -0.000000	diff=3.90356e-65
  0.000000	 -0.000000	diff=9.41285e-64
  0.000000	 -0.000000	diff=9.70928e-51
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=8.17898e-51
  0.000000	  0.000000	diff=1.45348e-37
  0.000000	 -0.000000	diff=5.68664e-57
  0.000000	  0.000000	diff=3.70338e-54
  0.000000	  0.000000	diff=1.37923e-50
  0.000000	  0.000000	diff=1.45239e-37
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.000463906
# W_src{2}, [8 4]
 -0.031640	 -0.031483	diff=0.000157161
 -0.000273	 -0.000272	diff=1.24136e-06
  0.000000	 -0.000000	diff=6.66367e-52
  0.000000	 -0.000000	diff=4.52042e-51
 -0.122196	 -0.122545	diff=0.000349177
 -0.008191	 -0.008093	diff=9.78578e-05
  0.000001	  0.000001	diff=5.06211e-09
 -0.000000	 -0.000000	diff=1.66727e-09
  0.000000	 -0.000000	diff=3.03135e-38
  0.000000	  0.000000	diff=2.19119e-37
  0.000000	  0.000000	diff=9.50889e-39
  0.000000	  0.000000	diff=6.72903e-38
  0.000000	 -0.000000	diff=2.25519e-38
  0.000000	  0.000000	diff=2.84134e-37
  0.000000	 -0.000000	diff=5.45618e-19
  0.000000	  0.000000	diff=3.53745e-18
  0.000000	  0.000000	diff=9.9969e-39
  0.000000	 -0.000000	diff=2.58607e-38
  0.000000	 -0.000000	diff=4.21441e-39
  0.000000	 -0.000000	diff=7.63615e-39
  0.000000	  0.000000	diff=5.87364e-39
  0.000000	 -0.000000	diff=4.17379e-38
  0.000000	 -0.000000	diff=1.00117e-18
  0.000000	 -0.000000	diff=4.98354e-19
  0.000000	  0.000000	diff=5.0114e-38
  0.000000	  0.000000	diff=1.59738e-37
  0.000000	 -0.000000	diff=1.48723e-38
  0.000000	  0.000000	diff=3.07209e-38
  0.000000	  0.000000	diff=4.7223e-38
  0.000000	  0.000000	diff=2.08569e-37
  0.000000	  0.000000	diff=3.60952e-19
  0.000000	 -0.000000	diff=4.65473e-20
  local_diff=0.000605444
# W_tgt{1}, [8 6]
 -0.000001	 -0.000001	diff=9.89076e-09
  0.000000	 -0.000000	diff=5.09269e-20
  0.000000	  0.000000	diff=1.06708e-12
  0.000000	  0.000000	diff=0
 -0.000002	 -0.000002	diff=1.19271e-07
 -0.000000	 -0.000000	diff=2.93418e-13
  0.000000	  0.000000	diff=1.17089e-52
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=4.29243e-09
  0.000000	  0.000000	diff=3.38601e-13
  0.000000	  0.000000	diff=9.99264e-13
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=4.85403e-08
 -0.000000	 -0.000000	diff=4.56641e-14
  0.000000	 -0.000000	diff=1.98405e-52
  0.000000	 -0.000000	diff=2.37043e-13
 -0.000057	 -0.000057	diff=3.51342e-07
  0.000000	  0.000000	diff=4.07376e-14
 -0.000001	 -0.000001	diff=5.55329e-09
  0.000000	  0.000000	diff=1.196e-10
 -0.002685	 -0.002669	diff=1.64996e-05
  0.000000	  0.000000	diff=8.40238e-13
  0.000621	  0.000627	diff=6.19551e-06
 -0.000001	 -0.000003	diff=2.01011e-06
  0.000057	  0.000057	diff=3.58098e-07
  0.000000	  0.000000	diff=5.84759e-13
  0.000001	  0.000001	diff=5.50699e-09
 -0.000000	 -0.000000	diff=1.20042e-10
  0.002708	  0.002725	diff=1.70623e-05
  0.000000	  0.000000	diff=1.83324e-13
 -0.000645	 -0.000638	diff=7.38301e-06
  0.000011	  0.000010	diff=1.16157e-06
 -0.012746	 -0.012784	diff=3.75883e-05
  0.000625	  0.000624	diff=9.85465e-07
 -0.017395	 -0.017321	diff=7.35444e-05
 -0.000572	 -0.000570	diff=1.69928e-06
 -0.005816	 -0.005792	diff=2.41263e-05
  0.000000	  0.000000	diff=1.24489e-09
  0.000487	  0.000492	diff=4.82987e-06
 -0.000005	 -0.000005	diff=3.36707e-08
 -0.000026	 -0.000026	diff=1.03425e-07
 -0.000000	 -0.000000	diff=6.0494e-13
  0.000001	  0.000001	diff=1.35989e-10
  0.000000	  0.000000	diff=1.75009e-12
 -0.001762	 -0.001755	diff=7.28693e-06
 -0.000000	 -0.000000	diff=9.58201e-13
  0.000420	  0.000424	diff=3.73392e-06
 -0.000002	 -0.000001	diff=1.74962e-07
  local_diff=0.000205323
# W_tgt{2}, [8 4]
  1.061870	  1.072444	diff=0.0105741
  0.000552	  0.000549	diff=2.83992e-06
 -0.205681	 -0.204145	diff=0.0015353
 -0.000889	 -0.000884	diff=4.25779e-06
  0.000212	  0.000211	diff=1.28814e-06
 -0.021193	 -0.021209	diff=1.59658e-05
  0.000399	  0.000395	diff=3.85205e-06
 -0.068724	 -0.069307	diff=0.000582688
 -0.000000	 -0.000000	diff=4.50215e-13
 -0.000000	 -0.000000	diff=5.32168e-13
  0.000000	 -0.000000	diff=3.29918e-14
  0.000000	 -0.000000	diff=3.6336e-13
 -0.000000	 -0.000000	diff=4.18147e-13
 -0.000000	 -0.000000	diff=8.85441e-13
  0.000019	  0.000010	diff=8.4068e-06
  0.000011	  0.000007	diff=3.86961e-06
  0.217542	  0.217608	diff=6.55141e-05
  0.000017	  0.000017	diff=1.97188e-10
 -0.004548	 -0.004547	diff=7.58276e-07
 -0.000015	 -0.000015	diff=7.60185e-09
 -0.000005	 -0.000005	diff=1.36208e-08
 -0.000457	 -0.000457	diff=7.53874e-09
 -0.000001	 -0.000001	diff=1.82476e-08
 -0.001554	 -0.001554	diff=2.83693e-07
 -0.003200	 -0.003205	diff=5.72321e-06
 -0.000540	 -0.000542	diff=1.98307e-06
  0.157779	  0.158699	diff=0.000919223
  0.000692	  0.000695	diff=2.54765e-06
 -0.000014	 -0.000014	diff=5.22403e-08
  0.016080	  0.016072	diff=7.86603e-06
 -0.000055	 -0.000055	diff=5.45507e-07
  0.054628	  0.054271	diff=0.000356999
  local_diff=0.0140941
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.028864	 -0.029224	diff=0.000360126
  0.000000	  0.000000	diff=1.23208e-16
 -0.000279	 -0.000000	diff=0.00027927
 -0.000322	 -0.000000	diff=0.000322353
  local_diff=0.000961749
# W_emb_tgt, [2 4]
  0.000000	 -0.000000	diff=6.6643e-15
 -0.000000	 -0.000000	diff=3.52353e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=3.94482e-20
  0.000000	  0.000000	diff=1.29263e-15
  0.000002	  0.000002	diff=1.20621e-07
 -0.000003	 -0.000003	diff=1.91471e-07
  local_diff=3.12092e-07
# W_pos, [2 2]
  0.000000	 -0.000000	diff=9.37811e-57
  0.000000	 -0.000000	diff=1.18723e-56
  0.000000	 -0.000000	diff=4.04678e-57
  0.000000	 -0.000000	diff=5.12304e-57
  local_diff=3.04202e-56
# v_pos, [1 2]
  0.000000	  0.000000	diff=3.98681e-56
  0.000000	  0.000000	diff=1.62797e-55
  local_diff=2.02666e-55
# W_a, [2 2]
  0.000000	 -0.000000	diff=8.60006e-49
  0.000000	 -0.000000	diff=7.17372e-48
  0.000000	 -0.000000	diff=6.15858e-49
  0.000000	  0.000000	diff=1.16245e-48
  local_diff=9.81204e-48
# W_h, [2 4]
  0.017542	  0.017545	diff=3.19922e-06
 -0.000016	 -0.000016	diff=3.34947e-09
 -0.616277	 -0.612365	diff=0.00391144
  0.000551	  0.000555	diff=4.05777e-06
 -0.096226	 -0.096105	diff=0.0001211
 -0.000367	 -0.000363	diff=3.69207e-06
  0.000159	  0.000167	diff=8.60044e-06
 -0.000023	 -0.000015	diff=8.22925e-06
  local_diff=0.00406032
# W_soft, [4 2]
 -2.800154	 -2.800154	diff=1.77152e-08
  0.821769	  0.821769	diff=5.15209e-09
  0.978392	  0.978392	diff=4.16933e-10
  0.999993	  0.999993	diff=1.20369e-08
  2.999965	  2.999965	diff=2.03313e-08
 -0.999989	 -0.999989	diff=6.06295e-09
 -0.999997	 -0.999997	diff=5.17358e-10
 -0.999979	 -0.999979	diff=1.38892e-08
  local_diff=7.61219e-08
# Num params=186, abs_diff=0.0203912
Elapsed time is 2.969374 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 1
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000001	  0.000001	diff=7.71111e-09
  0.000158	 -0.000005	diff=0.000163181
  0.000000	  0.000000	diff=1.93104e-11
  0.000006	  0.000006	diff=3.36581e-08
 -0.001355	 -0.001346	diff=9.21503e-06
 -0.000001	 -0.000001	diff=3.75515e-08
 -0.000000	 -0.000000	diff=2.01904e-09
  0.000060	  0.000060	diff=5.64828e-07
  0.000000	  0.000000	diff=5.10438e-09
 -0.000194	 -0.000000	diff=0.000193484
  0.000000	  0.000000	diff=1.4879e-33
  0.000000	 -0.000000	diff=1.14678e-25
  0.000000	 -0.000000	diff=6.28616e-30
  0.000000	 -0.000000	diff=2.42978e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.10326e-09
  0.000003	  0.000003	diff=1.08596e-08
  0.000000	  0.000000	diff=6.13123e-12
 -0.000004	 -0.000004	diff=1.2986e-08
  0.000962	  0.000963	diff=1.24815e-06
  0.000007	  0.000007	diff=2.70073e-08
  0.000000	  0.000000	diff=2.92672e-13
  0.000000	  0.000000	diff=5.82397e-11
 -0.000000	 -0.000000	diff=5.47623e-13
 -0.000000	 -0.000000	diff=7.6165e-13
 -0.000000	 -0.000000	diff=5.50316e-13
  0.000000	  0.000000	diff=2.0178e-13
 -0.000002	 -0.000002	diff=1.19224e-09
 -0.000000	 -0.000000	diff=2.50214e-11
  0.000000	  0.000000	diff=2.46577e-13
  0.000000	  0.000000	diff=5.68236e-13
  local_diff=0.000367833
# W_src{2}, [8 4]
 -0.000045	 -0.000045	diff=1.87212e-07
 -0.000309	 -0.000308	diff=1.2531e-06
 -0.000002	 -0.000002	diff=5.37233e-09
 -0.000001	 -0.000001	diff=3.91209e-09
 -0.003418	 -0.003401	diff=1.61501e-05
 -0.001512	 -0.001510	diff=2.10921e-06
  0.000063	  0.000064	diff=5.14387e-07
 -0.000000	 -0.000000	diff=2.42587e-11
  0.000000	 -0.000000	diff=1.9084e-38
  0.000000	  0.000000	diff=1.19587e-37
  0.000000	  0.000000	diff=7.72257e-39
  0.000000	  0.000000	diff=4.51714e-38
  0.000000	 -0.000000	diff=1.29539e-38
  0.000000	  0.000000	diff=1.80749e-37
  0.000000	 -0.000000	diff=8.60418e-19
  0.000000	  0.000000	diff=1.09402e-18
 -0.000026	 -0.000026	diff=8.6516e-08
 -0.000268	 -0.000267	diff=1.02299e-06
 -0.000000	 -0.000000	diff=1.48921e-10
 -0.000001	 -0.000001	diff=2.85365e-09
 -0.000216	 -0.000216	diff=6.9323e-07
 -0.000041	 -0.000041	diff=3.07332e-08
  0.000059	  0.000059	diff=4.43512e-07
 -0.000000	 -0.000000	diff=1.60273e-11
  0.000007	  0.000007	diff=6.92439e-09
  0.000095	  0.000095	diff=1.44847e-07
  0.000002	  0.000002	diff=5.79726e-09
  0.000000	  0.000000	diff=9.01186e-10
  0.003121	  0.003139	diff=1.77592e-05
  0.001323	  0.001323	diff=7.59726e-09
 -0.000017	 -0.000017	diff=3.48392e-08
  0.000000	  0.000000	diff=1.45749e-12
  local_diff=4.04634e-05
# W_tgt{1}, [8 6]
 -0.000001	 -0.000001	diff=4.19872e-09
  0.000000	 -0.000000	diff=5.93927e-20
  0.000000	  0.000000	diff=3.33753e-12
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=5.0626e-08
 -0.000000	 -0.000000	diff=7.51526e-13
  0.000000	  0.000000	diff=5.90485e-53
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=1.82159e-09
  0.000000	  0.000000	diff=5.28357e-13
  0.000000	  0.000000	diff=9.76005e-13
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=2.06035e-08
  0.000000	  0.000000	diff=9.75154e-13
  0.000000	 -0.000000	diff=1.00057e-52
 -0.000000	 -0.000000	diff=3.08413e-13
  0.000000	  0.000000	diff=1.07353e-12
  0.000000	  0.000000	diff=5.10656e-13
 -0.000000	 -0.000000	diff=6.21694e-13
  0.000000	  0.000000	diff=5.61926e-14
 -0.000000	 -0.000000	diff=4.56229e-13
  0.000000	  0.000000	diff=5.90052e-13
 -0.000000	 -0.000001	diff=4.99793e-07
  0.000003	  0.000002	diff=1.07353e-06
  0.000000	  0.000000	diff=1.51555e-12
 -0.000000	 -0.000000	diff=1.12705e-12
 -0.000000	 -0.000000	diff=9.86106e-14
 -0.000000	 -0.000000	diff=3.93558e-13
 -0.000000	 -0.000000	diff=5.81601e-13
 -0.000000	 -0.000000	diff=8.41935e-13
  0.000003	  0.000005	diff=1.97835e-06
 -0.000013	 -0.000009	diff=4.20626e-06
 -0.000002	 -0.000002	diff=5.18708e-09
  0.000000	  0.000000	diff=2.5367e-15
 -0.000002	 -0.000002	diff=7.16958e-09
  0.000000	  0.000000	diff=4.09434e-13
 -0.000001	 -0.000001	diff=2.78134e-09
 -0.000000	 -0.000000	diff=2.31839e-13
 -0.000000	 -0.000000	diff=1.18494e-11
  0.000000	  0.000000	diff=6.94714e-12
 -0.000000	 -0.000000	diff=7.18298e-12
  0.000000	  0.000000	diff=1.45839e-13
 -0.000000	 -0.000000	diff=1.12771e-11
  0.000000	  0.000000	diff=5.36816e-13
 -0.000000	 -0.000000	diff=5.2539e-12
  0.000000	  0.000000	diff=1.83226e-13
 -0.000000	 -0.000000	diff=6.84446e-08
  0.000000	  0.000000	diff=1.46927e-07
  local_diff=8.06576e-06
# W_tgt{2}, [8 4]
  0.000109	  0.000109	diff=4.31145e-08
 -0.000000	 -0.000000	diff=4.7707e-11
 -0.000000	 -0.000000	diff=6.42872e-11
  0.000000	  0.000000	diff=1.58615e-10
 -0.000005	 -0.000005	diff=2.3855e-08
  0.000001	  0.000001	diff=2.94526e-09
  0.000001	  0.000002	diff=2.03539e-07
 -0.000003	 -0.000003	diff=4.37609e-08
 -0.000000	 -0.000000	diff=2.96047e-13
  0.000000	  0.000000	diff=1.01176e-13
 -0.000000	 -0.000000	diff=3.24934e-13
  0.000000	  0.000000	diff=8.44173e-14
 -0.000000	 -0.000000	diff=8.03062e-14
  0.000000	  0.000000	diff=1.66716e-13
  0.000000	  0.000005	diff=4.31779e-06
 -0.000013	 -0.000010	diff=2.86293e-06
  0.000084	  0.000084	diff=3.69071e-09
 -0.000000	 -0.000000	diff=2.59601e-11
 -0.000000	 -0.000000	diff=3.47241e-11
  0.000000	  0.000000	diff=8.59228e-11
 -0.000004	 -0.000004	diff=1.5838e-08
  0.000000	  0.000000	diff=1.59444e-09
 -0.000000	 -0.000000	diff=3.63246e-09
  0.000000	  0.000000	diff=7.87449e-10
 -0.000023	 -0.000023	diff=2.54425e-09
  0.000000	  0.000000	diff=2.3192e-12
  0.000000	  0.000000	diff=3.88335e-12
 -0.000000	 -0.000000	diff=9.60237e-12
  0.000001	  0.000001	diff=9.86622e-10
 -0.000000	 -0.000000	diff=1.7678e-10
 -0.000000	 -0.000000	diff=3.09203e-08
  0.000000	  0.000000	diff=7.02617e-09
  local_diff=7.56557e-06
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.003808	 -0.003702	diff=0.000105797
  0.000000	  0.000000	diff=4.63455e-17
  0.000276	  0.000000	diff=0.000276148
  0.000319	  0.000000	diff=0.000318753
  local_diff=0.000700698
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=8.73261e-16
 -0.000000	 -0.000000	diff=6.5708e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.21566e-20
  0.000000	 -0.000000	diff=9.68362e-16
  0.000001	  0.000001	diff=5.11986e-08
 -0.000001	 -0.000001	diff=8.12716e-08
  local_diff=1.32471e-07
# W_a, [2 2]
  0.000132	  0.000126	diff=5.62188e-06
 -0.000165	 -0.000164	diff=1.35735e-06
 -0.000000	 -0.000000	diff=4.68953e-13
  0.000000	  0.000000	diff=4.85336e-13
  local_diff=6.97923e-06
# v_a, [1 2]
 -0.004163	 -0.004146	diff=1.76561e-05
 -0.000435	 -0.000435	diff=2.00205e-07
  local_diff=1.78563e-05
# W_h, [2 4]
 -0.000004	 -0.000004	diff=1.4079e-08
  0.003128	  0.003139	diff=1.05677e-05
  0.000006	  0.000006	diff=3.00859e-08
 -0.004576	 -0.004553	diff=2.23587e-05
 -0.000010	 -0.000011	diff=7.87962e-07
  0.008809	  0.008893	diff=8.43632e-05
 -0.000002	 -0.000007	diff=5.38299e-06
  0.000011	  0.000006	diff=4.7819e-06
  local_diff=0.000128287
# W_soft, [4 2]
 -0.009588	 -0.009636	diff=4.78789e-05
 -0.002234	 -0.005573	diff=0.00333881
  0.992061	  0.992021	diff=3.96587e-05
 -0.973438	 -0.976813	diff=0.00337457
 -0.009596	 -0.009644	diff=4.77818e-05
 -0.002327	 -0.005659	diff=0.00333203
  0.991124	  0.991085	diff=3.95783e-05
 -0.972414	 -0.975781	diff=0.00336772
  local_diff=0.013588
# Num params=182, abs_diff=0.0148659
Elapsed time is 2.347287 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 2, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 2
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=5.39423e-09
  0.000154	 -0.000009	diff=0.000163205
  0.000000	  0.000000	diff=9.27456e-11
  0.000012	  0.000012	diff=6.29672e-08
 -0.000607	 -0.000594	diff=1.31304e-05
 -0.000008	 -0.000008	diff=3.01168e-08
  0.000000	  0.000000	diff=1.99013e-10
  0.000112	  0.000113	diff=1.06509e-06
  0.000000	  0.000000	diff=5.1051e-09
 -0.000194	 -0.000000	diff=0.000193484
  0.000000	  0.000000	diff=1.4879e-33
  0.000000	 -0.000000	diff=1.14644e-25
  0.000000	 -0.000000	diff=6.10842e-30
  0.000000	 -0.000000	diff=2.38683e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=3.00145e-10
  0.000006	  0.000006	diff=2.02908e-08
 -0.000000	 -0.000000	diff=9.87545e-12
 -0.000007	 -0.000007	diff=2.42978e-08
  0.000491	  0.000491	diff=2.96776e-07
  0.000015	  0.000015	diff=5.9203e-08
  0.000000	  0.000000	diff=1.29909e-13
  0.000000	  0.000000	diff=8.17891e-11
 -0.000000	 -0.000000	diff=1.93606e-13
 -0.000000	 -0.000000	diff=4.27268e-13
 -0.000000	 -0.000000	diff=3.42014e-14
  0.000000	  0.000000	diff=5.82576e-14
 -0.000005	 -0.000005	diff=2.35142e-09
 -0.000001	 -0.000001	diff=4.32886e-11
  0.000000	  0.000000	diff=3.94869e-13
  0.000000	  0.000000	diff=1.12832e-13
  local_diff=0.000371392
# W_src{2}, [8 4]
 -0.000078	 -0.000077	diff=3.02361e-07
 -0.000615	 -0.000613	diff=2.64899e-06
 -0.000002	 -0.000002	diff=8.79005e-09
 -0.000002	 -0.000002	diff=7.56529e-09
 -0.004020	 -0.004002	diff=1.80446e-05
 -0.001818	 -0.001818	diff=5.97953e-07
  0.000135	  0.000136	diff=1.04666e-06
 -0.000000	 -0.000000	diff=3.77146e-11
  0.000000	 -0.000000	diff=1.96814e-38
  0.000000	  0.000000	diff=1.18776e-37
  0.000000	  0.000000	diff=7.80455e-39
  0.000000	  0.000000	diff=4.49849e-38
  0.000000	 -0.000000	diff=1.33883e-38
  0.000000	  0.000000	diff=1.79989e-37
  0.000000	 -0.000000	diff=8.32037e-19
  0.000000	  0.000000	diff=1.07574e-18
 -0.000054	 -0.000054	diff=1.76248e-07
 -0.000548	 -0.000546	diff=2.2244e-06
 -0.000000	 -0.000000	diff=3.1383e-10
 -0.000002	 -0.000002	diff=5.84102e-09
 -0.000435	 -0.000437	diff=1.55024e-06
 -0.000060	 -0.000060	diff=6.34149e-08
  0.000125	  0.000126	diff=9.02568e-07
 -0.000000	 -0.000000	diff=3.10599e-11
  0.000015	  0.000015	diff=1.3952e-08
  0.000178	  0.000178	diff=2.4256e-07
  0.000002	  0.000003	diff=9.12918e-09
  0.000001	  0.000001	diff=1.317e-09
  0.003459	  0.003479	diff=1.94272e-05
  0.001806	  0.001805	diff=3.25041e-07
 -0.000035	 -0.000035	diff=7.06493e-08
  0.000000	  0.000000	diff=2.44427e-12
  local_diff=4.76699e-05
# W_tgt{1}, [8 6]
 -0.000001	 -0.000001	diff=4.19801e-09
  0.000000	 -0.000000	diff=5.93927e-20
  0.000000	  0.000000	diff=3.33753e-12
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=5.06253e-08
 -0.000000	 -0.000000	diff=7.51526e-13
  0.000000	  0.000000	diff=5.90485e-53
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=1.82088e-09
  0.000000	  0.000000	diff=1.82185e-13
  0.000000	  0.000000	diff=1.68655e-12
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=2.06028e-08
  0.000000	  0.000000	diff=2.64611e-13
  0.000000	 -0.000000	diff=1.00057e-52
  0.000000	 -0.000000	diff=1.01896e-12
  0.000000	  0.000000	diff=1.7303e-12
  0.000000	  0.000000	diff=2.15047e-13
 -0.000000	 -0.000000	diff=1.50632e-13
  0.000000	  0.000000	diff=5.67229e-14
 -0.000000	 -0.000000	diff=3.20335e-12
  0.000000	  0.000000	diff=1.08032e-13
 -0.000000	 -0.000001	diff=4.99793e-07
  0.000003	  0.000002	diff=1.07353e-06
  0.000000	  0.000000	diff=1.40084e-12
 -0.000000	 -0.000000	diff=4.01366e-13
 -0.000000	 -0.000000	diff=3.67669e-13
 -0.000000	 -0.000000	diff=3.94088e-13
 -0.000000	 -0.000000	diff=3.46446e-12
 -0.000000	 -0.000000	diff=1.43838e-13
  0.000003	  0.000005	diff=1.97835e-06
 -0.000013	 -0.000009	diff=4.20626e-06
 -0.000004	 -0.000004	diff=1.09937e-08
  0.000000	  0.000000	diff=9.47157e-14
 -0.000005	 -0.000005	diff=1.50247e-08
  0.000000	  0.000000	diff=3.36887e-13
 -0.000002	 -0.000002	diff=5.39167e-09
  0.000000	  0.000000	diff=1.76866e-13
 -0.000000	 -0.000000	diff=1.40509e-11
  0.000000	  0.000000	diff=6.9327e-12
 -0.000000	 -0.000000	diff=1.72841e-11
  0.000000	  0.000000	diff=2.1787e-13
 -0.000000	 -0.000000	diff=2.34929e-11
  0.000000	  0.000000	diff=6.18171e-13
 -0.000000	 -0.000000	diff=9.95984e-12
  0.000000	  0.000000	diff=3.2067e-13
 -0.000000	 -0.000000	diff=6.84442e-08
  0.000000	  0.000000	diff=1.46928e-07
  local_diff=8.08206e-06
# W_tgt{2}, [8 4]
  0.000234	  0.000233	diff=5.87962e-08
 -0.000000	 -0.000000	diff=5.04073e-11
 -0.000000	 -0.000000	diff=1.3557e-10
  0.000000	  0.000000	diff=1.66058e-10
 -0.000010	 -0.000010	diff=4.86764e-08
  0.000001	  0.000001	diff=3.06855e-09
  0.000001	  0.000002	diff=2.03535e-07
 -0.000003	 -0.000003	diff=4.37639e-08
 -0.000000	 -0.000000	diff=2.96047e-13
  0.000000	  0.000000	diff=6.09366e-13
 -0.000000	 -0.000000	diff=3.24934e-13
  0.000000	  0.000000	diff=8.44173e-14
 -0.000000	 -0.000000	diff=8.03062e-14
  0.000000	  0.000000	diff=5.43826e-13
  0.000000	  0.000005	diff=4.31779e-06
 -0.000013	 -0.000010	diff=2.86293e-06
  0.000181	  0.000181	diff=8.38959e-08
 -0.000000	 -0.000000	diff=2.84508e-11
 -0.000000	 -0.000000	diff=7.52702e-11
  0.000000	  0.000000	diff=9.04681e-11
 -0.000010	 -0.000010	diff=4.1621e-08
  0.000000	  0.000000	diff=1.6604e-09
 -0.000000	 -0.000000	diff=3.6353e-09
  0.000000	  0.000000	diff=7.85375e-10
 -0.000050	 -0.000050	diff=1.31791e-09
  0.000000	  0.000000	diff=2.59993e-12
  0.000000	  0.000000	diff=7.84057e-12
 -0.000000	 -0.000000	diff=1.01977e-11
  0.000001	  0.000001	diff=1.01995e-09
 -0.000000	 -0.000000	diff=1.83653e-10
 -0.000000	 -0.000000	diff=3.09212e-08
  0.000000	  0.000000	diff=7.02625e-09
  local_diff=7.7112e-06
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.001640	 -0.001470	diff=0.000169315
  0.000000	  0.000000	diff=4.53957e-17
  0.000276	  0.000000	diff=0.000276148
  0.000319	  0.000000	diff=0.000318753
  local_diff=0.000764217
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=8.73261e-16
 -0.000000	 -0.000000	diff=5.34632e-14
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.21566e-20
  0.000000	 -0.000000	diff=9.68362e-16
  0.000001	  0.000001	diff=5.11986e-08
 -0.000001	 -0.000001	diff=8.12709e-08
  local_diff=1.3247e-07
# W_a, [2 2]
  0.000175	  0.000167	diff=7.14767e-06
 -0.000223	 -0.000221	diff=1.75349e-06
 -0.000000	 -0.000000	diff=8.52951e-13
  0.000000	  0.000000	diff=9.57033e-13
  local_diff=8.90116e-06
# v_a, [1 2]
 -0.005545	 -0.005525	diff=1.96727e-05
 -0.000611	 -0.000611	diff=2.22742e-07
  local_diff=1.98954e-05
# W_h, [2 4]
 -0.000023	 -0.000023	diff=5.15507e-08
  0.003814	  0.003825	diff=1.12005e-05
  0.000060	  0.000059	diff=3.41007e-07
 -0.007070	 -0.007033	diff=3.73316e-05
 -0.000084	 -0.000086	diff=1.39864e-06
  0.012220	  0.012333	diff=0.000113721
 -0.000002	 -0.000007	diff=5.38299e-06
  0.000011	  0.000006	diff=4.7819e-06
  local_diff=0.00017421
# W_soft, [4 2]
 -0.009586	 -0.009634	diff=4.78674e-05
 -0.002633	 -0.005972	diff=0.00333918
  0.992047	  0.992008	diff=3.97228e-05
 -0.973027	 -0.976402	diff=0.00337493
 -0.009591	 -0.009639	diff=4.7737e-05
 -0.003963	 -0.007293	diff=0.00333006
  0.991074	  0.991035	diff=3.96141e-05
 -0.970737	 -0.974103	diff=0.00336571
  local_diff=0.0135848
# Num params=182, abs_diff=0.014987
Elapsed time is 2.618329 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 188, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_a=4 v_a=2 W_h=8 W_soft=8
# addNoise = 0
# assert = 0
# attnFunc = 4
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# normLocalAttn = 0
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# prefixDecoder = 0
# reuseEncoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 188
  src input 1: <s> <s> y x
  src mask: 0  0  1  1
  tgt input 1: <s> b </s> </s> </s>
  tgt output 1: b </s> </s> </s> </s>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
  0.000000	 -0.000000	diff=5.66764e-28
  0.000000	  0.000000	diff=2.86785e-17
  0.000000	 -0.000000	diff=1.39905e-31
  0.000000	  0.000000	diff=3.11418e-27
  0.000000	  0.000000	diff=4.67217e-32
  0.000000	  0.000000	diff=8.64394e-18
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.62452e-18
  0.000000	 -0.000000	diff=9.01163e-17
  0.000000	  0.000000	diff=1.78716e-31
  0.000000	 -0.000000	diff=4.22286e-27
  0.000000	 -0.000000	diff=2.02162e-31
  0.000000	 -0.000000	diff=4.24554e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=9.049e-60
  0.000000	 -0.000000	diff=2.33421e-54
  0.000000	  0.000000	diff=2.58426e-70
  0.000000	 -0.000000	diff=5.38678e-66
  0.000000	 -0.000000	diff=2.24074e-69
  0.000000	 -0.000000	diff=2.3023e-54
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=5.77494e-40
  0.000000	  0.000000	diff=2.95336e-38
  0.000000	 -0.000000	diff=8.14484e-55
  0.000000	  0.000000	diff=5.99124e-55
  0.000000	  0.000000	diff=1.92799e-53
  0.000000	  0.000000	diff=2.46056e-38
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.72519e-16
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=6.26845e-52
  0.000000	 -0.000000	diff=1.39592e-51
  0.000000	 -0.000000	diff=1.15337e-52
  0.000000	 -0.000000	diff=3.81782e-52
  0.000000	  0.000000	diff=6.54372e-52
  0.000000	 -0.000000	diff=2.08147e-51
  0.000000	 -0.000000	diff=2.29999e-32
  0.000000	 -0.000000	diff=2.65057e-32
  0.000000	 -0.000000	diff=2.72038e-38
  0.000000	  0.000000	diff=1.13467e-37
  0.000000	  0.000000	diff=3.52363e-39
  0.000000	  0.000000	diff=1.44787e-38
  0.000000	 -0.000000	diff=3.25493e-38
  0.000000	  0.000000	diff=8.59556e-38
  0.000000	  0.000000	diff=1.1624e-18
  0.000000	  0.000000	diff=5.46804e-18
  0.000000	 -0.000000	diff=8.98756e-40
  0.000000	 -0.000000	diff=2.66207e-40
  0.000000	 -0.000000	diff=1.05283e-40
  0.000000	  0.000000	diff=6.79458e-40
  0.000000	 -0.000000	diff=1.19787e-39
  0.000000	  0.000000	diff=1.045e-38
  0.000000	  0.000000	diff=8.58564e-19
  0.000000	 -0.000000	diff=3.09972e-19
  0.000000	 -0.000000	diff=3.83263e-38
  0.000000	  0.000000	diff=1.45916e-37
  0.000000	  0.000000	diff=1.03651e-38
  0.000000	  0.000000	diff=6.26609e-38
  0.000000	 -0.000000	diff=3.60697e-38
  0.000000	  0.000000	diff=1.65057e-37
  0.000000	  0.000000	diff=3.58245e-19
  0.000000	  0.000000	diff=5.97618e-18
  local_diff=1.41334e-17
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.1097e-09
  0.000000	 -0.000000	diff=1.0621e-19
  0.000000	  0.000000	diff=9.14306e-12
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=1.33672e-08
 -0.000000	 -0.000000	diff=4.53243e-09
  0.000000	  0.000000	diff=6.83816e-53
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=4.81766e-10
 -0.051188	 -0.049594	diff=0.0015936
  0.000000	  0.000000	diff=2.95321e-12
  0.000000	  0.000000	diff=9.1722e-26
 -0.000000	 -0.000000	diff=5.44063e-09
 -0.000008	 -0.000008	diff=2.64284e-07
  0.000000	 -0.000000	diff=1.15872e-52
 -0.035995	 -0.038649	diff=0.00265377
  0.000000	  0.000000	diff=6.11153e-17
 -0.009039	 -0.008987	diff=5.15532e-05
  0.000000	  0.000000	diff=3.62389e-20
  0.000000	  0.000000	diff=1.64941e-26
  0.000000	  0.000000	diff=1.00764e-16
 -0.000001	 -0.000001	diff=8.80886e-09
  0.000000	  0.000000	diff=8.49824e-92
  0.000000	  0.000000	diff=1.29138e-15
  0.000000	  0.000000	diff=4.29389e-17
  0.000000	 -0.000000	diff=1.68667e-37
  0.000000	  0.000000	diff=2.5461e-20
  0.000000	  0.000000	diff=3.17353e-50
  0.000000	  0.000000	diff=7.07954e-17
  0.000000	 -0.000000	diff=5.03553e-22
  0.000000	 -0.000000	diff=1.9071e-122
  0.000000	 -0.000000	diff=6.37021e-19
  0.000000	 -0.000000	diff=2.48655e-17
  0.005460	  0.005479	diff=1.90551e-05
  0.000000	 -0.000000	diff=1.47442e-20
  0.000000	 -0.000000	diff=1.00555e-26
  0.000000	 -0.000000	diff=4.09969e-17
  0.000001	  0.000001	diff=3.29591e-09
  0.000000	 -0.000000	diff=6.82239e-50
  0.000000	 -0.000000	diff=5.64989e-20
  0.000000	 -0.000000	diff=4.777e-23
 -0.005338	 -0.005320	diff=1.80419e-05
  0.000000	 -0.000000	diff=2.83507e-26
  0.000000	  0.000000	diff=9.76439e-27
  0.000000	 -0.000000	diff=7.87606e-23
 -0.000001	 -0.000001	diff=3.09237e-09
  0.000000	  0.000000	diff=1.59822e-30
  0.000000	  0.000000	diff=1.4574e-19
  local_diff=0.00433633
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=7.12128e-17
  0.000000	 -0.000000	diff=3.30068e-17
  0.000000	 -0.000000	diff=9.44229e-18
  0.000000	 -0.000000	diff=3.36915e-18
  0.000000	  0.000000	diff=8.05869e-17
  0.000000	 -0.000000	diff=3.88815e-17
  0.000000	  0.000000	diff=1.4714e-13
  0.000000	  0.000000	diff=6.5187e-13
 -0.000192	 -0.000191	diff=8.53084e-07
 -0.052951	 -0.053265	diff=0.000314231
  0.000000	  0.000000	diff=2.68088e-13
 -0.000048	 -0.000048	diff=3.37249e-09
 -0.001836	 -0.001836	diff=1.54303e-07
 -0.006513	 -0.006544	diff=3.08051e-05
  0.000124	  0.000123	diff=8.32098e-07
  0.000001	  0.000001	diff=3.2203e-09
 -0.000000	 -0.000000	diff=3.06445e-12
  0.000000	  0.000000	diff=2.66408e-12
  0.000000	  0.000000	diff=1.76111e-13
 -0.000005	 -0.000005	diff=3.32444e-11
 -0.000182	 -0.000182	diff=1.40088e-09
 -0.000004	 -0.000004	diff=3.18565e-11
  0.000000	  0.000000	diff=6.15082e-11
  0.000000	  0.000000	diff=5.05525e-11
 -0.000188	 -0.000188	diff=6.5033e-07
  0.000187	  0.000188	diff=6.48196e-07
  0.000000	  0.000000	diff=2.43151e-10
 -0.002279	 -0.002286	diff=7.59918e-06
 -0.086777	 -0.087097	diff=0.00032044
 -0.002127	 -0.002134	diff=7.31799e-06
 -0.000002	 -0.000002	diff=1.27562e-08
  0.000037	  0.000037	diff=2.31325e-07
  local_diff=0.000683784
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=6.38534e-19
  0.000000	  0.000000	diff=1.38624e-16
  0.000000	  0.000000	diff=3.32198e-17
  0.000000	  0.000000	diff=3.80577e-17
  local_diff=2.1054e-16
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=6.99606e-09
  0.000000	  0.000000	diff=3.66329e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=4.96055e-23
  0.000000	 -0.000000	diff=2.89832e-15
  0.000000	  0.000000	diff=1.35179e-08
 -0.016303	 -0.016198	diff=0.000105063
  local_diff=0.000105084
# W_pos, [2 2]
  0.000000	 -0.000000	diff=9.51025e-23
  0.000000	 -0.000000	diff=1.20358e-22
  0.000000	 -0.000000	diff=8.35342e-24
  0.000000	  0.000000	diff=8.82209e-25
  local_diff=2.24696e-22
# v_pos, [1 2]
  0.000000	  0.000000	diff=2.23547e-22
  0.000000	  0.000000	diff=8.23892e-22
  local_diff=1.04744e-21
# W_a, [2 2]
  0.000000	  0.000000	diff=6.32088e-37
  0.000000	  0.000000	diff=3.93191e-38
  0.000000	 -0.000000	diff=4.07848e-39
  0.000000	 -0.000000	diff=1.62503e-39
  local_diff=6.7711e-37
# v_a, [1 2]
  0.000000	  0.000000	diff=1.09592e-37
  0.000000	  0.000000	diff=5.45102e-37
  local_diff=6.54693e-37
# W_h, [2 4]
  0.000000	  0.000000	diff=6.60343e-20
  0.000000	 -0.000000	diff=2.5641e-22
  0.000000	 -0.000000	diff=2.19384e-19
  0.000000	 -0.000000	diff=3.68496e-19
  0.040349	  0.040338	diff=1.07749e-05
  0.016295	  0.016293	diff=1.4384e-06
 -0.011491	 -0.011414	diff=7.65665e-05
  0.046568	  0.046247	diff=0.000320704
  local_diff=0.000409484
# W_soft, [4 2]
  0.006007	  0.006004	diff=3.22091e-06
 -0.017022	 -0.017023	diff=4.18161e-07
  1.005118	  1.005114	diff=3.96647e-06
 -0.994094	 -0.994095	diff=1.14387e-06
  0.004422	  0.004419	diff=2.95796e-06
 -0.012086	 -0.012086	diff=2.14466e-07
  0.995792	  0.995788	diff=3.66931e-06
 -0.988120	 -0.988121	diff=9.19865e-07
  local_diff=1.6511e-05
# Num params=188, abs_diff=0.00555119
Elapsed time is 3.406617 seconds.
[?1l>